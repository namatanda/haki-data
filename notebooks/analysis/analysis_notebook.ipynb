{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List, Union, Optional\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_columns(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows containing NaN values from the specified columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to process.\n",
    "        columns (List[str]): A list of column names to check for NaN values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with NaN-containing rows dropped.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any of the specified columns are not present in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Validate that all specified columns exist in the DataFrame\n",
    "    missing_columns = set(columns) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Columns not found in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Identify columns with NaN values\n",
    "    nan_columns = df[columns].columns[df[columns].isna().any()].tolist()\n",
    "\n",
    "    # Log dropped rows if any\n",
    "    if nan_columns:\n",
    "        nan_count = df[columns].isna().sum()\n",
    "        logger.info(\"Dropping rows with NaN values:\")\n",
    "        for col in nan_columns:\n",
    "            logger.info(f\"  {col}: {nan_count[col]} rows\")\n",
    "\n",
    "    # Drop rows with NaN values in specified columns\n",
    "    original_row_count = len(df)\n",
    "    df_cleaned = df.dropna(subset=columns)\n",
    "    dropped_row_count = original_row_count - len(df_cleaned)\n",
    "\n",
    "    if dropped_row_count > 0:\n",
    "        logger.info(f\"Total rows dropped: {dropped_row_count}\")\n",
    "    else:\n",
    "        logger.info(\"No rows were dropped.\")\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove duplicates from a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    num_duplicates = data.duplicated().sum()\n",
    "    \n",
    "    if num_duplicates > 0:\n",
    "        logging.info(f\"{num_duplicates} duplicates found.\")\n",
    "        data = data.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "        logging.info(f\"{num_duplicates} duplicates removed.\")\n",
    "    else:\n",
    "        logging.info(\"No duplicates found.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_date_column(df: pd.DataFrame, column_names: List[str], new_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a new date column in the DataFrame by concatenating the values of three specified columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_names (List[str]): A list of three column names to be concatenated [year, month, day].\n",
    "        new_col (str): The import commandsname of the new date column to be created.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new date column added.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input list doesn't contain exactly three column names or if columns are missing.\n",
    "    \"\"\"\n",
    "    if len(column_names) != 3:\n",
    "        raise ValueError(\"column_names must contain exactly three elements: [year, month, day]\")\n",
    "\n",
    "    year_col, month_col, day_col = column_names\n",
    "\n",
    "    # Check if all required columns exist in the DataFrame\n",
    "    missing_columns = set(column_names) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Create copies to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "\n",
    "    try:\n",
    "        # Convert year and day columns to integers\n",
    "        df[year_col] = df[year_col].astype(float).astype(int)\n",
    "        df[day_col] = df[day_col].astype(float).astype(int)\n",
    "\n",
    "        # Concatenate the columns to create a date string\n",
    "        df[new_col] = (df[year_col].astype(str) + '-' + \n",
    "                       df[month_col].astype(str) + '-' + \n",
    "                       df[day_col].astype(str))\n",
    "\n",
    "        # Convert to datetime\n",
    "        df[new_col] = pd.to_datetime(df[new_col], errors='coerce')\n",
    "\n",
    "        # Log information about the conversion\n",
    "        valid_dates = df[new_col].notna().sum()\n",
    "        logger.info(f\"Created new date column '{new_col}'. Valid dates: {valid_dates}/{len(df)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating date column: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_title_case(text):\n",
    "    \"\"\"\n",
    "    Apply title case to a given string.\n",
    "    \n",
    "    Args:\n",
    "        text: The input string to process.\n",
    "    \n",
    "    Returns:\n",
    "        str: The processed string in title case.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    if not isinstance(text, str):\n",
    "        logger.warning(f\"Non-string value encountered: {text}\")\n",
    "        return str(text)\n",
    "    return text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_outcome_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the 'outcome' column of the DataFrame by applying title case.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing the 'outcome' column.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the processed 'outcome' column.\n",
    "    \"\"\"\n",
    "    if 'outcome' not in df.columns:\n",
    "        logger.error(\"'outcome' column not found in the DataFrame\")\n",
    "        return df\n",
    "\n",
    "    original_null_count = df['outcome'].isnull().sum()\n",
    "    \n",
    "    df['outcome'] = df['outcome'].apply(apply_title_case)\n",
    "    \n",
    "    new_null_count = df['outcome'].isnull().sum()\n",
    "    if new_null_count > original_null_count:\n",
    "        logger.warning(f\"Number of null values in 'outcome' increased from {original_null_count} to {new_null_count}\")\n",
    "    \n",
    "    non_string_count = df['outcome'].apply(lambda x: not isinstance(x, str) if pd.notna(x) else False).sum()\n",
    "    if non_string_count > 0:\n",
    "        logger.warning(f\"Found {non_string_count} non-string values in 'outcome' after processing\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_values(df: pd.DataFrame, column_name: str = 'outcome') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows from the DataFrame where the specified column contains null values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame from which to drop rows.\n",
    "        column_name (str): The name of the column to check for null values. Default is 'outcome'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with rows containing null values in the specified column dropped.\n",
    "    \"\"\"\n",
    "    initial_row_count: int = df.shape[0]\n",
    "    cleaned_df: pd.DataFrame = df.dropna(subset=[column_name])\n",
    "    final_row_count: int = cleaned_df.shape[0]\n",
    "    dropped_row_count: int = initial_row_count - final_row_count\n",
    "    \n",
    "    if dropped_row_count > 0:\n",
    "        logger.info(f\"Total dropped rows with null values in '{column_name}': {dropped_row_count}\")\n",
    "    else:\n",
    "        logger.info(f\"No rows dropped with null values in '{column_name}'\")\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_case(case_type: str, criminal_cases: Optional[List[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Categorize a case as 'Criminal' or 'Civil' based on its type.\n",
    "    \n",
    "    Args:\n",
    "        case_type (str): The type of the case.\n",
    "        criminal_cases (Optional[List[str]]): List of case types considered as criminal.\n",
    "        \n",
    "    Returns:\n",
    "        str: 'Criminal' if the case type is in the criminal cases list or if criminal_cases is None, 'Civil' otherwise.\n",
    "    \"\"\"\n",
    "    if criminal_cases is None:\n",
    "        return 'Criminal'\n",
    "    else:\n",
    "        return 'Criminal' if case_type in criminal_cases else 'Civil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_cases(df: pd.DataFrame, criminal_cases: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Categorize all cases in the DataFrame as 'Criminal' or 'Civil'.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case data.\n",
    "        criminal_cases (Optional[List[str]]): List of case types considered as criminal.\n",
    "            If None, all cases are categorized as 'Criminal'.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an added 'nature' column indicating case nature.\n",
    "    \"\"\"\n",
    "    df['nature'] = df['case_type'].apply(lambda x: categorize_case(x, criminal_cases))\n",
    "\n",
    "    # Check for presence of both case types\n",
    "    if 'Criminal' not in df['nature'].values:\n",
    "        logging.warning(\"No criminal cases found in the DataFrame.\")\n",
    "    if 'Civil' not in df['nature'].values:\n",
    "        logging.warning(\"No civil cases found in the DataFrame.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dict(value: Any, dictionary: Dict[str, Union[str, List[Any]]]) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Find all keys in a dictionary where the given value matches.\n",
    "\n",
    "    Args:\n",
    "        value: The value to search for.\n",
    "        dictionary: The dictionary to search in.\n",
    "\n",
    "    Returns:\n",
    "        A list of keys where the value matches, or None if no matches are found.\n",
    "    \"\"\"\n",
    "    matching_keys = []\n",
    "    for key, dict_value in dictionary.items():\n",
    "        if isinstance(dict_value, str) and dict_value == value:\n",
    "            matching_keys.append(key)\n",
    "        elif isinstance(dict_value, list) and value in dict_value:\n",
    "            matching_keys.append(key)\n",
    "    \n",
    "    if not matching_keys:\n",
    "        return None\n",
    "    elif len(matching_keys) == 1:\n",
    "        return matching_keys[0]\n",
    "    else:\n",
    "        return matching_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_case_num(df: pd.DataFrame, court_col: str, caseid_type_col: str, caseid_no_col: str, filed_yyyy_col: str, new_col='case_number') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a case number by concatenating court, caseid_type, caseid_no, and filed_yyyy columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the necessary columns.\n",
    "        court_col (str): The name of the column containing court information.\n",
    "        caseid_type_col (str): The name of the column containing case ID type.\n",
    "        caseid_no_col (str): The name of the column containing case ID number.\n",
    "        filed_yyyy_col (str): The name of the column containing the year the case was filed.\n",
    "        new_col (str): The name of the new column to be created for the case number. Default is 'case_num'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the new case number column.\n",
    "    \"\"\"\n",
    "    df[new_col] = df[court_col] + '/' + df[caseid_type_col] + '/' + df[caseid_no_col] + '/' + df[filed_yyyy_col].astype(str)\n",
    "    return df\n",
    "\n",
    "def is_concluded(outcome: str, resolved_outcomes: List[str]) -> int:\n",
    "    \"\"\"\n",
    "    Determine if the case is concluded based on the outcome.\n",
    "    \n",
    "    Args:\n",
    "        outcome (str): The outcome of the case.\n",
    "        resolved_outcomes (List[str]): List of outcomes considered as resolved.\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if the case outcome is resolved, 0 otherwise.\n",
    "    \"\"\"\n",
    "    return 1 if outcome in resolved_outcomes else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_case_registered(outcome: str, activity_date: Union[pd.Timestamp, str], filed_date: Union[pd.Timestamp, str]) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if a case is registered based on its outcome and dates.\n",
    "\n",
    "    Args:\n",
    "        outcome (str): The outcome of the case.\n",
    "        activity_date (Union[pd.Timestamp, str]): The date of the activity.\n",
    "        filed_date (Union[pd.Timestamp, str]): The date the case was filed.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the case is registered, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Normalize the outcome string\n",
    "        normalized_outcome = outcome.strip().lower()\n",
    "\n",
    "        # Check if the outcome indicates registration\n",
    "        is_registered_outcome = 'case registered/filed' in normalized_outcome \n",
    "\n",
    "        # Convert dates to pd.Timestamp if they're strings\n",
    "        if isinstance(activity_date, str):\n",
    "            activity_date = pd.to_datetime(activity_date, errors='coerce')\n",
    "        if isinstance(filed_date, str):\n",
    "            filed_date = pd.to_datetime(filed_date, errors='coerce')\n",
    "\n",
    "        # Check if dates are equal\n",
    "        dates_match = pd.notna(activity_date) and pd.notna(filed_date) and activity_date == filed_date\n",
    "\n",
    "        is_registered = is_registered_outcome and dates_match\n",
    "\n",
    "        if is_registered:\n",
    "            logger.debug(f\"Case registered: outcome='{outcome}', activity_date={activity_date}, filed_date={filed_date}\")\n",
    "        \n",
    "        return is_registered\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in is_case_registered: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_case_status(df: pd.DataFrame, resolved_outcome: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the DataFrame to add 'concluded' and 'registered' columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case information.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with added 'concluded' and 'registered' columns.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If required columns are missing from the DataFrame.\n",
    "    \"\"\"\n",
    "    required_columns = ['outcome', 'activity_date', 'filed_date']\n",
    "    missing_columns = set(required_columns) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
    "\n",
    "    #df['concluded'] = df['outcome'].apply(is_case_concluded)\n",
    "    df['concluded'] = df['outcome'].apply(lambda x: is_concluded(x, resolved_outcome))\n",
    "    df['registered'] = df.apply(lambda row: is_case_registered(row['outcome'], row['activity_date'], row['filed_date']), axis=1)\n",
    "\n",
    "    logger.info(f\"Processed {len(df)} cases\")\n",
    "    logger.info(f\"Concluded cases: {df['concluded'].sum()}\")\n",
    "    logger.info(f\"Registered cases: {df['registered'].sum()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_court_outcomes(df: pd.DataFrame, start_date: str, end_date: str, outcome: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the number of case outcomes per court within a specified period.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): A pandas DataFrame containing the data.\n",
    "        start_date (str): The starting date of the period (YYYY-MM-DD format).\n",
    "        end_date (str): The ending date of the period (YYYY-MM-DD format).\n",
    "        outcome (str): A column representing the outcome of interest.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame showing the number of resolved cases per court and case category.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        period_start = pd.to_datetime(start_date)\n",
    "        period_end = pd.to_datetime(end_date)\n",
    "        \n",
    "        if period_start > period_end:\n",
    "            raise ValueError(\"start_date must be earlier than end_date\")\n",
    "        \n",
    "        required_columns = {'court', 'broad_case_type', 'activity_date', outcome}\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            missing_columns = required_columns - set(df.columns)\n",
    "            raise KeyError(f\"Missing required columns: {missing_columns}\")\n",
    "        \n",
    "        filtered_cases = df[\n",
    "            (df['activity_date'] >= period_start) &\n",
    "            (df['activity_date'] <= period_end) &\n",
    "            (df[outcome] == 1)\n",
    "        ]\n",
    "        \n",
    "        if filtered_cases.empty:\n",
    "            logging.warning(\"No cases found for the given date range and outcome.\")\n",
    "   \n",
    "        outcome_by_type = (\n",
    "            filtered_cases\n",
    "            .groupby(['court', 'broad_case_type'])\n",
    "            .size()\n",
    "            .reset_index(name='num_cases')\n",
    "        )\n",
    "\n",
    "        result = outcome_by_type.pivot_table(\n",
    "            index='court', \n",
    "            columns='broad_case_type', \n",
    "            values='num_cases', \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        logging.info(\"Successfully calculated case outcomes per court.\")\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time_limit(age, case_category, concluded, time_lines):\n",
    "    \"\"\"\n",
    "    Check if a case falls within the specified time limit for its category and is concluded.\n",
    "    \n",
    "    Parameters:\n",
    "        age (int): The age of the case in days.\n",
    "        case_category (str): The category of the case.\n",
    "        concluded (int): The status of the case conclusion (1 for concluded, 0 otherwise).\n",
    "        time_lines (dict): A dictionary with case categories as keys and time limits as values.\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if the case is within the time limit and concluded, otherwise 0.\n",
    "    \"\"\"\n",
    "    time_limit = time_lines.get(case_category, 0)\n",
    "    return 1 if age <= time_limit and concluded == 1 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_judgment_scheduling(df, cutoff_date):\n",
    "    judgment_date_set_outcomes = [\"Judgment Date Given\", \"Judgment On Notice\", \"Judgment Date Set\"]\n",
    "    judgment_delivered_outcomes = [\"Grant Revoked\", \"Judgment Delivered\", \n",
    "                                   \"Judgment Delivered- Acquittal\", \"Judgment Delivered- Case Closed\", \n",
    "                                   \"Judgment Delivered- Convicted\"]\n",
    "    \n",
    "    # Preprocessing: Filter and sort the DataFrame upfront\n",
    "    df_filtered = df[df['outcome'].isin(judgment_date_set_outcomes + judgment_delivered_outcomes)]\n",
    "    df_filtered = df_filtered.sort_values(by=['case_number', 'activity_date'])\n",
    "    \n",
    "    # Initialize columns\n",
    "    df['judgment_status'] = 'Not Scheduled'\n",
    "    df['set_date'] = pd.NaT\n",
    "    df['delivery_date'] = pd.NaT\n",
    "    df['delivery_category'] = ''\n",
    "    \n",
    "    # Filter rows with judgment set outcomes and valid schedule dates\n",
    "    judgment_set_rows = df_filtered[df_filtered['outcome'].isin(judgment_date_set_outcomes) & \n",
    "                                    (df_filtered['next_date'] <= cutoff_date)]\n",
    "    \n",
    "    # For each case, find the earliest set date\n",
    "    earliest_schedule = judgment_set_rows.groupby('case_number').first().reset_index()\n",
    "    \n",
    "    # Create dictionaries to map case numbers to their schedule dates and statuses\n",
    "    case_to_set_date = dict(zip(earliest_schedule['case_number'], earliest_schedule['next_date']))\n",
    "    case_to_status = {case: 'Scheduled' for case in earliest_schedule['case_number']}\n",
    "    \n",
    "    # Update the result dataframe with schedule information\n",
    "    df['set_date'] = df['case_number'].map(case_to_set_date)\n",
    "    df['judgment_status'] = df['case_number'].map(case_to_status).fillna('Not Scheduled')\n",
    "    df['delivery_category'] = df['case_number'].map(case_to_status).fillna('')\n",
    "    \n",
    "    # Filter rows with judgment delivered outcomes\n",
    "    judgment_delivered_rows = df_filtered[df_filtered['outcome'].isin(judgment_delivered_outcomes)]\n",
    "    \n",
    "    # Find the first delivery date after set date\n",
    "    for case_number, group in earliest_schedule.groupby('case_number'):\n",
    "        set_date = group['next_date'].values[0]\n",
    "        delivery = judgment_delivered_rows[(judgment_delivered_rows['case_number'] == case_number) & \n",
    "                                           (judgment_delivered_rows['activity_date'] >= set_date)]\n",
    "        \n",
    "        if not delivery.empty:\n",
    "            delivery_date = delivery.iloc[0]['activity_date']\n",
    "            df.loc[df['case_number'] == case_number, 'delivery_date'] = delivery_date\n",
    "            df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "            \n",
    "            if delivery_date <= set_date:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'On Time'\n",
    "            else:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'Delayed'\n",
    "        else:\n",
    "            earlier_delivery = judgment_delivered_rows[(judgment_delivered_rows['case_number'] == case_number) & \n",
    "                                                       (judgment_delivered_rows['activity_date'] < set_date)]\n",
    "            if earlier_delivery.empty:\n",
    "                if cutoff_date >= set_date:\n",
    "                    df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delayed'\n",
    "                    df.loc[df['case_number'] == case_number, 'delivery_category'] = 'Delayed'\n",
    "            else:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_date'] = earlier_delivery.iloc[0]['activity_date']\n",
    "                df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'On Time'\n",
    "    \n",
    "    return df[df['set_date'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_on_time_delivery_proportions(scheduled_cases):\n",
    "    # Get the final status for each case\n",
    "    final_status = scheduled_cases.groupby(['court', 'case_number']).last().reset_index()\n",
    "    \n",
    "    # Group by court and calculate statistics\n",
    "    court_stats = final_status.groupby('court').agg({\n",
    "        'case_number': 'count',\n",
    "        'delivery_category': lambda x: (x == 'On Time').sum()\n",
    "    }).rename(columns={\n",
    "        'case_number': 'total_scheduled',\n",
    "        'delivery_category': 'delivered_on_time'\n",
    "    })\n",
    "    \n",
    "    # Calculate the proportion\n",
    "    court_stats['proportion_on_time'] = court_stats['delivered_on_time'] / court_stats['total_scheduled']\n",
    "    \n",
    "    return court_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_case_resolution_proportions(df, case_type_timelines):\n",
    "  # Convert date columns to datetime\n",
    "  date_columns = ['filed_date', 'activity_date']\n",
    "  for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "  # Filter cases based on case_type_timelines\n",
    "  df = df[df['broad_case_type'].isin(HC_PMMU_TIME_LINES.keys())]\n",
    "\n",
    "  # Function to check if a case is resolved within timeline\n",
    "  def is_resolved_within_timeline(row):\n",
    "    timeline = case_type_timelines.get(row['broad_case_type'], float('inf'))\n",
    "    return row['concluded'] == 1 and row['age'] <= timeline\n",
    "\n",
    "  # Group by court and case type, then calculate statistics\n",
    "  stats = df.groupby(['court', 'broad_case_type']).apply(\n",
    "    lambda x: pd.Series({\n",
    "      'total_cases': len(x),\n",
    "      'resolved_within_timeline': sum(x.apply(is_resolved_within_timeline, axis=1)),\n",
    "      'proportion_resolved': sum(x.apply(is_resolved_within_timeline, axis=1)) / len(x) if len(x) > 0 else 0\n",
    "    })\n",
    "  ).reset_index()\n",
    "\n",
    "  return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivot_table(df, case_type_timelines):\n",
    "  # Calculate statistics using the modified function\n",
    "  stats = get_case_resolution_proportions(df, case_type_timelines)\n",
    "\n",
    "  # Pivot the data\n",
    "  pivot_table = stats.pivot_table(\n",
    "      index='court',\n",
    "      columns='broad_case_type',\n",
    "      values=['total_cases', 'resolved_within_timeline', 'proportion_resolved']\n",
    "  )\n",
    "\n",
    "  # Flatten the column hierarchy\n",
    "  pivot_table.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_table.columns]\n",
    "\n",
    "  return pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_case_resolution_pivot(df, case_type_timelines):\n",
    "    # Prepare the aggfunc dictionary\n",
    "    aggfunc = {}\n",
    "    for case_type, timeline in case_type_timelines.items():\n",
    "        column = f\"{case_type}_{timeline}_days\"\n",
    "        aggfunc[f\"{column}_total\"] = 'count'\n",
    "        aggfunc[f\"{column}_resolved\"] = 'sum'\n",
    "        aggfunc[f\"{column}_proportion\"] = lambda x: x.sum() / x.count() if x.count() > 0 else 0\n",
    "\n",
    "    # Create pivot table\n",
    "    pivot = pd.pivot_table(\n",
    "        df,\n",
    "        values=[f\"{case_type}_{timeline}_days\" for case_type, timeline in case_type_timelines.items()],\n",
    "        index=['court'],\n",
    "        aggfunc=aggfunc\n",
    "    )\n",
    "\n",
    "    # Rename columns to match the desired format\n",
    "    new_columns = []\n",
    "    for case_type, timeline in case_type_timelines.items():\n",
    "        for stat in ['total', 'resolved', 'proportion']:\n",
    "            new_columns.append(f\"{case_type}_{timeline}_days_{stat}\")\n",
    "    \n",
    "    pivot.columns = new_columns\n",
    "\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_case_resolution_proportions(df, case_type_timelines):\n",
    "  # Convert date columns to datetime\n",
    "  date_columns = ['filed_date', 'activity_date']\n",
    "  for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "  # Filter cases based on case_type_timelines\n",
    "  df = df[df['broad_case_type'].isin(HC_PMMU_TIME_LINES.keys())]\n",
    "\n",
    "  # Function to check if a case is resolved within timeline\n",
    "  def is_resolved_within_timeline(row):\n",
    "    timeline = case_type_timelines.get(row['broad_case_type'], float('inf'))\n",
    "    return row['concluded'] == 1 and row['age'] <= timeline\n",
    "\n",
    "  # Group by court and case type, then calculate statistics\n",
    "  stats = df.groupby(['court', 'broad_case_type']).apply(\n",
    "    lambda x: pd.Series({\n",
    "      'total_cases': len(x),\n",
    "      'resolved_within_timeline': sum(x.apply(is_resolved_within_timeline, axis=1)),\n",
    "      'proportion_resolved': sum(x.apply(is_resolved_within_timeline, axis=1)) / len(x) if len(x) > 0 else 0\n",
    "    })\n",
    "  ).reset_index()\n",
    "\n",
    "  return stats\n",
    "def create_pivot_table(df, case_type_timelines):\n",
    "  # Calculate statistics using the modified function\n",
    "  stats = get_case_resolution_proportions(df, case_type_timelines)\n",
    "\n",
    "  # Pivot the data\n",
    "  pivot_table = stats.pivot_table(\n",
    "      index='court',\n",
    "      columns='broad_case_type',\n",
    "      values=['total_cases', 'resolved_within_timeline', 'proportion_resolved']\n",
    "  )\n",
    "\n",
    "  # Flatten the column hierarchy\n",
    "  pivot_table.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_table.columns]\n",
    "\n",
    "  return pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_222326/830036084.py:2: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  raw_df = pd.read_csv(f'{file_path}API/Hc/hc_23-24_data.csv')\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/stanoo/dcrt/data/'\n",
    "raw_df = pd.read_csv(f'{file_path}API/Hc/hc_23-24_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#rename court_name columns to court\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# where the sheduled/next date is outside the evaluation period\u001b[39;00m\n\u001b[1;32m      3\u001b[0m cutoff_date \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mTimestamp(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2024-06-30\u001b[39m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m----> 4\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourt_name\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcourt\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[1;32m      5\u001b[0m raw_df \u001b[38;5;241m=\u001b[39m create_date_column(raw_df\u001b[38;5;241m.\u001b[39mcopy(), [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_dd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_mon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_yyyy\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity_date\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m raw_df \u001b[38;5;241m=\u001b[39m create_date_column(raw_df\u001b[38;5;241m.\u001b[39mcopy(), [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiled_dd\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiled_mon\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiled_yyyy\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfiled_date\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "#rename court_name columns to court\n",
    "# where the sheduled/next date is outside the evaluation period\n",
    "cutoff_date = pd.Timestamp('2024-06-30') \n",
    "df = df.rename(columns={'court_name': 'court'})\n",
    "raw_df = create_date_column(raw_df.copy(), ['date_dd', 'date_mon', 'date_yyyy'], 'activity_date')\n",
    "raw_df = create_date_column(raw_df.copy(), ['filed_dd', 'filed_mon', 'filed_yyyy'], 'filed_date')\n",
    "raw_df = create_date_column(raw_df.copy(), ['next_dd', 'next_mon','next_yyyy'], 'next_date')\n",
    "df = raw_df.copy()\n",
    "\n",
    "df = drop_nan_columns(df, ['date_dd', 'date_mon', 'date_yyyy', 'caseid_type', 'caseid_no',\n",
    "       'filed_dd', 'filed_mon', 'filed_yyyy', 'case_type', 'comingfor'])\n",
    "\n",
    "df = remove_duplicates(df)\n",
    "#Apply title case to the outcomes column\n",
    "df = process_outcome_column(df)\n",
    "# missing outcomes\n",
    "df = drop_null_values(df)\n",
    "# Add broad case category of civil and criminal\n",
    "df = categorize_cases(df, CRIMINAL_CASES)\n",
    "# Add case number to the data\n",
    "df = generate_case_num(df, 'court', 'caseid_type', 'caseid_no', 'filed_yyyy')\n",
    "# Add filed and resolved outcomes\n",
    "df = process_case_status(df, RESOLVED_OUTCOMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add sojar case groupings\n",
    "df['broad_case_type'] = df['case_type'].apply(lambda x: apply_dict(x, BROAD_CASE_TYPES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove whitespace and rename terminated \n",
    "df['outcome'] = df['outcome'].str.strip()\n",
    "df['outcome'] = df['outcome'].replace('Terminated/ Struck Out/ Dismissed/Case Closed', 'Terminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to create a new column with keys\n",
    "df['productivity'] = df['outcome'].apply(lambda x: apply_dict(x, MERIT_CATEGORY))\n",
    "# Add the age column \n",
    "df['age'] = (df['activity_date'] - df['filed_date']).dt.days\n",
    "# Add time lines\n",
    "df['time_lines'] = df.apply(lambda row: check_time_limit(row['age'], row['broad_case_type'], row['concluded'], HC_PMMU_TIME_LINES), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leading and trailing spaces on comingfor\n",
    "df['comingfor'] = df['comingfor'].str.strip()\n",
    "\n",
    "# create a new column of 1 if reason_adj is not null and comingfor is not in non_adjourned else 0\n",
    "df['adjourned'] = (df['reason_adj'].notnull() & df['comingfor'].apply(lambda x: x not in NON_ADJOURNABLE)).astype(int)\n",
    "# an event is adjournable if non_adjourned is not in comingfor\n",
    "df['adjournable'] = df['comingfor'].apply(lambda x: x not in NON_ADJOURNABLE).astype(int)\n",
    "\n",
    "# transferred\n",
    "df['transfer'] = df['outcome'].apply(lambda x: x in TRANSFERED_CASES)\n",
    "\n",
    "df['productivity_category'] = df.apply(\n",
    "    lambda row: 'merit' if row['outcome'] in MERIT_OUTCOMES and row['concluded'] == 1 \n",
    "    else 'non-merit' if row['outcome'] not in MERIT_OUTCOMES and row['concluded'] == 1 \n",
    "    else None, axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data for output\n",
    "filed_cases = analyze_court_outcomes(df, '2023-07-01', '2024-06-30', 'registered')\n",
    "resolved_cases = analyze_court_outcomes(df, '2023-07-01', '2024-06-30', 'concluded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count  filed_cases\n",
    "\n",
    "monthly_filed_cases = df.groupby(['court','date_mon']).agg({'registered':'sum'}).reset_index()\n",
    "monthly_concluded_cases = df.groupby(['court','date_mon']).agg({'concluded':'sum'}).reset_index()\n",
    "concluded_cases = df.groupby('court').agg({'concluded':'sum'}).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_time_to_conclude = df.loc[df['concluded'] == 1].pivot_table(index='court', columns='nature', values='age', aggfunc='mean', fill_value=0).round(2)\n",
    "pmmu_timelines = df[df['time_lines'] == 1].pivot_table(index='court', columns='broad_case_type', values='time_lines', aggfunc='count', fill_value=0)\n",
    "total_concluded_per_court = df[df['concluded'] == 1].pivot_table(index='court', columns='broad_case_type', values='time_lines', aggfunc='count', fill_value=0)\n",
    "resolved_within_pmmu_timeline = pmmu_timelines / total_concluded_per_court\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "court_productivity = df.pivot_table(index='court', columns='productivity', values='concluded', aggfunc='count', fill_value=0)\n",
    "court_productivity = court_productivity.rename_axis(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "productivity_pivot_table = pd.pivot_table(\n",
    "    df,\n",
    "    values='concluded',  \n",
    "    index='court',     \n",
    "    columns='productivity_category', \n",
    "    aggfunc='count',   \n",
    "    fill_value=0        \n",
    ").rename(columns={'merit': 'Merit', 'non-merit': 'Non_Merit'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new column of 1 if reason_adj is not null and comingfor is not in non_adjourned else 0\n",
    "df['adjourned'] = (df['reason_adj'].notnull() & df['comingfor'].apply(lambda x: x not in NON_ADJOURNABLE)).astype(int)\n",
    "# an event is adjournable if non_adjourned is not in comingfor\n",
    "df['adjournable'] = df['comingfor'].apply(lambda x: x not in NON_ADJOURNABLE).astype(int)\n",
    "adjourned_per_court = df.groupby(['court', 'reason_adj'])['adjourned'].sum().reset_index(name='count')\n",
    "adjourned = df.groupby('court')['adjourned'].sum().reset_index(name='total_adjourned')\n",
    "adjournable = df.groupby('court')['adjournable'].sum().reset_index(name='total_adjournable')\n",
    "# deternine the rate of adjournments\n",
    "adjourn_proportion = pd.merge(adjourned, adjournable, on=['court'])\n",
    "adjourn_proportion['adjourn_proportion'] = (adjourn_proportion['total_adjourned']/adjourn_proportion['total_adjournable'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove trailing on judge names\n",
    "judge_names['judge_1'] = judge_names['judge_1'].str.strip()\n",
    "# create dataframe of judges only\n",
    "judge_df = df[df['judge_1'].isin(judge_names['judge_1'])]\n",
    "judge_productivity = judge_df.pivot_table(index='judge_1', columns='productivity', values='concluded', aggfunc='sum', fill_value=0)\n",
    "judge_productivity = judge_productivity.rename_axis(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have df and case_type_timelines\n",
    "pivot_table = create_pivot_table(df, case_type_timelines)\n",
    "judgement_df = determine_judgment_scheduling(df, cutoff_date)\n",
    "proportions = get_on_time_delivery_proportions(judgement_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "CRIMINAL_CASES = [\n",
    "    'Murder Case',\n",
    "    'Criminal Revision',\n",
    "    'Criminal Appeal',\n",
    "    'Murder - Gender Justice Criminal Case',\n",
    "    'Criminal Court Martial Appeal',\n",
    "    'Anti-Corruption and Economic Crimes Revision',\n",
    "    'Criminal Miscellaneous Application',\n",
    "    'Criminal Applications', \n",
    "    'COA Criminal Appeal'\n",
    "]\n",
    "BROAD_CASE_TYPES = {\n",
    "    'Civil Suit': [\n",
    "        'Civil Suit',\n",
    "        'Anti-Corruption and Economic Crimes Suit',\n",
    "        'Family Originating Summons',\n",
    "        'Family Civil Case',\n",
    "        'HCC(OS) Family',\n",
    "        'Commercial Admiralty',\n",
    "        'Commercial Matters',\n",
    "    ],\n",
    "    \n",
    "    'Adoption': 'Family Adoption',\n",
    "    'Divorce': 'Family Divorce Cause',\n",
    "\n",
    "    'Criminal Application': 'Criminal Miscellaneous Application',\n",
    "\n",
    "    'Miscellaneous Application': [\n",
    "        'Civil Case Miscellaneous',\n",
    "        'Judicial Review Miscellaneous',\n",
    "        'JR  Petition Miscellaneous',\n",
    "        'Anti-Corruption and Economic Crimes Miscellaneous',\n",
    "        'Commercial Miscellaneous',\n",
    "        'Constitution and Human Rights Petitions Miscellaneous',\n",
    "        'Family Miscellaneous',\n",
    "        'Commercial Arbitration',\n",
    "    ],\n",
    "    'Judicial Review': [\n",
    "        'Anti-Corruption and Economic Crime Judicial review',\n",
    "        'Judicial Review ELC',\n",
    "        'Judicial Review',\n",
    "    ],\n",
    "    'Criminal Revision': [\n",
    "        'Criminal Revision',\n",
    "        'Anti-Corruption and Economic Crimes Revision',\n",
    "    ],\n",
    "    'Criminal Appeal': [\n",
    "        'Criminal Appeal',\n",
    "        'Criminal Court Martial Appeal',\n",
    "        'Anti-Corruption and Economic Crimes Appeal',\n",
    "    ],\n",
    "    'Civil Appeal': [\n",
    "        'Family Appeal',\n",
    "        'Civil Appeal',\n",
    "        'Commercial Appeal',\n",
    "        'Constitution and Human Rights Election Petition Appeal',\n",
    "        'Constitution and Human Rights Petition Appeal',\n",
    "        'Constitution and Human Rights Election Petition Appeal',\n",
    "        'Gender Justice Civil Appeal',\n",
    "        'Constitution and Human Rights Miscellaneous Election Petition Appeal (MEPA)',\n",
    "    ],\n",
    "    'Constitution Petition': [\n",
    "        'Anti Corruption and Economic Crimes Petition',\n",
    "        'High Court Criminal Petition',\n",
    "        'Constitution and Human Rights Petition (Civil)',\n",
    "        'Constitution and Human Rights Election Petition',\n",
    "        'High Court Constitution and Human Rights Petitions (Criminal)',\n",
    "        'Commercial Petition',\n",
    "    ],\n",
    "    'Probate Administration': [\n",
    "        'Family P&A Intestate',\n",
    "        'Family P&A Ad Litem',\n",
    "        'Family P&A Ad Colligenda',\n",
    "        'Family P&A Citation',\n",
    "        'Family P&A Testate',\n",
    "        'Family P&A Resealing of Grant',\n",
    "        'Family P&A De Bonis Non',\n",
    "        'Resealing of Grant',\n",
    "        'Citation-Family',\n",
    "    ],\n",
    "    'Murder': [\n",
    "        'Murder Case',\n",
    "        'Murder - Gender Justice Criminal Case',\n",
    "    ],\n",
    "    'Tax Appeal': [\n",
    "        'Commercial Income Tax Apperiod_startpeal',\n",
    "        'Commercial Custom Tax Appeal',\n",
    "    ],\n",
    "    'Bankruptcy and Insolvency' : [\n",
    "        'Commercial Insolvency Notice Petition',\n",
    "        'Commercial Insolvency Petition',\n",
    "        'Commercial Bankruptcy Notice',\n",
    "        'Commercial Insolvency Cause',\n",
    "        'Commercial Insolvency Notice',\n",
    "        'Commercial Bankruptcy Cause',\n",
    "        'Commercial Winding Up Cause',\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "RESOLVED_OUTCOMES = ['Ruling Delivered- Case Closed',\n",
    " 'Terminated',\n",
    " 'Matter Settled- Case Closed',\n",
    " 'Application Dismissed - Case Closed',\n",
    " 'Judgment Delivered- Case Closed',\n",
    " 'Matter Withdrawn',\n",
    " 'Application Allowed - Case Closed',\n",
    " 'Application Withdrawn - Case Closed',\n",
    " 'Judgment Delivered- Convicted',\n",
    " 'Placed In Probation',\n",
    " 'Dismissed',\n",
    " 'Judgment Delivered',\n",
    " 'Judgment Delivered- Acquittal',\n",
    " 'Ruling Delivered- Accused Discharged',\n",
    " 'Abated',\n",
    " 'Consolidated- Case Closed',\n",
    " 'Grant Confirmed',\n",
    " 'Limited Grant Issued',\n",
    " 'Struck Out',\n",
    " 'Grant Revoked',\n",
    " 'Consent Recorded - Case Closed',\n",
    " 'Dismissed For Want Of Prosecution - Case Closed',\n",
    " 'Out Of Court Settlement Reached',\n",
    " 'Appeal Dismissed',\n",
    " 'Retrial',\n",
    " 'Appeal Rejected',\n",
    " 'Sentence Commuted',\n",
    " 'Ruling Delivered- Application Closed',\n",
    " 'Probation Orders Issued',\n",
    " 'Order Issued - Case Closed',\n",
    " 'Revision Declined']\n",
    "\n",
    "\n",
    "TRANSFERED_CASES = ['File Transfered -case Closed', \n",
    "        'File Transferred',]\n",
    "\n",
    "MERIT_CATEGORY = {\n",
    "    'Judgment Delivered': [\n",
    "        'Judgment Delivered- Case Closed',\n",
    "        'Judgment Delivered',\n",
    "        'Judgment Delivered- Acquittal',\n",
    "        'Judgment Delivered- Convicted',\n",
    "        'Grant Revoked',\n",
    "        'Retrial'\n",
    "        ],\n",
    "    'Ruling Case Closed': [\n",
    "        'Ruling Delivered- Case Closed', \n",
    "        'Ruling Delivered- Accused Discharged',\n",
    "        ],\n",
    "    'Final Grant': [\n",
    "        'Grant Confirmed',\n",
    "        'Limited Grant Issued',\n",
    "        ],\n",
    "    'Case Withdrawn': [\n",
    "        'Matter Withdrawn',\n",
    "        'Application Withdrawn - Case Closed',\n",
    "        ],\n",
    "   'Out Of Court Settlement': [\n",
    "        'Consent Recorded - Case Closed',\n",
    "        'Matter Settled Through Mediat26\tJun\t2024\tion',\n",
    "        'Out Of Court Settlement Reached',\n",
    "    ],\n",
    "    'Dismissed':[\n",
    "        'Dismissed For Want Of Prosecution - Case Closed',\n",
    "        'Dismissed',\n",
    "        'Appeal Dismissed',\n",
    "        'Terminated'\n",
    "    ],\n",
    "\n",
    "    'Case Closed': [\n",
    "        'Struck Out',\n",
    "        'Application Dismissed - Case Closed',\n",
    "        'Application Allowed - Case Closed',\n",
    "        'Matter Settled- Case Closed',\n",
    "        'Ruling Delivered- Application Closed',\n",
    "        'Consolidated- Case Closed',\n",
    "        'Abated',\n",
    "        'Placed In Probation',\n",
    "        'Revision Declined',\n",
    "        'Probation Orders Issued',\n",
    "        'Appeal Rejected',\n",
    "        'Interlocutory Judgement Entered',\n",
    "        'Order issued - Case closed'   \n",
    "    ],\n",
    "}\n",
    "\n",
    "HC_PMMU_TIME_LINES = {\n",
    "    'murder': 360,\n",
    "    'revision': 90,\n",
    "    'misc_application': 90,\n",
    "    'suit': 360,\n",
    "    'judicial_review': 180,\n",
    "    'constitutional_petition': 180,\n",
    "}\n",
    "\n",
    "NON_ADJOURNABLE = [\n",
    "    'Taxation and Issuance of Certificates',\n",
    "    'Orders',\n",
    "    'Appointments of  Mediator',\n",
    "    'Screening of files for Mediation',\n",
    "    'Post-judgment',\n",
    "    'Re-activation',\n",
    "    'Reactivation',\n",
    "    'Notice of Taxation',\n",
    "    'Entering Interlocutory Judgments',\n",
    "    'Approval by DR', \n",
    "    'Registration/Filing-Application', \n",
    "    'Registration/Filing', \n",
    "    'Registration/Filing-Application',\n",
    " ]\n",
    "MERIT_OUTCOMES = [\n",
    "    'Ruling Delivered- Case Closed', \n",
    "    'Judgment Delivered- Case Closed',\n",
    "    'Judgment Delivered',\n",
    "    'Judgment Delivered- Acquittal',\n",
    "    'Judgment Delivered- Convicted',\n",
    "    'Grant Revoked',\n",
    "    'Ruling Delivered- Accused Discharged',\n",
    "    'Retrial'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
