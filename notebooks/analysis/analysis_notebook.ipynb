{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List, Union, Optional\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_ADJOURNABLE = [\n",
    "    'Taxation and Issuance of Certificates',\n",
    "    'Orders',\n",
    "    'Appointments of  Mediator',\n",
    "    'Screening of files for Mediation',\n",
    "    'Post-judgment',\n",
    "    'Re-activation',\n",
    "    'Reactivation',\n",
    "    'Notice of Taxation',\n",
    "    'Entering Interlocutory Judgments',\n",
    "    'Approval by DR', \n",
    "    'Registration/Filing-Application', \n",
    "    'Registration/Filing', \n",
    "    'Registration/Filing-Application',\n",
    " ]\n",
    "RESOLVED_OUTCOMES = [\n",
    "    'Ruling Delivered- Case Closed', 'Grant Confirmed', 'Matter Withdrawn',\n",
    "    'Dismissed For Want Of Prosecution - Case Closed', 'Dismissed',\n",
    "    'Terminated/ Struck Out/ Dismissed/case Closed', 'Judgment Delivered- Case Closed',\n",
    "    'Application Allowed - Case Closed',\n",
    "    'Matter Settled- Case Closed', 'Consent Recorded - Case Closed',\n",
    "    'Judgment Delivered', 'Judgment Delivered- Acquittal',\n",
    "    'Judgment Delivered- Convicted', 'Application Withdrawn - Case Closed',\n",
    "    'Struck Out', 'Application Dismissed - Case Closed',\n",
    "    'Out Of Court Settlement Reached', 'Terminated',\n",
    "    'Ruling Delivered- Application Closed', 'Consolidated- Case Closed',\n",
    "    'Interlocutory Judgement Entered', 'Abated', 'Limited Grant Issued',\n",
    "    'Grant Revoked', 'Placed In Probation', 'Ruling Delivered- Accused Discharged',\n",
    "    'Revision Declined', 'Retrial', 'Probation Orders Issued',\n",
    "    'Matter Settled Through Mediation', 'Appeal Dismissed', 'Appeal Rejected', \n",
    "    'Order Issued - Case Closed',\n",
    "    'Terminated',\n",
    "    'Judgment Delivered- Aquittal',\n",
    "    'Taxation',\n",
    "    'Case Transferred To Nyeri High Court',\n",
    "    'Sentenced',\n",
    "    'Taxation Date Set',\n",
    "    'Dismissed (Under Order 17 Rule 2)',\n",
    "    'Matter Settled',\n",
    "    'File Transfered -Case Closed',\n",
    "    'Allowed',\n",
    "    'Application Allowed',\n",
    "    'Application Dismissed',\n",
    "    'Application Withdrawn',\n",
    "    'Case Closed',\n",
    "    'Grant Issued',\n",
    "\n",
    "]\n",
    "CRIMINAL_CASES = [\n",
    "    'Murder Case',\n",
    "    'Criminal Revision',\n",
    "    'Criminal Appeal',\n",
    "    'Murder - Gender Justice Criminal Case',\n",
    "    'Criminal Court Martial Appeal',\n",
    "    'Anti-Corruption and Economic Crimes Revision',\n",
    "    'Criminal Miscellaneous Application',\n",
    "    'Criminal Applications', \n",
    "    'COA Criminal Appeal'\n",
    "]\n",
    "BROAD_CASE_TYPES = {\n",
    "    'Civil Matter': [\n",
    "        'Civil Suit',\n",
    "        'Anti-Corruption and Economic Crimes Suit',\n",
    "        'Family Originating Summons',\n",
    "        'Family Civil Case',\n",
    "        'HCC(OS) Family',\n",
    "        'Commercial Admiralty',\n",
    "        'Commercial Matters',\n",
    "    ],\n",
    "    \n",
    "    'Adoption': 'Family Adoption',\n",
    "    'Divorce': 'Family Divorce Cause',\n",
    "\n",
    "    'Criminal Application': 'Criminal Miscellaneous Application',\n",
    "\n",
    "    'Civil Application': [\n",
    "        'Civil Case Miscellaneous',\n",
    "        'Judicial Review Miscellaneous',\n",
    "        'JR  Petition Miscellaneous',\n",
    "        'Anti-Corruption and Economic Crimes Miscellaneous',\n",
    "        'Commercial Miscellaneous',\n",
    "        'Constitution and Human Rights Petitions Miscellaneous',\n",
    "        'Family Miscellaneous',\n",
    "        'Commercial Arbitration',\n",
    "    ],\n",
    "    'Judicial Review': [\n",
    "        'Anti-Corruption and Economic Crime Judicial review',\n",
    "        'Judicial Review ELC',\n",
    "        'Judicial Review',\n",
    "    ],\n",
    "    'Criminal Revision': [\n",
    "        'Criminal Revision',\n",
    "        'Anti-Corruption and Economic Crimes Revision',\n",
    "    ],\n",
    "    'Criminal Appeal': [\n",
    "        'Criminal Appeal',\n",
    "        'Criminal Court Martial Appeal',\n",
    "        'Anti-Corruption and Economic Crimes Appeal',\n",
    "    ],\n",
    "    'Civil Appeal': [\n",
    "        'Family Appeal',\n",
    "        'Civil Appeal',\n",
    "        'Commercial Appeal',\n",
    "        'Constitution and Human Rights Election Petition Appeal',\n",
    "        'Constitution and Human Rights Petition Appeal',\n",
    "        'Constitution and Human Rights Election Petition Appeal',\n",
    "        'Gender Justice Civil Appeal',\n",
    "        'Constitution and Human Rights Miscellaneous Election Petition Appeal (MEPA)',\n",
    "    ],\n",
    "    'Constitution Petition': [\n",
    "        'Anti Corruption and Economic Crimes Petition',\n",
    "        'High Court Criminal Petition',\n",
    "        'Constitution and Human Rights Petition (Civil)',\n",
    "        'Constitution and Human Rights Election Petition',\n",
    "        'High Court Constitution and Human Rights Petitions (Criminal)',\n",
    "        'Commercial Petition',\n",
    "    ],\n",
    "    'Probate Administration': [\n",
    "        'Family P&A Intestate',\n",
    "        'Family P&A Ad Litem',\n",
    "        'Family P&A Ad Colligenda',\n",
    "        'Family P&A Citation',\n",
    "        'Family P&A Testate',\n",
    "        'Family P&A Resealing of Grant',\n",
    "        'Family P&A De Bonis Non',\n",
    "        'Resealing of Grant',\n",
    "        'Citation-Family',\n",
    "    ],\n",
    "    'Murder': [\n",
    "        'Murder Case',\n",
    "        'Murder - Gender Justice Criminal Case',\n",
    "    ],\n",
    "    'Tax Appeal': [\n",
    "        'Commercial Income Tax Appeal',\n",
    "        'Commercial Custom Tax Appeal',\n",
    "    ],\n",
    "    \n",
    "    'Bankruptcy and Insolvency' : [\n",
    "        'Commercial Insolvency Notice Petition',\n",
    "        'Commercial Insolvency Petition',\n",
    "        'Commercial Bankruptcy Notice',\n",
    "        'Commercial Insolvency Cause',\n",
    "        'Commercial Insolvency Notice',\n",
    "        'Commercial Bankruptcy Cause',\n",
    "        'Commercial Winding Up Cause',\n",
    "    ]\n",
    "}\n",
    "\n",
    "MERIT_CATEGORY ={\n",
    "    'Merit Resolution' : [    \n",
    "    'Ruling Delivered- Case Closed', \n",
    "    'Judgment Delivered- Case Closed',\n",
    "    'Judgment Delivered', \n",
    "    'Judgment Delivered- Acquittal',\n",
    "    'Judgment Delivered- Convicted',\n",
    "    'Ruling Delivered- Application Closed',\n",
    "    'Retrial',\n",
    "    'Appeal Dismissed',\n",
    "    'Grant Revoked',\n",
    "],\n",
    "'Non Merit Resolution': [\n",
    "    'Grant Confirmed', \n",
    "    'Matter Withdrawn',\n",
    "    'Dismissed For Want Of Prosecution - Case Closed',\n",
    "    'Dismissed',\n",
    "    'Terminated/ Struck Out/ Dismissed/case Closed', \n",
    "    'Application Allowed - Case Closed',\n",
    "    'Matter Settled- Case Closed', \n",
    "    'Consent Recorded - Case Closed',\n",
    "    'Application Withdrawn - Case Closed',\n",
    "    'Struck Out', \n",
    "    'Application Dismissed - Case Closed',\n",
    "    'Out Of Court Settlement Reached', \n",
    "    'Terminated',\n",
    "    'Consolidated- Case Closed',\n",
    "    'Interlocutory Judgement Entered', \n",
    "    'Abated', \n",
    "    'Limited Grant Issued',\n",
    "    'Placed In Probation', \n",
    "    'Revision Declined',  \n",
    "    'Probation Orders Issued',\n",
    "    'Matter Settled Through Mediation', \n",
    "    'Appeal Rejected', \n",
    "    'Order Issued - Case Closed',\n",
    "    'Terminated',\n",
    "    'Ruling Delivered- Accused Discharged',\n",
    "    'File Transfered -case Closed', \n",
    "        'File Transferred',\n",
    "    ]\n",
    "} \n",
    "\n",
    "\n",
    "PRODUCTIVITY = {\n",
    "    'Judgment Delivered': [\n",
    "        'Judgment Delivered- Case Closed',\n",
    "        'Judgment Delivered',\n",
    "        'Judgment Delivered- Acquittal',\n",
    "        'Judgment Delivered- Convicted',\n",
    "        'Grant Revoked',\n",
    "        'Retrial'\n",
    "        ],\n",
    "    'Ruling Case Closed': [\n",
    "        'Ruling Delivered- Case Closed', \n",
    "        'Ruling Delivered- Accused Discharged',\n",
    "        ],\n",
    "    'Final Grant': [\n",
    "        'Grant Confirmed',\n",
    "        'Limited Grant Issued',\n",
    "        ],\n",
    "    'Case Withdrawn': [\n",
    "        'Matter Withdrawn',\n",
    "        'Application Withdrawn - Case Closed',\n",
    "        ],\n",
    "   'Out Of Court Settlement': [\n",
    "        'Consent Recorded - Case Closed',\n",
    "        'Matter Settled Through Mediation',\n",
    "        'Out Of Court Settlement Reached',\n",
    "    ],\n",
    "    'Dismissed':[\n",
    "        'Dismissed For Want Of Prosecution - Case Closed',\n",
    "        'Dismissed',\n",
    "        'Appeal Dismissed',\n",
    "        'Terminated',\n",
    "        'Terminated/ Struck Out/ Dismissed/case Closed',\n",
    "    ],\n",
    "    'Case Transfered': [\n",
    "        'File Transfered -case Closed',\n",
    "        'File Transferred',\n",
    "    ],\n",
    "    'Case Closed': [\n",
    "        'Struck Out',\n",
    "        'Application Dismissed - Case Closed',\n",
    "        'Application Allowed - Case Closed',\n",
    "        'Matter Settled- Case Closed',\n",
    "        'Ruling Delivered- Application Closed',\n",
    "        'Consolidated- Case Closed',\n",
    "        'Abated',\n",
    "        'Placed In Probation',\n",
    "        'Revision Declined',\n",
    "        'Probation Orders Issued',\n",
    "        'Appeal Rejected',\n",
    "        'Interlocutory Judgement Entered',\n",
    "    ],\n",
    "}\n",
    "\n",
    "HC_PMMU_TIME_LINES = {\n",
    "    'Murder': 360, \n",
    "    'Constitution Petition': 360, \n",
    "    'Criminal Revision': 180, \n",
    "    'Judicial Review': 360, \n",
    "    'Civil Matter': 360,\n",
    "    'Anti Corruption': 360,\n",
    "    'Income Tax Appeal': 180,\n",
    "    'Matrimonial Property': 360,\n",
    "    'Succession': 180,\n",
    "}\n",
    "\n",
    "TRANSFERED_CASES = ['File Transfered -case Closed', \n",
    "        'File Transferred',]\n",
    "\n",
    "MERIT_OUTCOMES = [\n",
    "    'Ruling Delivered- Case Closed', \n",
    "    'Judgment Delivered- Case Closed',\n",
    "    'Judgment Delivered',\n",
    "    'Judgment Delivered- Acquittal',\n",
    "    'Judgment Delivered- Convicted',\n",
    "    'Grant Revoked',\n",
    "    'Ruling Delivered- Accused Discharged',\n",
    "    'Retrial'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_columns(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows containing NaN values from the specified columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to process.\n",
    "        columns (List[str]): A list of column names to check for NaN values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with NaN-containing rows dropped.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any of the specified columns are not present in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Validate that all specified columns exist in the DataFrame\n",
    "    missing_columns = set(columns) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Columns not found in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Identify columns with NaN values\n",
    "    nan_columns = df[columns].columns[df[columns].isna().any()].tolist()\n",
    "\n",
    "    # Log dropped rows if any\n",
    "    if nan_columns:\n",
    "        nan_count = df[columns].isna().sum()\n",
    "        logger.info(\"Dropping rows with NaN values:\")\n",
    "        for col in nan_columns:\n",
    "            logger.info(f\"  {col}: {nan_count[col]} rows\")\n",
    "\n",
    "    # Drop rows with NaN values in specified columns\n",
    "    original_row_count = len(df)\n",
    "    df_cleaned = df.dropna(subset=columns)\n",
    "    dropped_row_count = original_row_count - len(df_cleaned)\n",
    "\n",
    "    if dropped_row_count > 0:\n",
    "        logger.info(f\"Total rows dropped: {dropped_row_count}\")\n",
    "    else:\n",
    "        logger.info(\"No rows were dropped.\")\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove duplicates from a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    num_duplicates = data.duplicated().sum()\n",
    "    \n",
    "    if num_duplicates > 0:\n",
    "        logging.info(f\"{num_duplicates} duplicates found.\")\n",
    "        data = data.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "        logging.info(f\"{num_duplicates} duplicates removed.\")\n",
    "    else:\n",
    "        logging.info(\"No duplicates found.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_date_column(df: pd.DataFrame, column_names: List[str], new_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a new date column in the DataFrame by concatenating the values of three specified columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_names (List[str]): A list of three column names to be concatenated [year, month, day].\n",
    "        new_col (str): The import commandsname of the new date column to be created.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new date column added.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input list doesn't contain exactly three column names or if columns are missing.\n",
    "    \"\"\"\n",
    "    if len(column_names) != 3:\n",
    "        raise ValueError(\"column_names must contain exactly three elements: [year, month, day]\")\n",
    "\n",
    "    year_col, month_col, day_col = column_names\n",
    "\n",
    "    # Check if all required columns exist in the DataFrame\n",
    "    missing_columns = set(column_names) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Create copies to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "\n",
    "    try:\n",
    "        # Convert year and day columns to integers\n",
    "        df[year_col] = df[year_col].astype(float).astype(int)\n",
    "        df[day_col] = df[day_col].astype(float).astype(int)\n",
    "\n",
    "        # Concatenate the columns to create a date string\n",
    "        df[new_col] = (df[year_col].astype(str) + '-' + \n",
    "                       df[month_col].astype(str) + '-' + \n",
    "                       df[day_col].astype(str))\n",
    "\n",
    "        # Convert to datetime\n",
    "        df[new_col] = pd.to_datetime(df[new_col], errors='coerce')\n",
    "\n",
    "        # Log information about the conversion\n",
    "        valid_dates = df[new_col].notna().sum()\n",
    "        logger.info(f\"Created new date column '{new_col}'. Valid dates: {valid_dates}/{len(df)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating date column: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_dataframe_columns(df):\n",
    "    \"\"\"Strips leading and trailing whitespace from all columns in a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The modified DataFrame with stripped columns.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df = df.astype(str).apply(lambda x: x.str.strip())\n",
    "        logger.info(\"str.strip() applied successfully to all columns.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error applying str.strip(): {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_title_case(text):\n",
    "    \"\"\"\n",
    "    Apply title case to a given string.\n",
    "    \n",
    "    Args:\n",
    "        text: The input string to process.\n",
    "    \n",
    "    Returns:\n",
    "        str: The processed string in title case.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    if not isinstance(text, str):\n",
    "        logger.warning(f\"Non-string value encountered: {text}\")\n",
    "        return str(text)\n",
    "    return text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_title_case(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the 'outcome' column of the DataFrame by applying title case.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing the 'outcome' column.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the processed 'outcome' column.\n",
    "    \"\"\"\n",
    "    if 'outcome' not in df.columns:\n",
    "        logger.error(\"'outcome' column not found in the DataFrame\")\n",
    "        return df\n",
    "\n",
    "    original_null_count = df[column].isnull().sum()\n",
    "    \n",
    "    df['outcome'] = df[column].apply(apply_title_case)\n",
    "    \n",
    "    new_null_count = df[column].isnull().sum()\n",
    "    if new_null_count > original_null_count:\n",
    "        logger.warning(f\"Number of null values in 'outcome' increased from {original_null_count} to {new_null_count}\")\n",
    "    \n",
    "    non_string_count = df[column].apply(lambda x: not isinstance(x, str) if pd.notna(x) else False).sum()\n",
    "    if non_string_count > 0:\n",
    "        logger.warning(f\"Found {non_string_count} non-string values in 'outcome' after processing\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_values(df: pd.DataFrame, column_name: str = 'outcome') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows from the DataFrame where the specified column contains null values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame from which to drop rows.\n",
    "        column_name (str): The name of the column to check for null values. Default is 'outcome'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with rows containing null values in the specified column dropped.\n",
    "    \"\"\"\n",
    "    initial_row_count: int = df.shape[0]\n",
    "    cleaned_df: pd.DataFrame = df.dropna(subset=[column_name])\n",
    "    final_row_count: int = cleaned_df.shape[0]\n",
    "    dropped_row_count: int = initial_row_count - final_row_count\n",
    "    \n",
    "    if dropped_row_count > 0:\n",
    "        logger.info(f\"Total dropped rows with null values in '{column_name}': {dropped_row_count}\")\n",
    "    else:\n",
    "        logger.info(f\"No rows dropped with null values in '{column_name}'\")\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_case(case_type: str, criminal_cases: Optional[List[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Categorize a case as 'Criminal' or 'Civil' based on its type.\n",
    "    \n",
    "    Args:\n",
    "        case_type (str): The type of the case.\n",
    "        criminal_cases (Optional[List[str]]): List of case types considered as criminal.\n",
    "        \n",
    "    Returns:\n",
    "        str: 'Criminal' if the case type is in the criminal cases list or if criminal_cases is None, 'Civil' otherwise.\n",
    "    \"\"\"\n",
    "    if criminal_cases is None:\n",
    "        return 'Criminal'\n",
    "    else:\n",
    "        return 'Criminal' if case_type in criminal_cases else 'Civil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_cases(df: pd.DataFrame, criminal_cases: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Categorize all cases in the DataFrame as 'Criminal' or 'Civil'.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case data.\n",
    "        criminal_cases (Optional[List[str]]): List of case types considered as criminal.\n",
    "            If None, all cases are categorized as 'Criminal'.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an added 'nature' column indicating case nature.\n",
    "    \"\"\"\n",
    "    df['nature'] = df['case_type'].apply(lambda x: categorize_case(x, criminal_cases))\n",
    "\n",
    "    # Check for presence of both case types\n",
    "    if 'Criminal' not in df['nature'].values:\n",
    "        logging.warning(\"No criminal cases found in the DataFrame.\")\n",
    "    if 'Civil' not in df['nature'].values:\n",
    "        logging.warning(\"No civil cases found in the DataFrame.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dict(value: Any, dictionary: Dict[str, Union[str, List[Any]]]) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Find all keys in a dictionary where the given value matches.\n",
    "\n",
    "    Args:\n",
    "        value: The value to search for.\n",
    "        dictionary: The dictionary to search in.\n",
    "\n",
    "    Returns:\n",
    "        A list of keys where the value matches, or None if no matches are found.\n",
    "    \"\"\"\n",
    "    matching_keys = []\n",
    "    for key, dict_value in dictionary.items():\n",
    "        if isinstance(dict_value, str) and dict_value == value:\n",
    "            matching_keys.append(key)\n",
    "        elif isinstance(dict_value, list) and value in dict_value:\n",
    "            matching_keys.append(key)\n",
    "    \n",
    "    if not matching_keys:\n",
    "        return None\n",
    "    elif len(matching_keys) == 1:\n",
    "        return matching_keys[0]\n",
    "    else:\n",
    "        return matching_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_case_num(df: pd.DataFrame, caseid_type_col: str, caseid_no_col: str, filed_yyyy_col: str, new_col='case_number') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a case number by concatenating court, caseid_type, caseid_no, and filed_yyyy columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the necessary columns.\n",
    "        court_col (str): The name of the column containing court information.\n",
    "        caseid_type_col (str): The name of the column containing case ID type.\n",
    "        caseid_no_col (str): The name of the column containing case ID number.\n",
    "        filed_yyyy_col (str): The name of the column containing the year the case was filed.\n",
    "        new_col (str): The name of the new column to be created for the case number. Default is 'case_num'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the new case number column.\n",
    "    \"\"\"\n",
    "    df[new_col] = df[caseid_type_col] + '/' + df[caseid_no_col] + '/' + df[filed_yyyy_col].astype(str)\n",
    "    return df\n",
    "\n",
    "def is_concluded(outcome: str, resolved_outcomes: List[str]) -> int:\n",
    "    \"\"\"\n",
    "    Determine if the case is concluded based on the outcome.\n",
    "    \n",
    "    Args:\n",
    "        outcome (str): The outcome of the case.\n",
    "        resolved_outcomes (List[str]): List of outcomes considered as resolved.\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if the case outcome is resolved, 0 otherwise.\n",
    "    \"\"\"\n",
    "    return 1 if outcome in resolved_outcomes else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_case_registered(outcome: str, activity_date: Union[pd.Timestamp, str], filed_date: Union[pd.Timestamp, str]) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if a case is registered based on its outcome and dates.\n",
    "\n",
    "    Args:\n",
    "        outcome (str): The outcome of the case.\n",
    "        activity_date (Union[pd.Timestamp, str]): The date of the activity.\n",
    "        filed_date (Union[pd.Timestamp, str]): The date the case was filed.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the case is registered, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Normalize the outcome string\n",
    "        normalized_outcome = outcome.strip().lower()\n",
    "\n",
    "        # Check if the outcome indicates registration\n",
    "        is_registered_outcome = 'case registered/filed' in normalized_outcome \n",
    "\n",
    "        # Convert dates to pd.Timestamp if they're strings\n",
    "        if isinstance(activity_date, str):\n",
    "            activity_date = pd.to_datetime(activity_date, errors='coerce')\n",
    "        if isinstance(filed_date, str):\n",
    "            filed_date = pd.to_datetime(filed_date, errors='coerce')\n",
    "\n",
    "        # Check if dates are equal\n",
    "        dates_match = pd.notna(activity_date) and pd.notna(filed_date) and activity_date == filed_date\n",
    "\n",
    "        is_registered = is_registered_outcome and dates_match\n",
    "\n",
    "        if is_registered:\n",
    "            logger.debug(f\"Case registered: outcome='{outcome}', activity_date={activity_date}, filed_date={filed_date}\")\n",
    "        \n",
    "        return is_registered\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in is_case_registered: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_case_status(df: pd.DataFrame, resolved_outcome: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the DataFrame to add 'concluded' and 'registered' columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case information.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with added 'concluded' and 'registered' columns.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If required columns are missing from the DataFrame.\n",
    "    \"\"\"\n",
    "    required_columns = ['outcome', 'activity_date', 'filed_date']\n",
    "    missing_columns = set(required_columns) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
    "\n",
    "    #df['concluded'] = df['outcome'].apply(is_case_concluded)\n",
    "    df['concluded'] = df['outcome'].apply(lambda x: is_concluded(x, resolved_outcome))\n",
    "    df['registered'] = df.apply(lambda row: is_case_registered(row['outcome'], row['activity_date'], row['filed_date']), axis=1)\n",
    "\n",
    "    logger.info(f\"Processed {len(df)} cases\")\n",
    "    logger.info(f\"Concluded cases: {df['concluded'].sum()}\")\n",
    "    logger.info(f\"Registered cases: {df['registered'].sum()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_court_outcomes(df: pd.DataFrame, start_date: str, end_date: str, outcome: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the number of case outcomes per court within a specified period.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): A pandas DataFrame containing the data.\n",
    "        start_date (str): The starting date of the period (YYYY-MM-DD format).\n",
    "        end_date (str): The ending date of the period (YYYY-MM-DD format).\n",
    "        outcome (str): A column representing the outcome of interest.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame showing the number of resolved cases per court and case category.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        period_start = pd.to_datetime(start_date)\n",
    "        period_end = pd.to_datetime(end_date)\n",
    "        \n",
    "        if period_start > period_end:\n",
    "            raise ValueError(\"start_date must be earlier than end_date\")\n",
    "        \n",
    "        required_columns = {'court', 'broad_case_type', 'activity_date', outcome}\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            missing_columns = required_columns - set(df.columns)\n",
    "            raise KeyError(f\"Missing required columns: {missing_columns}\")\n",
    "        \n",
    "        filtered_cases = df[\n",
    "            (df['activity_date'] >= period_start) &\n",
    "            (df['activity_date'] <= period_end) &\n",
    "            (df[outcome] == 1)\n",
    "        ]\n",
    "        \n",
    "        if filtered_cases.empty:\n",
    "            logging.warning(\"No cases found for the given date range and outcome.\")\n",
    "   \n",
    "        outcome_by_type = (\n",
    "            filtered_cases\n",
    "            .groupby(['court', 'broad_case_type'])\n",
    "            .size()\n",
    "            .reset_index(name='num_cases')\n",
    "        )\n",
    "\n",
    "        result = outcome_by_type.pivot_table(\n",
    "            index='court', \n",
    "            columns='broad_case_type', \n",
    "            values='num_cases', \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        logging.info(\"Successfully calculated case outcomes per court.\")\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time_limit(age, case_category, concluded, time_lines):\n",
    "    \"\"\"\n",
    "    Check if a case falls within the specified time limit for its category and is concluded.\n",
    "    \n",
    "    Parameters:\n",
    "        age (int): The age of the case in days.\n",
    "        case_category (str): The category of the case.\n",
    "        concluded (int): The status of the case conclusion (1 for concluded, 0 otherwise).\n",
    "        time_lines (dict): A dictionary with case categories as keys and time limits as values.\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if the case is within the time limit and concluded, otherwise 0.\n",
    "    \"\"\"\n",
    "    time_limit = time_lines.get(case_category, 0)\n",
    "    return 1 if age <= time_limit and concluded == 1 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of multiple resolved outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the priority order\n",
    "priority_order = [\n",
    "    'Judgment Delivered- Case Closed',\n",
    "    'Judgment Delivered',\n",
    "    'Judgment Delivered- Acquittal',\n",
    "    'Judgment Delivered- Convicted',\n",
    "    'Grant Revoked',\n",
    "    'Ruling Delivered- Case Closed',\n",
    "    'Ruling Delivered- Accused Discharged'\n",
    "]\n",
    "\n",
    "# Create a priority mapping for efficient lookups\n",
    "priority_mapping = {value: index for index, value in enumerate(priority_order)}\n",
    "\n",
    "def get_resolved_cases_by_court(df, outcome_col='outcome', court_col='court'):\n",
    "    # Assign priority to each row based on the outcome\n",
    "    df['priority'] = df[outcome_col].map(priority_mapping)\n",
    "    \n",
    "    # Filter rows with resolved cases\n",
    "    resolved_cases = df[df['priority'].notna()]\n",
    "    \n",
    "    # Drop duplicates to ensure one outcome per case with the highest priority\n",
    "    resolved_cases = resolved_cases.sort_values(by='priority').drop_duplicates(subset=['case_number', court_col], keep='first')\n",
    "    \n",
    "    # Drop the priority column as it is no longer needed\n",
    "    resolved_cases = resolved_cases.drop(columns=['priority'])\n",
    "    \n",
    "    # Pivot the table\n",
    "    pivot_table = resolved_cases.pivot_table(index=court_col, columns=outcome_col, values='case_number', aggfunc='count', fill_value=0)\n",
    "    \n",
    "    return pivot_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data (modify file paths and separators as needed)\n",
    "df_a = pd.read_csv(\"master.csv\", sep='\\t', names=[\"master\"], header=0)\n",
    "df_b = pd.read_csv(\"mixed.csv\", sep='\\t', names=[\"mixed\"], header=0)\n",
    "import re\n",
    "\n",
    "def tokenize_name(name):\n",
    "    \"\"\"\n",
    "    Lowercases the name, removes non-alphanumeric characters except spaces,\n",
    "    and returns a frozenset of tokens (words).\n",
    "    \"\"\"\n",
    "    # Remove punctuation except spaces\n",
    "    name_clean = re.sub(r'[^\\w\\s]', '', name.lower())\n",
    "    # Split on whitespace\n",
    "    tokens = name_clean.split()\n",
    "    # Convert list to a frozenset so order doesn't matter\n",
    "    return frozenset(tokens)\n",
    "# --------------------------------------------------------------------\n",
    "# 1. Read your CSV. If it's truly tab-delimited, use sep='\\t'.\n",
    "#    Otherwise, adjust the separator accordingly.\n",
    "# --------------------------------------------------------------------\n",
    "judges_df = pd.read_csv(f'{file_path}/Judges.csv', header=0)\n",
    "# Drop empty values\n",
    "judges_df = judges_df.dropna(subset=[\"master\"])\n",
    "df = df.dropna(subset=[\"judge_1\"])\n",
    "# Create a set of tokenized master names\n",
    "master_tokens = set(judges_df[\"master\"].apply(tokenize_name))\n",
    "# Filter df_b to keep only rows where the mixed name matches a master name\n",
    "df_filtered = df[df[\"judge_1\"].apply(lambda x: tokenize_name(x) in master_tokens)]\n",
    "# Get unique names of judge_1 \n",
    "\n",
    "judges_name = df_filtered['judge_1'].unique().tolist()\n",
    "judges = pd.DataFrame(judges_name)\n",
    "judges.to_csv(f'{file_path}/judges.csv')\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 2. Build a set of tokenized names from the 'master' column.\n",
    "# --------------------------------------------------------------------\n",
    "master_tokens = set(tokenize_name(m) for m in df[\"master\"])\n",
    "\n",
    "# --------------------------------------------------------------------\n",
    "# 3. Filter rows where the 'mixed' name also appears in the master set\n",
    "#    (by token comparison).\n",
    "# --------------------------------------------------------------------\n",
    "mask = df[\"mixed\"].apply(lambda x: tokenize_name(x) in master_tokens)\n",
    "df_filtered = df[mask]\n",
    "\n",
    "# df_filtered now contains only the rows where the 'mixed' name\n",
    "# matches a 'master' name (ignoring order/punctuation).\n",
    "print(df_filtered)\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "def clean_name(name):\n",
    "    \"\"\"Lowercase and remove extra punctuation/spaces.\"\"\"\n",
    "    return re.sub(r'[^\\w\\s]', '', name.lower()).strip()\n",
    "from rapidfuzz import process, fuzz\n",
    "master_names = judges_df[\"master\"].unique().tolist()\n",
    "master_cleaned = [clean_name(m) for m in master_names]\n",
    "\n",
    "def is_match_fuzzy(mixed_name, threshold=57):\n",
    "    \"\"\"\n",
    "    Return True if 'mixed_name' matches any name in 'master_names'\n",
    "    with a fuzzy ratio >= threshold.\n",
    "    \"\"\"\n",
    "    # Clean the name\n",
    "    name_clean = clean_name(mixed_name)\n",
    "    # Find best fuzzy match among the master names\n",
    "    best_match = process.extractOne(name_clean, master_cleaned, scorer=fuzz.ratio)\n",
    "    # best_match looks like (matched_string, score, index)\n",
    "    if best_match and best_match[1] >= threshold:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "df_filtered_fuzzy = df[df[\"judge_1\"].apply(is_match_fuzzy)]\n",
    "df_filtered_fuzzy.groupby('judge_1')['judge_1'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/fiend/Documents'\n",
    "raw_df = pd.read_csv(f'{file_path}/nyahururu.csv')\n",
    "df = raw_df.set_axis(['caseid_type', 'case_type','caseid_no', 'activity_date'], axis=1)\n",
    "df['activity_date'] = pd.to_datetime(df['activity_date'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_case_num(raw_df, 'caseid_type', 'caseid_no', 'filed_yyyy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop row with missing values on raw_df['date_dd']\n",
    "df = df.dropna(subset=['date_dd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['outcome'] = df['outcome'].str.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_title_case(df, 'outcome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['outcome'] = df['outcome'].replace('Terminated/ Struck Out/ Dismissed/Case Closed', 'Terminated')\n",
    "#cutoff_date = pd.Timestamp('2024-06-30') \n",
    "#raw_df = raw_df.rename(columns={'court_name': 'court'})\n",
    "df = drop_nan_columns(df, ['date_dd', 'date_mon', 'date_yyyy'])\n",
    "df = create_date_column(df.copy(), ['date_dd', 'date_mon', 'date_yyyy'], 'activity_date')\n",
    "df = create_date_column(df.copy(), ['filed_dd', 'filed_mon', 'filed_yyyy'], 'filed_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = remove_duplicates(df)\n",
    "df = drop_null_values(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = df['outcome'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = strip_dataframe_columns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_case_status(df, RESOLVED_OUTCOMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort by case_number and activity_date\n",
    "df = df.sort_values(by=['activity_date', 'case_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['max_resolved'] = df.groupby('case_number')['concluded'].transform('max')\n",
    "# convert max_resolved to int\n",
    "df['max_resolved'] = df['max_resolved'].astype(int)\n",
    "# keep if max_resolved is not 1 \n",
    "pending_df = df[df['max_resolved'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_df = pending_df.drop_duplicates(subset=['case_number'], keep='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_df['activity_date'] = pd.to_datetime(pending_df['activity_date'], errors='coerce')\n",
    "pending_df['age'] = (pd.Timestamp.now() - pending_df['activity_date']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set concluded to 1 if outcome == \"Judgment Date Given\" & age_case > 360\n",
    "pending_df['concluded'] = np.where((pending_df['outcome'] == 'Judgment Date Given') & (pending_df['age'] > 360), 1, pending_df['concluded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_df['max_resolved'] = pending_df.groupby('case_number')['concluded'].transform('max')\n",
    "# convert max_resolved to int\n",
    "pending_df['max_resolved'] = pending_df['max_resolved'].astype(int)\n",
    "# keep if max_resolved is not 1 \n",
    "pending_df = df[df['max_resolved'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['age'] = (pd.Timestamp.now() - df['activity_date']).dt.days\n",
    "df['age_category'] = pd.cut(\n",
    "    df['age'], \n",
    "    bins=[0, 360, 1080, df['age'].max()], \n",
    "    labels=['0-360 days', '360-1080 days', 'Over 1080 days']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a pivot table of age category and case_type\n",
    "df.pivot_table(index='case_type', columns='age_category', values='caseid_no', aggfunc='count', fill_value=0).to_csv(f'{file_path}/nyahururu_age_category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.pivot_table(index='case_type', columns='age_category', values='case_number', aggfunc='count', fill_value=0).to_csv(f'{file_path}/age_category.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_df.to_csv(f'{file_path}/final_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haki-data-HVHT8HQl-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
