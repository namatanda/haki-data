{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['date_dd', 'date_mon', 'date_yyyy', 'caseid_type', 'caseid_no',\n",
    "       'filed_dd', 'filed_mon', 'filed_yyyy', 'original_court',\n",
    "       'original_code', 'original_number', 'original_year', 'case_type',\n",
    "       'judge_1', 'judge_2', 'judge_3', 'judge_4', 'judge_5', 'judge_6',\n",
    "       'judge_7', 'comingfor', 'outcome', 'reason_adj', 'next_dd', 'next_mon',\n",
    "       'next_yyyy', 'male_applicant', 'female_applicant',\n",
    "       'organization_applicant', 'male_defendant', 'female_defendant',\n",
    "       'organization_defendant', 'legalrep', 'applicant_witness',\n",
    "       'defedant_witness', 'custody', 'other_details']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_file_paths(root_folder, start_year, end_year):\n",
    "    \"\"\"Generates a list of file paths for Excel files within the specified financial year range.\"\"\"\n",
    "    logging.info(f\"Entering generate_file_paths\")\n",
    "    file_paths = []\n",
    "    for root, _, files in os.walk(root_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\".xlsx\"):\n",
    "                file_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    year = int(os.path.basename(os.path.dirname(root)))\n",
    "                    if start_year <= year <= end_year:\n",
    "                        file_paths.append(file_path)\n",
    "                except ValueError as ve:\n",
    "                    logging.error(f\"Error processing file path {file_path}: {ve}\")\n",
    "                    continue\n",
    "\n",
    "    logging.info(f\"Exiting generate_file_paths successfully\")\n",
    "    return file_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)  # Set logging level to INFO\n",
    "\n",
    "def process_file(file_path: str, col_names: list) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    Processes a single Excel file, extracting the court code and relevant data.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the Excel file.\n",
    "        col_names (list): List of column names for DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame | None: A DataFrame containing the processed data, or None if an error occurred.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        court_name = os.path.split(file_path)[0].split(\"\\\\\")[-3]        \n",
    "        try:\n",
    "            df = pd.read_excel(file_path, header=4, names=col_names)  \n",
    "\n",
    "            df = df.assign(court_name=court_name)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            \n",
    "            # Print processing information\n",
    "            logging.info(f\"Processed file: {file_path}\")\n",
    "            \n",
    "            return df\n",
    "        except Exception as e:  \n",
    "            print(f\"Error processing file {file_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "    except ValueError:\n",
    "        print(f\"Skipping file {file_path} as code is not an integer.\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(file_paths: list[str], col_names: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Reads and processes Excel files from a list of paths sequentially,\n",
    "    combining them into a DataFrame, and logs file processing information.\n",
    "\n",
    "    Args:\n",
    "        file_paths (list[str]): A list of file paths to process.\n",
    "        col_names (list[str]): List of column names for DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the combined data from all processed files.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "    for file_path in file_paths:\n",
    "        result = process_file(file_path, col_names)\n",
    "        results.append(result)\n",
    "\n",
    "        if result is not None:\n",
    "            logging.info(f\"Processed file: {file_path}\")\n",
    "        else:\n",
    "            logging.warning(f\"Unprocessed file: {file_path}\")\n",
    "\n",
    "    combined_df = pd.concat(results, ignore_index=True)\n",
    "    return combined_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = r\"C:\\Users\\Gichimu\\Desktop\\Data Science\\utility\\data\\coa\"\n",
    "start_year = 2023\n",
    "end_year = 2024\n",
    "file_paths = generate_file_paths(root_folder, start_year, end_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = process_files(file_paths, col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "broad_case_types = ['COA  Criminal Appeal', 'Civil Appeal', 'Court of Appeal Election Petition Appeal', 'Criminal Applications']\n",
    "df.loc[:, 'broad_case_type'] = df['case_type'].where(df['case_type'].isin(broad_case_types), 'Civil Applications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('raw_coa-22_23.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\Gichimu\\Desktop\\Data Science\\utility\\utility\\processor\\coa-22_23.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get bench sittings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_lists(column):\n",
    "    result = []\n",
    "    for item in column:\n",
    "        if isinstance(item, list):\n",
    "            if not any(pd.isna(x) for x in item):\n",
    "                result.append(item)\n",
    "        elif not pd.isna(item):\n",
    "            result.append(item)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop where the combined bench column contains null values\n",
    "lean_df.loc[:, 'judge_list'] = lean_df['judge_list'].apply(lambda x: drop_nan_lists(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip judge names\n",
    "lean_df['judge_1'] = lean_df['judge_1'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the judge list contains only one judge\n",
    "single_bench_df = lean_df[lean_df['judge_list'].apply(lambda x: len(x) == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where outcome is not yet assigned\n",
    "not_assigned_df = lean_df[lean_df['judge_1'] == 'Not Yet Assigned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicates in not_assigned_df \n",
    "not_assigned_df.drop_duplicates(subset=['court_name', 'caseid_type', 'caseid_no', 'filed_dd', 'filed_mon', 'filed_yyyy'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_assigned_df.groupby('court_name')['court_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_assigned_df.groupby(['court_name', 'outcome'])['outcome'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the total of rows with missing outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lean_df[lean_df['outcome'].isnull()].groupby('court_name')['court_name'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lean_df[lean_df['outcome'].isnull()].groupby(['court_name', 'comingfor'])['comingfor'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of adjourmnents per courts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapped_working_df[mapped_working_df['outcome'] == 'Adjournment'].groupby('court_name').size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group mapped_working_df by court_name where outcome is \"adjourned\" and reason_for_hearing is missing\n",
    "adjourned_df = lean_df[(lean_df['outcome'] == 'Adjournment') & lean_df['reason_adj'].isnull()].groupby('court_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjourned_df['court_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where the matter was adjourned a but the reason was not indicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lean_df[lean_df['outcome'].isnull()].groupby(['court_name', 'comingfor'])['comingfor'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by 'comingfor' if outcome is null\n",
    "missing_outcomes = lean_df[lean_df['outcome'].isnull()].groupby(['court_name', 'comingfor'])['comingfor'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_outcomes.to_csv('missing_outcomes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inconsistency in outcomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent = lean_df[(lean_df['judge_1'] == 'Not Yet Assigned') & (lean_df['outcome'] != 'Case Registered/Filed')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inconsistent.groupby('court_name')['court_name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a group of of pannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Function to check similarity between lists\n",
    "def are_lists_similar(list1, list2):\n",
    "    return sorted(list1) == sorted(list2)\n",
    "\n",
    "# Function to create groupings of similar lists\n",
    "def create_groups(df, col_name):\n",
    "    group_number = 1\n",
    "    groups = {}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        found_group = False\n",
    "        for group_id, group in groups.items():\n",
    "            if any(are_lists_similar(row[col_name], x) for x in group):\n",
    "                groups[group_id].append(row[col_name])\n",
    "                found_group = True\n",
    "                break\n",
    "        \n",
    "        if not found_group:\n",
    "            group_name = f\"Group_{group_number}\"\n",
    "            groups[group_name] = [row[col_name]]\n",
    "            group_number += 1\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to create groupings\n",
    "groupings = create_groups(lean_df, 'judge_list')\n",
    "# Create a mapping of list to group number\n",
    "group_map = {}\n",
    "for group_id, group in groupings.items():\n",
    "    for item in group:\n",
    "        group_map[str(item)] = group_id\n",
    "\n",
    "# Apply the mapping to create a 'group' column in the DataFrame\n",
    "lean_df['bench_panel'] = lean_df['judge_list'].apply(lambda x: group_map[str(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column of 1 if reason_adj is present otherwise 0\n",
    "lean_df['reason_adj_indicator'] = lean_df['reason_adj'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lean_df.groupby('reason_adj')['reason_adj_indicator'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lean_df.to_csv('half_year_23-24.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where reason_adj_indicator is 1\n",
    "filtered_df = lean_df[lean_df['reason_adj_indicator'] == 1]\n",
    "\n",
    "# Convert lists in 'judge_list' column to tuples\n",
    "filtered_df['judge_list'] = filtered_df['judge_list'].apply(tuple)\n",
    "\n",
    "# Group by 'bench_panel' and 'judge_list'\n",
    "grouped_df = filtered_df.groupby(['bench_panel', 'judge_list']).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort grouped_df by 'count' in descending order\n",
    "benched_df = grouped_df.sort_values('count', ascending=False)\n",
    "#save \n",
    "benched_df.to_csv('coa-panel-benched.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop where adjourment reason is not provided"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    # Drop rows with missing data in column: 'reason_adj'\n",
    "    df = df.dropna(subset=['reason_adj'])\n",
    "    return df\n",
    "\n",
    "df_clean = clean_data(df.copy())\n",
    "# drop if reason_adj is missing\n",
    "lean_df = lean_df[~lean_df['reason_adj'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjourn_group = lean_df[['reason_adj', 'bench_panel']].groupby('bench_panel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjourn_group.groupby('panel')['reason_adj'].apply(lambda x: ', '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjournents = adjourn_group.groupby('panel')['reason_adj'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjournents.to_csv('coa-panel-adjournment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check how many benches each judge appears in \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fy_data = df.groupby(['date_yyyy', 'date_mon'])['date_mon'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
