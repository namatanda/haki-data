{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List, Union, Optional\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_values(df: pd.DataFrame, column_name: str = 'outcome') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows from the DataFrame where the specified column contains null values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame from which to drop rows.\n",
    "        column_name (str): The name of the column to check for null values. Default is 'outcome'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with rows containing null values in the specified column dropped.\n",
    "    \"\"\"\n",
    "    initial_row_count: int = df.shape[0]\n",
    "    cleaned_df: pd.DataFrame = df.dropna(subset=[column_name])\n",
    "    final_row_count: int = cleaned_df.shape[0]\n",
    "    dropped_row_count: int = initial_row_count - final_row_count\n",
    "    \n",
    "    if dropped_row_count > 0:\n",
    "        logger.info(f\"Total dropped rows with null values in '{column_name}': {dropped_row_count}\")\n",
    "    else:\n",
    "        logger.info(f\"No rows dropped with null values in '{column_name}'\")\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_columns(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows containing NaN values from the specified columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to process.\n",
    "        columns (List[str]): A list of column names to check for NaN values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with NaN-containing rows dropped.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any of the specified columns are not present in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Validate that all specified columns exist in the DataFrame\n",
    "    missing_columns = set(columns) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Columns not found in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Identify columns with NaN values\n",
    "    nan_columns = df[columns].columns[df[columns].isna().any()].tolist()\n",
    "\n",
    "    # Log dropped rows if any\n",
    "    if nan_columns:\n",
    "        nan_count = df[columns].isna().sum()\n",
    "        logger.info(\"Dropping rows with NaN values:\")\n",
    "        for col in nan_columns:\n",
    "            logger.info(f\"  {col}: {nan_count[col]} rows\")\n",
    "\n",
    "    # Drop rows with NaN values in specified columns\n",
    "    original_row_count = len(df)\n",
    "    df_cleaned = df.dropna(subset=columns)\n",
    "    dropped_row_count = original_row_count - len(df_cleaned)\n",
    "\n",
    "    if dropped_row_count > 0:\n",
    "        logger.info(f\"Total rows dropped: {dropped_row_count}\")\n",
    "    else:\n",
    "        logger.info(\"No rows were dropped.\")\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove duplicates from a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    num_duplicates = data.duplicated().sum()\n",
    "    \n",
    "    if num_duplicates > 0:\n",
    "        logging.info(f\"{num_duplicates} duplicates found.\")\n",
    "        data = data.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "        logging.info(f\"{num_duplicates} duplicates removed.\")\n",
    "    else:\n",
    "        logging.info(\"No duplicates found.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_column(df: pd.DataFrame, column_names: List[str], new_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a new date column in the DataFrame by concatenating the values of three specified columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_names (List[str]): A list of three column names to be concatenated [year, month, day].\n",
    "        new_col (str): The import commandsname of the new date column to be created.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new date column added.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input list doesn't contain exactly three column names or if columns are missing.\n",
    "    \"\"\"\n",
    "    if len(column_names) != 3:\n",
    "        raise ValueError(\"column_names must contain exactly three elements: [year, month, day]\")\n",
    "\n",
    "    year_col, month_col, day_col = column_names\n",
    "\n",
    "    # Check if all required columns exist in the DataFrame\n",
    "    missing_columns = set(column_names) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Create copies to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "\n",
    "    try:\n",
    "        # Convert year and day columns to integers\n",
    "        df[year_col] = df[year_col].astype(float).astype(int)\n",
    "        df[day_col] = df[day_col].astype(float).astype(int)\n",
    "\n",
    "        # Concatenate the columns to create a date string\n",
    "        df[new_col] = (df[year_col].astype(str) + '-' + \n",
    "                       df[month_col].astype(str) + '-' + \n",
    "                       df[day_col].astype(str))\n",
    "\n",
    "        # Convert to datetime\n",
    "        df[new_col] = pd.to_datetime(df[new_col], errors='coerce')\n",
    "\n",
    "        # Log information about the conversion\n",
    "        valid_dates = df[new_col].notna().sum()\n",
    "        logger.info(f\"Created new date column '{new_col}'. Valid dates: {valid_dates}/{len(df)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating date column: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_case_num(df: pd.DataFrame, court_col: str, caseid_type_col: str, caseid_no_col: str, filed_yyyy_col: str, new_col='case_number') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a case number by concatenating court, caseid_type, caseid_no, and filed_yyyy columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the necessary columns.\n",
    "        court_col (str): The name of the column containing court information.\n",
    "        caseid_type_col (str): The name of the column containing case ID type.\n",
    "        caseid_no_col (str): The name of the column containing case ID number.\n",
    "        filed_yyyy_col (str): The name of the column containing the year the case was filed.\n",
    "        new_col (str): The name of the new column to be created for the case number. Default is 'case_num'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the new case number column.\n",
    "    \"\"\"\n",
    "    df[new_col] = df[court_col] + '/' + df[caseid_type_col] + '/' + df[caseid_no_col] + '/' + df[filed_yyyy_col].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_title_case(text):\n",
    "    \"\"\"\n",
    "    Apply title case to a given string.\n",
    "    \n",
    "    Args:\n",
    "        text: The input string to process.\n",
    "    \n",
    "    Returns:\n",
    "        str: The processed string in title case.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    if not isinstance(text, str):\n",
    "        logger.warning(f\"Non-string value encountered: {text}\")\n",
    "        return str(text)\n",
    "    return text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outcome_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the 'outcome' column of the DataFrame by applying title case.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing the 'outcome' column.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the processed 'outcome' column.\n",
    "    \"\"\"\n",
    "    if 'outcome' not in df.columns:\n",
    "        logger.error(\"'outcome' column not found in the DataFrame\")\n",
    "        return df\n",
    "\n",
    "    original_null_count = df['outcome'].isnull().sum()\n",
    "    \n",
    "    df['outcome'] = df['outcome'].apply(apply_title_case)\n",
    "    \n",
    "    new_null_count = df['outcome'].isnull().sum()\n",
    "    if new_null_count > original_null_count:\n",
    "        logger.warning(f\"Number of null values in 'outcome' increased from {original_null_count} to {new_null_count}\")\n",
    "    \n",
    "    non_string_count = df['outcome'].apply(lambda x: not isinstance(x, str) if pd.notna(x) else False).sum()\n",
    "    if non_string_count > 0:\n",
    "        logger.warning(f\"Found {non_string_count} non-string values in 'outcome' after processing\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_case(case_type: str, criminal_cases: Optional[List[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Categorize a case as 'Criminal' or 'Civil' based on its type.\n",
    "    \n",
    "    Args:\n",
    "        case_type (str): The type of the case.\n",
    "        criminal_cases (Optional[List[str]]): List of case types considered as criminal.\n",
    "        \n",
    "    Returns:\n",
    "        str: 'Criminal' if the case type is in the criminal cases list or if criminal_cases is None, 'Civil' otherwise.\n",
    "    \"\"\"\n",
    "    if criminal_cases is None:\n",
    "        return 'Criminal'\n",
    "    else:\n",
    "        return 'Criminal' if case_type in criminal_cases else 'Civil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def categorize_cases(df: pd.DataFrame, criminal_cases: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Categorize all cases in the DataFrame as 'Criminal' or 'Civil'.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case data.\n",
    "        criminal_cases (Optional[List[str]]): List of case types considered as criminal.\n",
    "            If None, all cases are categorized as 'Criminal'.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an added 'nature' column indicating case nature.\n",
    "    \"\"\"\n",
    "    df['nature'] = df['case_type'].apply(lambda x: categorize_case(x, criminal_cases))\n",
    "\n",
    "    # Check for presence of both case types\n",
    "    if 'Criminal' not in df['nature'].values:\n",
    "        logging.warning(\"No criminal cases found in the DataFrame.\")\n",
    "    if 'Civil' not in df['nature'].values:\n",
    "        logging.warning(\"No civil cases found in the DataFrame.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dict(value: Any, dictionary: Dict[str, Union[str, List[Any]]]) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Find all keys in a dictionary where the given value matches.\n",
    "\n",
    "    Args:\n",
    "        value: The value to search for.\n",
    "        dictionary: The dictionary to search in.\n",
    "\n",
    "    Returns:\n",
    "        A list of keys where the value matches, or None if no matches are found.\n",
    "    \"\"\"\n",
    "    matching_keys = []\n",
    "    for key, dict_value in dictionary.items():\n",
    "        if isinstance(dict_value, str) and dict_value == value:\n",
    "            matching_keys.append(key)\n",
    "        elif isinstance(dict_value, list) and value in dict_value:\n",
    "            matching_keys.append(key)\n",
    "    \n",
    "    if not matching_keys:\n",
    "        return None\n",
    "    elif len(matching_keys) == 1:\n",
    "        return matching_keys[0]\n",
    "    else:\n",
    "        return matching_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def _convert_to_date(date: Union[str, pd.Timestamp]) -> pd.Timestamp:\n",
    "    \"\"\"\n",
    "    Safely convert a string to a pd.Timestamp object.\n",
    "    \"\"\"\n",
    "    if isinstance(date, pd.Timestamp):\n",
    "        return date\n",
    "    try:\n",
    "        return pd.to_datetime(date)\n",
    "    except (ValueError, TypeError):\n",
    "        return pd.NaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_concluded(outcome: str, resolved_outcomes: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if a case outcome is resolved.\n",
    "\n",
    "    Args:\n",
    "        outcome (str): The outcome of the case.\n",
    "        resolved_outcomes (List[str]): List of outcomes that indicate resolution.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the outcome is considered resolved, otherwise False.\n",
    "    \"\"\"\n",
    "    return outcome.lower() in (resolved.lower() for resolved in resolved_outcomes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_case_registered(outcome: str, activity_date: Union[str, pd.Timestamp], filed_date: Union[str, pd.Timestamp]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a case is registered based on outcome and whether activity and filed dates match.\n",
    "\n",
    "    Args:\n",
    "        outcome (str): The outcome of the case.\n",
    "        activity_date (Union[str, pd.Timestamp]): The date of the activity.\n",
    "        filed_date (Union[str, pd.Timestamp]): The date the case was filed.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the outcome implies registration and activity_date matches filed_date, otherwise False.\n",
    "    \"\"\"\n",
    "    outcome = outcome.strip().lower()\n",
    "    \n",
    "    if 'registered' not in outcome and 'filed' not in outcome:\n",
    "        return False\n",
    "\n",
    "    activity_date = _convert_to_date(activity_date)\n",
    "    filed_date = _convert_to_date(filed_date)\n",
    "\n",
    "    return pd.notna(activity_date) and pd.notna(filed_date) and activity_date == filed_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_columns(df: pd.DataFrame, required_columns: Union[str, List[str]]) -> None:\n",
    "    \"\"\"\n",
    "    Validate that the DataFrame contains the required columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        required_columns (Union[str, List[str]]): A single column name (str) or a list of column names (List[str]) that must be present.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any required columns are missing.\n",
    "    \"\"\"\n",
    "    # Convert required_columns to a list if it's a string\n",
    "    if isinstance(required_columns, str):\n",
    "        required_columns = [required_columns]\n",
    "\n",
    "    # Check which required columns are missing\n",
    "    missing_columns = set(required_columns) - set(df.columns)\n",
    "    \n",
    "    # If there are missing columns, raise a ValueError with an informative message\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_concluded_column(df: pd.DataFrame, resolved_outcomes: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add the 'concluded' column to the DataFrame based on resolved outcomes.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame with case data.\n",
    "        resolved_outcomes (List[str]): List of outcomes considered resolved.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'concluded' column added.\n",
    "    \"\"\"\n",
    "    df['concluded'] = df['outcome'].apply(lambda outcome: is_concluded(outcome, resolved_outcomes))\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_registered_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add the 'registered' column to the DataFrame based on case registration criteria.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame with case data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'registered' column added.\n",
    "    \"\"\"\n",
    "    df['registered'] = df.apply(\n",
    "        lambda row: is_case_registered(row['outcome'], row['activity_date'], row['filed_date']),\n",
    "        axis=1\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "\n",
    "TIME_LIMITS: Dict[str, int] = {\n",
    "    'murder': 360,\n",
    "    'revision': 90,\n",
    "    'misc_application': 90,\n",
    "    'suit': 360,\n",
    "    'judicial_review': 180,\n",
    "    'constitutional_petition': 180,\n",
    "}\n",
    "\n",
    "def is_case_within_time_limit(age: int, case_category: str, concluded: bool) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a case falls within the specified time limit for its category and is concluded.\n",
    "\n",
    "    Args:\n",
    "        age (int): The age of the case in days.\n",
    "        case_category (str): The category of the case.\n",
    "        concluded (bool): Whether the case is concluded.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the case is within the time limit and concluded, otherwise False.\n",
    "    \"\"\"\n",
    "    time_limit = TIME_LIMITS.get(case_category, 0)\n",
    "    return age <= time_limit and concluded\n",
    "\n",
    "def calculate_case_age(filed_date: datetime, activity_date: datetime) -> int:\n",
    "    \"\"\"\n",
    "    Calculate the age of a case in days.\n",
    "\n",
    "    Args:\n",
    "        filed_date (datetime): The date the case was filed.\n",
    "        activity_date (datetime): The date of the latest activity.\n",
    "\n",
    "    Returns:\n",
    "        int: The age of the case in days.\n",
    "    \"\"\"\n",
    "    return (activity_date - filed_date).days\n",
    "\n",
    "def add_pmmu_timelines(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the case data by adding age and time limit compliance columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The processed DataFrame with new columns added.\n",
    "    \"\"\"\n",
    "    df['age'] = df.apply(lambda row: calculate_case_age(row['filed_date'], row['activity_date']), axis=1)\n",
    "    df['within_time_limit'] = df.apply(\n",
    "        lambda row: is_case_within_time_limit(row['age'], row['broad_case_type'], row['concluded']),\n",
    "        axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "# Example usage\n",
    "# df = pd.read_csv('case_data.csv')  # Load your data\n",
    "# df['filed_date'] = pd.to_datetime(df['filed_date'])\n",
    "# df['activity_date'] = pd.to_datetime(df['activity_date'])\n",
    "# df['concluded'] = df['concluded'].astype(bool)\n",
    "# processed_df = add_pmmu_timelines(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_case_stats(df, registered_col, concluded_col):\n",
    "    \"\"\"Calculates monthly statistics for registered and concluded cases.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing case data.\n",
    "        registered_col (str): The name of the column containing registered cases.\n",
    "        concluded_col (str): The name of the column containing concluded cases.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with monthly statistics for registered and concluded cases.\n",
    "    \"\"\"\n",
    "\n",
    "    monthly_cases = df.groupby(['court', 'date_mon', 'case_type']).agg(\n",
    "        registered=(registered_col, 'sum'),\n",
    "        concluded=(concluded_col, 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    return monthly_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_dataframe_columns(df):\n",
    "    \"\"\"Strips leading and trailing whitespace from all columns in a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The modified DataFrame with stripped columns.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df = df.astype(str).apply(lambda x: x.str.strip())\n",
    "        logger.info(\"str.strip() applied successfully to all columns.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error applying str.strip(): {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONSTANTS\n",
    "CRIMINAL_CASES = [\n",
    "    'Murder Case',\n",
    "    'Criminal Revision',\n",
    "    'Criminal Appeal',\n",
    "    'Murder - Gender Justice Criminal Case',\n",
    "    'Criminal Court Martial Appeal',\n",
    "    'Anti-Corruption and Economic Crimes Revision',\n",
    "    'Criminal Miscellaneous Application',\n",
    "    'Criminal Applications', \n",
    "    'COA Criminal Appeal'\n",
    "]\n",
    "\n",
    "CRIMINAL_CASES = [\n",
    "    'Murder Case',\n",
    "    'Criminal Revision',\n",
    "    'Criminal Appeal',\n",
    "    'Murder - Gender Justice Criminal Case',\n",
    "    'Criminal Court Martial Appeal',\n",
    "    'Anti-Corruption and Economic Crimes Revision',\n",
    "    'Criminal Miscellaneous Application',\n",
    "    'Criminal Applications', \n",
    "    'COA Criminal Appeal'\n",
    "]\n",
    "BROAD_CASE_TYPES = {\n",
    "    'Civil Suit': [\n",
    "        'Civil Suit',\n",
    "        'Anti-Corruption and Economic Crimes Suit',\n",
    "        'Family Originating Summons',\n",
    "        'Family Civil Case',\n",
    "        'HCC(OS) Family',\n",
    "        'Commercial Admiralty',\n",
    "        'Commercial Matters',\n",
    "    ],\n",
    "    \n",
    "    'Adoption': 'Family Adoption',\n",
    "    'Divorce': 'Family Divorce Cause',\n",
    "\n",
    "    'Criminal Application': 'Criminal Miscellaneous Application',\n",
    "\n",
    "    'Miscellaneous Application': [\n",
    "        'Civil Case Miscellaneous',\n",
    "        'Judicial Review Miscellaneous',\n",
    "        'JR  Petition Miscellaneous',\n",
    "        'Anti-Corruption and Economic Crimes Miscellaneous',\n",
    "        'Commercial Miscellaneous',\n",
    "        'Constitution and Human Rights Petitions Miscellaneous',\n",
    "        'Family Miscellaneous',\n",
    "        'Commercial Arbitration',\n",
    "    ],\n",
    "    'Judicial Review': [\n",
    "        'Anti-Corruption and Economic Crime Judicial review',\n",
    "        'Judicial Review ELC',\n",
    "        'Judicial Review',\n",
    "    ],\n",
    "    'Criminal Revision': [\n",
    "        'Criminal Revision',\n",
    "        'Anti-Corruption and Economic Crimes Revision',\n",
    "    ],\n",
    "    'Criminal Appeal': [\n",
    "        'Criminal Appeal',\n",
    "        'Criminal Court Martial Appeal',\n",
    "        'Anti-Corruption and Economic Crimes Appeal',\n",
    "    ],\n",
    "    'Civil Appeal': [\n",
    "        'Family Appeal',\n",
    "        'Civil Appeal',\n",
    "        'Commercial Appeal',\n",
    "        'Constitution and Human Rights Election Petition Appeal',\n",
    "        'Constitution and Human Rights Petition Appeal',\n",
    "        'Constitution and Human Rights Election Petition Appeal',\n",
    "        'Gender Justice Civil Appeal',\n",
    "        'Constitution and Human Rights Miscellaneous Election Petition Appeal (MEPA)',\n",
    "    ],\n",
    "    'Constitution Petition': [\n",
    "        'Anti Corruption and Economic Crimes Petition',\n",
    "        'High Court Criminal Petition',\n",
    "        'Constitution and Human Rights Petition (Civil)',\n",
    "        'Constitution and Human Rights Election Petition',\n",
    "        'High Court Constitution and Human Rights Petitions (Criminal)',\n",
    "        'Commercial Petition',\n",
    "    ],\n",
    "    'Probate Administration': [\n",
    "        'Family P&A Intestate',\n",
    "        'Family P&A Ad Litem',\n",
    "        'Family P&A Ad Colligenda',\n",
    "        'Family P&A Citation',\n",
    "        'Family P&A Testate',\n",
    "        'Family P&A Resealing of Grant',\n",
    "        'Family P&A De Bonis Non',\n",
    "        'Resealing of Grant',\n",
    "        'Citation-Family',\n",
    "    ],\n",
    "    'Murder': [\n",
    "        'Murder Case',\n",
    "        'Murder - Gender Justice Criminal Case',\n",
    "    ],\n",
    "    'Tax Appeal': [\n",
    "        'Commercial Income Tax Apperiod_startpeal',\n",
    "        'Commercial Custom Tax Appeal',\n",
    "    ],\n",
    "    'Bankruptcy and Insolvency' : [\n",
    "        'Commercial Insolvency Notice Petition',\n",
    "        'Commercial Insolvency Petition',\n",
    "        'Commercial Bankruptcy Notice',\n",
    "        'Commercial Insolvency Cause',\n",
    "        'Commercial Insolvency Notice',\n",
    "        'Commercial Bankruptcy Cause',\n",
    "        'Commercial Winding Up Cause',\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "RESOLVED_OUTCOMES = ['Ruling Delivered- Case Closed',\n",
    " 'Terminated',\n",
    " 'Matter Settled- Case Closed',\n",
    " 'Application Dismissed - Case Closed',\n",
    " 'Judgment Delivered- Case Closed',\n",
    " 'Matter Withdrawn',\n",
    " 'Application Allowed - Case Closed',\n",
    " 'Application Withdrawn - Case Closed',\n",
    " 'Judgment Delivered- Convicted',\n",
    " 'Placed In Probation',\n",
    " 'Dismissed',\n",
    " 'Judgment Delivered',\n",
    " 'Judgment Delivered- Acquittal',\n",
    " 'Ruling Delivered- Accused Discharged',\n",
    " 'Abated',\n",
    " 'Consolidated- Case Closed',\n",
    " 'Grant Confirmed',\n",
    " 'Limited Grant Issued',\n",
    " 'Struck Out',\n",
    " 'Grant Revoked',\n",
    " 'Consent Recorded - Case Closed',\n",
    " 'Dismissed For Want Of Prosecution - Case Closed',\n",
    " 'Out Of Court Settlement Reached',\n",
    " 'Appeal Dismissed',\n",
    " 'Retrial',\n",
    " 'Appeal Rejected',\n",
    " 'Sentence Commuted',\n",
    " 'Ruling Delivered- Application Closed',\n",
    " 'Probation Orders Issued',\n",
    " 'Order Issued - Case Closed',\n",
    " 'Revision Declined']\n",
    "\n",
    "\n",
    "TRANSFERED_CASES = ['File Transfered -case Closed', \n",
    "        'File Transferred',]\n",
    "\n",
    "MERIT_CATEGORY = {\n",
    "    'Judgment Delivered': [\n",
    "        'Judgment Delivered- Case Closed',\n",
    "        'Judgment Delivered',\n",
    "        'Judgment Delivered- Acquittal',\n",
    "        'Judgment Delivered- Convicted',\n",
    "        'Grant Revoked',\n",
    "        'Retrial'\n",
    "        ],\n",
    "    'Ruling Case Closed': [\n",
    "        'Ruling Delivered- Case Closed', \n",
    "        'Ruling Delivered- Accused Discharged',\n",
    "        ],\n",
    "    'Final Grant': [\n",
    "        'Grant Confirmed',\n",
    "        'Limited Grant Issued',\n",
    "        ],\n",
    "    'Case Withdrawn': [\n",
    "        'Matter Withdrawn',\n",
    "        'Application Withdrawn - Case Closed',\n",
    "        ],\n",
    "   'Out Of Court Settlement': [\n",
    "        'Consent Recorded - Case Closed',\n",
    "        'Matter Settled Through Mediat26\tJun\t2024\tion',\n",
    "        'Out Of Court Settlement Reached',\n",
    "    ],\n",
    "    'Dismissed':[\n",
    "        'Dismissed For Want Of Prosecution - Case Closed',\n",
    "        'Dismissed',\n",
    "        'Appeal Dismissed',\n",
    "        'Terminated'\n",
    "    ],\n",
    "\n",
    "    'Case Closed': [\n",
    "        'Struck Out',\n",
    "        'Application Dismissed - Case Closed',\n",
    "        'Application Allowed - Case Closed',\n",
    "        'Matter Settled- Case Closed',\n",
    "        'Ruling Delivered- Application Closed',\n",
    "        'Consolidated- Case Closed',\n",
    "        'Abated',\n",
    "        'Placed In Probation',\n",
    "        'Revision Declined',\n",
    "        'Probation Orders Issued',\n",
    "        'Appeal Rejected',\n",
    "        'Interlocutory Judgement Entered',\n",
    "        'Order issued - Case closed'   \n",
    "    ],\n",
    "}\n",
    "\n",
    "HC_PMMU_TIME_LINES = {\n",
    "    'murder': 360,\n",
    "    'revision': 90,\n",
    "    'misc_application': 90,\n",
    "    'suit': 360,\n",
    "    'judicial_review': 180,\n",
    "    'constitutional_petition': 180,\n",
    "}\n",
    "\n",
    "NON_ADJOURNABLE = [\n",
    "    'Taxation and Issuance of Certificates',\n",
    "    'Orders',\n",
    "    'Appointments of  Mediator',\n",
    "    'Screening of files for Mediation',\n",
    "    'Post-judgment',\n",
    "    'Re-activation',\n",
    "    'Reactivation',\n",
    "    'Notice of Taxation',\n",
    "    'Entering Interlocutory Judgments',\n",
    "    'Approval by DR', \n",
    "    'Registration/Filing-Application', \n",
    "    'Registration/Filing', \n",
    "    'Registration/Filing-Application',\n",
    " ]\n",
    "MERIT_OUTCOMES = [\n",
    "    'Ruling Delivered- Case Closed', \n",
    "    'Judgment Delivered- Case Closed',\n",
    "    'Judgment Delivered',\n",
    "    'Judgment Delivered- Acquittal',\n",
    "    'Judgment Delivered- Convicted',\n",
    "    'Grant Revoked',\n",
    "    'Ruling Delivered- Accused Discharged',\n",
    "    'Retrial'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = '/home/stanoo/dcrt/data/API/'\n",
    "# raw_df = pd.read_csv(f'{file_path}/Hc/hc_23-24_data.csv')\n",
    "# # # Load name of judges\n",
    "# # judge_names = pd.read_csv(f'{file_path}/reports/judges.csv')\n",
    "# # # Load name of judges\n",
    "# # #pending_baseline = pd.read_csv(f'{file_path}/reports/pending_baseline.csv')\n",
    "file_path = '/home/stanoo/dcrt/data/API/dcrt_2023-2024.csv'\n",
    "raw_df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 16:06:54,100 - ERROR - Missing required columns: filed_date, activity_date\n",
      "2024-10-14 16:06:54,183 - INFO - str.strip() applied successfully to all columns.\n",
      "2024-10-14 16:06:54,201 - INFO - Created new date column 'activity_date'. Valid dates: 12896/12896\n",
      "2024-10-14 16:06:54,227 - INFO - Created new date column 'filed_date'. Valid dates: 1495/12896\n",
      "2024-10-14 16:06:54,250 - INFO - Created new date column 'next_date'. Valid dates: 8957/12896\n",
      "2024-10-14 16:06:54,270 - INFO - No rows were dropped.\n",
      "2024-10-14 16:06:54,287 - INFO - 1221 duplicates found.\n",
      "2024-10-14 16:06:54,308 - INFO - 1221 duplicates removed.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resolved_outcomes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m df \u001b[38;5;241m=\u001b[39m remove_duplicates(df)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Step 2: Add the 'concluded' column\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m add_concluded_column(df, \u001b[43mresolved_outcomes\u001b[49m)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# Step 3: Add the 'registered' column\u001b[39;00m\n\u001b[1;32m     26\u001b[0m df \u001b[38;5;241m=\u001b[39m add_registered_column(df)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resolved_outcomes' is not defined"
     ]
    }
   ],
   "source": [
    "raw_df.rename(columns={'court_name': 'court'}, inplace=True)\n",
    "df = df.rename(columns={'court_name': 'court'})\n",
    "try:\n",
    "    validate_columns(df, ['outcome', 'activity_date', 'filed_date'])\n",
    "    logger.info(\"Validation passed.\")\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "raw_df = strip_dataframe_columns(raw_df)\n",
    "# create activity date and filed date columns\n",
    "raw_df = create_date_column(raw_df.copy(), ['date_dd', 'date_mon', 'date_yyyy'], 'activity_date')\n",
    "raw_df = create_date_column(raw_df.copy(), ['filed_dd', 'filed_mon', 'filed_yyyy'], 'filed_date')\n",
    "raw_df = create_date_column(raw_df.copy(), ['next_dd', 'next_mon','next_yyyy'], 'next_date')\n",
    "#cutoff_date = pd.Timestamp('2024-06-30') \n",
    "#df = raw_df[raw_df['activity_date'] <= cutoff_date]\n",
    "df = raw_df.copy()\n",
    "\n",
    "df = drop_nan_columns(df, ['date_dd', 'date_mon', 'date_yyyy', 'caseid_type', 'caseid_no',\n",
    "       'filed_dd', 'filed_mon', 'filed_yyyy', 'case_type', 'comingfor'])\n",
    "\n",
    "df = remove_duplicates(df)\n",
    "\n",
    "# Step 2: Add the 'concluded' column\n",
    "df = add_concluded_column(df, resolved_outcomes)\n",
    "    \n",
    "    # Step 3: Add the 'registered' column\n",
    "df = add_registered_column(df)\n",
    "\n",
    "# missing outcomes\n",
    "df = drop_null_values(df)\n",
    "\n",
    "df = generate_case_num(df, 'court', 'caseid_type', 'caseid_no', 'filed_yyyy')\n",
    "\n",
    "# Add broad case category of civil and criminal\n",
    "df = categorize_cases(df, CRIMINAL_CASES)\n",
    "# Add filed and resolved outcomes\n",
    "df = process_case_status(df, RESOLVED_OUTCOMES)\n",
    "\n",
    "\n",
    "# Add sojar case groupings\n",
    "df['broad_case_type'] = df['case_type'].apply(lambda x: apply_dict(x, BROAD_CASE_TYPES))\n",
    "\n",
    "\n",
    "# Apply the function to create a new column with keys\n",
    "df['productivity'] = df['outcome'].apply(lambda x: apply_dict(x, MERIT_CATEGORY))\n",
    "\n",
    "# Add time lines\n",
    "df = add_pmmu_timelines(df)\n",
    "\n",
    "# transferred\n",
    "df['transfer'] = df['outcome'].apply(lambda x: x in TRANSFERED_CASES)\n",
    "\n",
    "df['productivity_category'] = df.apply(\n",
    "    lambda row: 'merit' if row['outcome'] in MERIT_OUTCOMES and row['concluded'] == 1 \n",
    "    else 'non-merit' if row['outcome'] not in MERIT_OUTCOMES and row['concluded'] == 1 \n",
    "    else None, axis=1\n",
    ")\n",
    "\n",
    "# Create data for output\n",
    "filed_cases = analyze_court_outcomes(df, '2023-07-01', '2024-06-30', 'registered')\n",
    "resolved_cases = analyze_court_outcomes(df, '2023-07-01', '2024-06-30', 'concluded')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove leading and trailing spaces on comingfor\n",
    "df['comingfor'] = df['comingfor'].str.strip()\n",
    "\n",
    "# create a new column of 1 if reason_adj is not null and comingfor is not in non_adjourned else 0\n",
    "df['adjourned'] = (df['reason_adj'].notnull() & df['comingfor'].apply(lambda x: x not in NON_ADJOURNABLE)).astype(int)\n",
    "# an event is adjournable if non_adjourned is not in comingfor\n",
    "df['adjournable'] = df['comingfor'].apply(lambda x: x not in NON_ADJOURNABLE).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "monthly_filed_cases = df.groupby(['court','date_mon']).agg({'registered':'sum'}).reset_index()\n",
    "monthly_concluded_cases = df.groupby(['court','date_mon']).agg({'concluded':'sum'}).reset_index()\n",
    "concluded_cases = df.groupby('court').agg({'concluded':'sum'}).reset_index()\n",
    "\n",
    "\n",
    "average_time_to_conclude = df.loc[df['concluded'] == 1].pivot_table(index='court', columns='nature', values='age', aggfunc='mean', fill_value=0).round(2)\n",
    "pmmu_timelines = df[df['time_lines'] == 1].pivot_table(index='court', columns='broad_case_type', values='time_lines', aggfunc='count', fill_value=0)\n",
    "total_concluded_per_court = df[df['concluded'] == 1].pivot_table(index='court', columns='broad_case_type', values='time_lines', aggfunc='count', fill_value=0)\n",
    "resolved_within_pmmu_timeline = pmmu_timelines / total_concluded_per_court\n",
    "\n",
    "court_productivity = df.pivot_table(index='court', columns='productivity', values='concluded', aggfunc='count', fill_value=0)\n",
    "court_productivity = court_productivity.rename_axis(columns=None)\n",
    "\n",
    "productivity_pivot_table = pd.pivot_table(\n",
    "    df,\n",
    "    values='concluded',  \n",
    "    index='court',     \n",
    "    columns='productivity_category', \n",
    "    aggfunc='count',   \n",
    "    fill_value=0        \n",
    ").rename(columns={'merit': 'Merit', 'non-merit': 'Non_Merit'})\n",
    "\n",
    "monthly_stats = monthly_case_stats(df, 'registered', 'concluded')\n",
    "adjourned_per_court = df.groupby(['court', 'reason_adj'])['adjourned'].sum().reset_index(name='count')\n",
    "adjourned = df.groupby('court')['adjourned'].sum().reset_index(name='total_adjourned')\n",
    "adjournable = df.groupby('court')['adjournable'].sum().reset_index(name='total_adjournable')\n",
    "# deternine the rate of adjournments\n",
    "adjourn_proportion = pd.merge(adjourned, adjournable, on=['court'])\n",
    "adjourn_proportion['adjourn_proportion'] = (adjourn_proportion['total_adjourned']/adjourn_proportion['total_adjournable'])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove trailing on judge names\n",
    "judge_names['judge_1'] = judge_names['judge_1'].str.strip()\n",
    "judge_df = df[df['judge_1'].isin(judge_names['judge_1'])]\n",
    "judge_productivity = judge_df.pivot_table(index='judge_1', columns='productivity', values='concluded', aggfunc='sum', fill_value=0)\n",
    "judge_productivity = judge_productivity.rename_axis(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29856/2059409827.py:1: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  df.groupby(pd.Grouper(key='activity_date', freq='M')).size().reset_index(name='count')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activity_date</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-08-31</td>\n",
       "      <td>487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-09-30</td>\n",
       "      <td>432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  activity_date  count\n",
       "0    2024-07-31    516\n",
       "1    2024-08-31    487\n",
       "2    2024-09-30    432"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(pd.Grouper(key='activity_date', freq='M')).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #remove white space at the begining and end of pending_baseline['case_number'] and pending_baseline['court']\n",
    "# pending_baseline['case_number'] = pending_baseline['case_number'].str.strip()\n",
    "# pending_baseline['court'] = pending_baseline['court'].str.strip()\n",
    "# pending_baseline['case_number'] = pending_baseline ['court'] + \"/\" + pending_baseline['case_number']\n",
    "# pending_baseline.drop(columns='case_type', inplace=True)\n",
    "\n",
    "# # Perform a merge with indicator to find rows only in pending_baseline\n",
    "# merged_df = pending_baseline.merge(df, on=['case_number', 'court'], how='left', indicator=True)\n",
    "# # Filter to get only the rows that are in pending_baseline but not in df\n",
    "# #only_in_pending_baseline = merged_df[merged_df['_merge'] == 'left_only']\n",
    "# merged_df['resolved'] = merged_df.groupby('case_number')['concluded'].transform('max')\n",
    "# merged_df['year_filed'] = merged_df['case_number'].str.split('/').str[-1]\n",
    "# merged_df['year_filed'] = merged_df['year_filed'].astype(int)\n",
    "# merged_df = merged_df.sort_values(by=['court', 'year_filed'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolved_cases = analyze_court_outcomes(df, '2023-07-01', '2024-06-30', 'concluded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot of concluded cases by case_type per court \n",
    "resolved_pivot = df.pivot_table(index='court', columns='broad_case_type', values='concluded', aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "filed_pivot = df.pivot_table(index='court', columns='broad_case_type', values='registered', aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>broad_case_type</th>\n",
       "      <th>Constitution Petition</th>\n",
       "      <th>Criminal Appeal</th>\n",
       "      <th>Criminal Application</th>\n",
       "      <th>Criminal Revision</th>\n",
       "      <th>Miscellaneous Application</th>\n",
       "      <th>Murder</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>court</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Kibera</th>\n",
       "      <td>11</td>\n",
       "      <td>73</td>\n",
       "      <td>65</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "broad_case_type  Constitution Petition  Criminal Appeal  Criminal Application  \\\n",
       "court                                                                           \n",
       "Kibera                              11               73                    65   \n",
       "\n",
       "broad_case_type  Criminal Revision  Miscellaneous Application  Murder  \n",
       "court                                                                  \n",
       "Kibera                         153                          0       5  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filed_pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "column_order = ['Murder', 'Criminal Appeal', 'Criminal Application', \n",
    "                'Criminal Revision', 'Miscellaneous Application', \n",
    "                'Constitution Petition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "filed_pivot.to_csv('/home/stanoo/dcrt/data/HC/reports/kibera_filed_cases.csv', columns=column_order, index=True)\n",
    "resolved_pivot.to_csv('/home/stanoo/dcrt/data/HC/reports/kibera_resolved_cases.csv', index=True)\n",
    "#df.to_csv('/home/stanoo/dcrt/data-analysis/processed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot of transfered cases by case_type per court \n",
    "transfer_pivot = df.pivot_table(index='court', columns='broad_case_type', values='transfer', aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pivot of transfered cases by case_type per court \n",
    "transfer_pivot.to_csv('/home/stanoo/dcrt/data/HC/reports/kibera_transfer_cases.csv', columns=column_order, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>court</th>\n",
       "      <th>total_transfered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kibera</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    court  total_transfered\n",
       "0  Kibera                 7"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('court')['transfer'].sum().reset_index(name='total_transfered')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/home/stanoo/dcrt/data-analysis/processed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "court_productivity = df.pivot_table(index='court', columns='productivity', values='concluded', aggfunc='count', fill_value=0)\n",
    "court_productivity = court_productivity.rename_axis(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "court_productivity = df.pivot_table(index='court', columns='productivity', values='concluded', aggfunc='count', fill_value=0)\n",
    "court_productivity = court_productivity.rename_axis(columns=None)\n",
    "judge_productivity = judge_df.pivot_table(index='judge_1', columns='productivity', values='concluded', aggfunc='sum', fill_value=0)\n",
    "judge_productivity = judge_productivity.rename_axis(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove trailing on judge names\n",
    "df['judge_1'] = df['judge_1'].str.strip()\n",
    "\n",
    "# create dataframe of judges only\n",
    "judge_df_1 = df[df['judge_1'].isin(judge_names['judge_1'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "court_productivity = judge_df_1.pivot_table(index='court', columns='productivity', values='concluded', aggfunc='count', fill_value=0)\n",
    "court_productivity = court_productivity.rename_axis(columns=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "court_productivity.to_csv(f'{file_path}/reports/judge_productivity.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', 65)\n",
    "df = df.sort_values('activity_date')\n",
    "cutoff_date = pd.Timestamp('2024-06-30')  \n",
    "processed_df = calculate_judgment_time(df)\n",
    "judgement_df = determine_scheduled_judgment(processed_df, cutoff_date)\n",
    "on_time_proportion = get_on_time_delivery_proportions(judgement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processed_df.to_csv(f'{file_path}/reports/hc_processed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# judgement_df.to_csv(f'{file_path}/reports/hc_judgement_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def determine_judgment_scheduling(df, cutoff_date):\n",
    "#     judgment_date_set_outcomes = [\"Judgment Date Given\", \"Judgment On Notice\", \"Judgment Date Set\"]\n",
    "#     judgment_delivered_outcomes = [\"Grant Revoked\", \"Judgment Delivered\", \n",
    "#                                    \"Judgment Delivered- Acquittal\", \"Judgment Delivered- Case Closed\", \n",
    "#                                    \"Judgment Delivered- Convicted\"]\n",
    "    \n",
    "#     result = df.copy()\n",
    "    \n",
    "#     result['judgment_delayed'] = False\n",
    "#     result['set_date'] = pd.NaT\n",
    "#     result['delivery_date'] = pd.NaT\n",
    "    \n",
    "#     grouped = df.groupby('case_number')\n",
    "    \n",
    "#     for case_number, group in grouped:\n",
    "#         group = group.sort_values('activity_date')\n",
    "        \n",
    "#         judgment_set_rows = group[group['outcome'].isin(judgment_date_set_outcomes)]\n",
    "#         for _, judgment_set_row in judgment_set_rows.iterrows():\n",
    "#             set_date = judgment_set_row['activity_date']\n",
    "#             scheduled_date = judgment_set_row['next_date']\n",
    "            \n",
    "#             # Skip this case if the scheduled date is after the cutoff date\n",
    "#             if scheduled_date > cutoff_date:\n",
    "#                 continue\n",
    "            \n",
    "#             result.loc[result['case_number'] == case_number, 'set_date'] = scheduled_date\n",
    "            \n",
    "#             # Find activities on or after the scheduled_date\n",
    "#             subsequent_activities = group[group['activity_date'] >= scheduled_date]\n",
    "            \n",
    "#             if not subsequent_activities.empty:\n",
    "#                 first_activity = subsequent_activities.iloc[0]\n",
    "#                 if first_activity['activity_date'] == scheduled_date:\n",
    "#                     if first_activity['outcome'] in judgment_delivered_outcomes:\n",
    "#                         result.loc[result['case_number'] == case_number, 'delivery_date'] = scheduled_date\n",
    "#                     else:\n",
    "#                         # If the outcome is not judgment delivery on the scheduled date, it's delayed\n",
    "#                         result.loc[result['case_number'] == case_number, 'judgment_delayed'] = True\n",
    "#                 else:\n",
    "#                     # If the first activity after scheduling is after the scheduled date, it's delayed\n",
    "#                     result.loc[result['case_number'] == case_number, 'judgment_delayed'] = True\n",
    "                \n",
    "#                 # Check for eventual judgment delivery\n",
    "#                 eventual_delivery = subsequent_activities[subsequent_activities['outcome'].isin(judgment_delivered_outcomes)]\n",
    "#                 if not eventual_delivery.empty:\n",
    "#                     result.loc[result['case_number'] == case_number, 'delivery_date'] = eventual_delivery.iloc[0]['activity_date']\n",
    "#             else:\n",
    "#                 # If there are no activities on or after the scheduled date, we assume it's delayed\n",
    "#                 result.loc[result['case_number'] == case_number, 'judgment_delayed'] = True\n",
    "            \n",
    "#             # Break after processing the first judgment set date for this case\n",
    "#             break\n",
    "    \n",
    "#     # Remove cases where set_date is NaT (which means they were skipped due to cutoff date)\n",
    "#     result = result[result['set_date'].notna()]\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# case_level = scheduled_df.groupby(['court', 'case_number']).agg({\n",
    "#     'set_date': lambda x: x.notna().any(),  # Was the case scheduled?\n",
    "#     'delivery_date': lambda x: x.notna().any(),  # Was the judgment delivered?\n",
    "#     'judgment_delayed': 'any'  # Was the judgment delayed for this case?\n",
    "# }).reset_index()\n",
    "# # Now aggregate to the judge level\n",
    "# judgement_stats = case_level.groupby('court').agg({\n",
    "#     'set_date': 'sum',  # Total scheduled cases\n",
    "#     'delivery_date': 'sum',  # Total delivered judgments\n",
    "#     'judgment_delayed': 'sum'  # Total delayed cases\n",
    "# }).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def determine_judgment_scheduled(df, cutoff_date):\n",
    "#     judgment_date_set_outcomes = [\"Judgment Date Given\", \"Judgment On Notice\", \"Judgment Date Set\"]\n",
    "#     judgment_delivered_outcomes = [\"Grant Revoked\", \"Judgment Delivered\", \n",
    "#                                    \"Judgment Delivered- Acquittal\", \"Judgment Delivered- Case Closed\", \n",
    "#                                    \"Judgment Delivered- Convicted\"]\n",
    "    \n",
    "#     result = df.copy()\n",
    "    \n",
    "#     result['judgment_status'] = 'Not Scheduled'  # Default status\n",
    "#     result['set_date'] = pd.NaT\n",
    "#     result['delivery_date'] = pd.NaT\n",
    "    \n",
    "#     grouped = df.groupby('case_number')\n",
    "    \n",
    "#     for case_number, group in grouped:\n",
    "#         group = group.sort_values('activity_date')\n",
    "        \n",
    "#         judgment_set_rows = group[group['outcome'].isin(judgment_date_set_outcomes)]\n",
    "#         for _, judgment_set_row in judgment_set_rows.iterrows():\n",
    "#             set_date = judgment_set_row['activity_date']\n",
    "#             scheduled_date = judgment_set_row['next_date']\n",
    "            \n",
    "#             if scheduled_date > cutoff_date:\n",
    "#                 continue\n",
    "            \n",
    "#             result.loc[result['case_number'] == case_number, 'set_date'] = scheduled_date\n",
    "#             result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Scheduled'\n",
    "            \n",
    "#             subsequent_activities = group[group['activity_date'] >= scheduled_date]\n",
    "            \n",
    "#             if not subsequent_activities.empty:\n",
    "#                 first_activity = subsequent_activities.iloc[0]\n",
    "#                 if first_activity['outcome'] in judgment_delivered_outcomes:\n",
    "#                     result.loc[result['case_number'] == case_number, 'delivery_date'] = first_activity['activity_date']\n",
    "#                     result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "#                 elif first_activity['activity_date'] > scheduled_date or first_activity['outcome'] not in judgment_delivered_outcomes:\n",
    "#                     result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Delayed'\n",
    "#             elif cutoff_date >= scheduled_date:\n",
    "#                 result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Delayed'\n",
    "            \n",
    "#             break\n",
    "    \n",
    "#     result = result[result['set_date'].notna()]\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduled_df = determine_judgment_scheduled(df, cutoff_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ############################################\n",
    "# def determine_judgment_scheduling_v2(df, cutoff_date):\n",
    "#     judgment_date_set_outcomes = [\"Judgment Date Given\", \"Judgment On Notice\", \"Judgment Date Set\"]\n",
    "\n",
    "    \n",
    "#     judgment_delivered_outcomes = [\"Grant Revoked\", \"Judgment Delivered\", \n",
    "#                                    \"Judgment Delivered- Acquittal\", \"Judgment Delivered- Case Closed\", \n",
    "#                                    \"Judgment Delivered- Convicted\"]\n",
    "    \n",
    "#     result = df.copy()\n",
    "    \n",
    "#     result['judgment_status'] = 'Not Scheduled'  # Default status\n",
    "#     result['set_date'] = pd.NaT\n",
    "#     result['delivery_date'] = pd.NaT\n",
    "    \n",
    "#     grouped = df.groupby('case_number')\n",
    "    \n",
    "#     for case_number, group in grouped:\n",
    "#         group = group.sort_values('activity_date')\n",
    "        \n",
    "#         judgment_set_rows = group[group['outcome'].isin(judgment_date_set_outcomes)]\n",
    "#         for _, judgment_set_row in judgment_set_rows.iterrows():\n",
    "#             set_date = judgment_set_row['activity_date']\n",
    "#             scheduled_date = judgment_set_row['next_date']\n",
    "            \n",
    "#             if scheduled_date > cutoff_date:\n",
    "#                 continue\n",
    "            \n",
    "#             result.loc[result['case_number'] == case_number, 'set_date'] = scheduled_date\n",
    "#             result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Scheduled'\n",
    "            \n",
    "#             # Check for judgment delivery between set_date and scheduled_date\n",
    "#             early_delivery = group[(group['activity_date'] > set_date) & \n",
    "#                                    (group['activity_date'] < scheduled_date) & \n",
    "#                                    (group['outcome'].isin(judgment_delivered_outcomes))]\n",
    "            \n",
    "#             if not early_delivery.empty:\n",
    "#                 result.loc[result['case_number'] == case_number, 'delivery_date'] = early_delivery.iloc[0]['activity_date']\n",
    "#                 result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "#             else:\n",
    "#                 subsequent_activities = group[group['activity_date'] >= scheduled_date]\n",
    "                \n",
    "#                 if not subsequent_activities.empty:\n",
    "#                     first_activity = subsequent_activities.iloc[0]\n",
    "#                     if first_activity['outcome'] in judgment_delivered_outcomes:\n",
    "#                         result.loc[result['case_number'] == case_number, 'delivery_date'] = first_activity['activity_date']\n",
    "#                         result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "#                     elif first_activity['activity_date'] > scheduled_date:\n",
    "#                         result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Delayed'\n",
    "#                 elif cutoff_date >= scheduled_date:\n",
    "#                     result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Delayed'\n",
    "            \n",
    "#             break\n",
    "    \n",
    "#     result = result[result['set_date'].notna()]\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduled_df_v2 = determine_judgment_scheduling_v2(df, cutoff_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add a new column to categorize delivery timing\n",
    "# def categorize_delivery(row):\n",
    "#     if row['judgment_status'] == 'Delivered':\n",
    "#         if row['delivery_date'] < row['set_date']:\n",
    "#             return 'Early'\n",
    "#         elif row['delivery_date'] == row['set_date']:\n",
    "#             return 'On Time'\n",
    "#         else:\n",
    "#             return 'Late'\n",
    "#     return row['judgment_status']\n",
    "\n",
    "# scheduled_df_v2['delivery_category'] = scheduled_df_v2.apply(categorize_delivery, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by judge and case_number to ensure each case is counted once per judge\n",
    "# case_level = scheduled_df_v2.groupby(['court', 'case_number'])['delivery_category'].last().reset_index()\n",
    "\n",
    "# # Now aggregate to the judge level\n",
    "# judgememt_stats = case_level.groupby('court')['delivery_category'].value_counts().unstack(fill_value=0).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Rename columns for clarity\n",
    "# judge_stats.columns.name = None\n",
    "# judge_stats = judge_stats.rename(columns={\n",
    "#     'Scheduled': 'scheduled_cases',\n",
    "#     'Early': 'early_deliveries',\n",
    "#     'On Time': 'on_time_deliveries',\n",
    "#     'Late': 'late_deliveries',\n",
    "#     'Delayed': 'delayed_cases'\n",
    "# })\n",
    "\n",
    "# # Ensure all columns exist\n",
    "# for col in ['scheduled_cases', 'early_deliveries', 'on_time_deliveries', 'late_deliveries', 'delayed_cases']:\n",
    "#     if col not in judge_stats.columns:\n",
    "#         judge_stats[col] = 0\n",
    "\n",
    "# # Calculate total scheduled and delivered cases\n",
    "# judge_stats['scheduled_cases'] = judge_stats['early_deliveries'] + judge_stats['on_time_deliveries'] + judge_stats['late_deliveries'] + judge_stats['delayed_cases']\n",
    "# judge_stats['delivered_cases'] = judge_stats['early_deliveries'] + judge_stats['on_time_deliveries'] + judge_stats['late_deliveries']\n",
    "\n",
    "# # Calculate proportions\n",
    "# judge_stats['early_proportion'] = judge_stats['early_deliveries'] / judge_stats['scheduled_cases']\n",
    "# judge_stats['on_time_proportion'] = judge_stats['on_time_deliveries'] / judge_stats['scheduled_cases']\n",
    "# judge_stats['late_proportion'] = judge_stats['late_deliveries'] / judge_stats['scheduled_cases']\n",
    "# judge_stats['delay_proportion'] = judge_stats['delayed_cases'] / judge_stats['scheduled_cases']\n",
    "# judge_stats['delivered_as_scheduled_proportion'] = (judge_stats['on_time_deliveries'] + judge_stats['early_deliveries']) / judge_stats['scheduled_cases']\n",
    "\n",
    "# # Sort by delay proportion in descending order\n",
    "# judge_stats = judge_stats.sort_values('delay_proportion', ascending=False)\n",
    "\n",
    "# # Display the results\n",
    "# print(judge_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = pd.Timestamp('2024-06-30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_scheduled_judgment(df, cutoff_date):\n",
    "    judgment_date_set_outcomes = [\"Judgment Date Given\", \"Judgment On Notice\", \"Judgment Date Set\"]\n",
    "    judgment_delivered_outcomes = [\"Grant Revoked\", \"Judgment Delivered\", \n",
    "                                   \"Judgment Delivered- Acquittal\", \"Judgment Delivered- Case Closed\", \n",
    "                                   \"Judgment Delivered- Convicted\"]\n",
    "    \n",
    "    df['judgment_status'] = 'Not Scheduled'\n",
    "    df['set_date'] = pd.NaT\n",
    "    df['delivery_date'] = pd.NaT\n",
    "    df['delivery_category'] = ''\n",
    "    \n",
    "    # Filter rows with judgment set outcomes\n",
    "    judgment_set_rows = df[df['outcome'].isin(judgment_date_set_outcomes)]\n",
    "    \n",
    "    # Only consider rows with a scheduled date before or equal to the cutoff date\n",
    "    valid_scheduled = judgment_set_rows[judgment_set_rows['next_date'] <= cutoff_date]\n",
    "    \n",
    "    # For each valid schedule, find the earliest set date\n",
    "    earliest_schedule = valid_scheduled.sort_values('activity_date').groupby('case_number').first().reset_index()\n",
    "    \n",
    "    # Create a dictionary to map case numbers to their schedule dates and statuses\n",
    "    case_to_set_date = dict(zip(earliest_schedule['case_number'], earliest_schedule['next_date']))\n",
    "    case_to_status = {case: 'Scheduled' for case in earliest_schedule['case_number']}\n",
    "    \n",
    "    # Update the result dataframe with schedule information\n",
    "    df['set_date'] = df['case_number'].map(case_to_set_date)\n",
    "    df['judgment_status'] = df['case_number'].map(case_to_status).fillna('Not Scheduled')\n",
    "    df['delivery_category'] = df['case_number'].map(case_to_status).fillna('')\n",
    "    \n",
    "    # Filter rows with judgment delivered outcomes\n",
    "    judgment_delivered_rows = df[df['outcome'].isin(judgment_delivered_outcomes)]\n",
    "    \n",
    "    # Find the first delivery date after set date\n",
    "    for case_number, group in earliest_schedule.groupby('case_number'):\n",
    "        set_date = group['next_date'].values[0]\n",
    "        delivery = judgment_delivered_rows[(judgment_delivered_rows['case_number'] == case_number) & \n",
    "                                           (judgment_delivered_rows['activity_date'] >= set_date)]\n",
    "        if not delivery.empty:\n",
    "            delivery_date = delivery.sort_values('activity_date').iloc[0]['activity_date']\n",
    "            df.loc[df['case_number'] == case_number, 'delivery_date'] = delivery_date\n",
    "            df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "            \n",
    "            if delivery_date <= set_date:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'On Time'\n",
    "            else:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'Delayed'\n",
    "        else:\n",
    "            if cutoff_date >= set_date:\n",
    "                df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delayed'\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'Delayed'\n",
    "    \n",
    "    return df[df['set_date'].notna()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def determine_judgment_scheduling_v3(df, cutoff_date):\n",
    "#     judgment_date_set_outcomes = [\"Judgment Date Given\", \"Judgment On Notice\", \"Judgment Date Set\"]\n",
    "#     judgment_delivered_outcomes = [\"Grant Revoked\", \"Judgment Delivered\", \n",
    "#                                    \"Judgment Delivered- Acquittal\", \"Judgment Delivered- Case Closed\", \n",
    "#                                    \"Judgment Delivered- Convicted\"]\n",
    "    \n",
    "#     result = df.copy()\n",
    "    \n",
    "#     result['judgment_status'] = 'Not Scheduled'  # Default status\n",
    "#     result['set_date'] = pd.NaT\n",
    "#     result['delivery_date'] = pd.NaT\n",
    "#     result['delivery_category'] = ''\n",
    "    \n",
    "#     grouped = df.groupby('case_number')\n",
    "    \n",
    "#     for case_number, group in grouped:\n",
    "#         group = group.sort_values('activity_date')\n",
    "        \n",
    "#         judgment_set_rows = group[group['outcome'].isin(judgment_date_set_outcomes)]\n",
    "#         for _, judgment_set_row in judgment_set_rows.iterrows():\n",
    "#             set_date = judgment_set_row['activity_date']\n",
    "#             scheduled_date = judgment_set_row['next_date']\n",
    "            \n",
    "#             if pd.isnull(scheduled_date) or scheduled_date > cutoff_date:\n",
    "#                 continue\n",
    "            \n",
    "#             result.loc[result['case_number'] == case_number, 'set_date'] = scheduled_date\n",
    "#             result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Scheduled'\n",
    "#             result.loc[result['case_number'] == case_number, 'delivery_category'] = 'Scheduled'\n",
    "            \n",
    "#             # Check for judgment delivery after set_date\n",
    "#             delivery = group[(group['activity_date'] >= set_date) & \n",
    "#                              (group['outcome'].isin(judgment_delivered_outcomes))]\n",
    "            \n",
    "#             if not delivery.empty:\n",
    "#                 delivery_date = delivery.iloc[0]['activity_date']\n",
    "#                 result.loc[result['case_number'] == case_number, 'delivery_date'] = delivery_date\n",
    "#                 result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "                \n",
    "#                 if delivery_date <= scheduled_date:\n",
    "#                     result.loc[result['case_number'] == case_number, 'delivery_category'] = 'On Time'\n",
    "#                 else:\n",
    "#                     result.loc[result['case_number'] == case_number, 'delivery_category'] = 'Delayed'\n",
    "#             else:\n",
    "#                 if cutoff_date >= scheduled_date:\n",
    "#                     result.loc[result['case_number'] == case_number, 'judgment_status'] = 'Delayed'\n",
    "#                     result.loc[result['case_number'] == case_number, 'delivery_category'] = 'Delayed'\n",
    "            \n",
    "#             break\n",
    "    \n",
    "#     result = result[result['set_date'].notna()]\n",
    "    \n",
    "#     return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduled_df_v3 = determine_judgment_scheduling_v3(df, cutoff_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_on_time_delivery_proportions_0(scheduled_cases):\n",
    "#     # Group bjudgement_df.query('case_number ==\"Kiambu/HCCA/E291/2022\"')y court and calculate statistics\n",
    "#     court_stats = scheduled_cases.groupby('court').agg({\n",
    "#         'case_number': 'count',\n",
    "#         'delivery_category': lambda x: (x == 'On Time').sum()\n",
    "#     }).rename(columns={\n",
    "#         'case_number': 'total_scheduled',\n",
    "#         'delivery_category': 'delivered_on_time'\n",
    "#     })\n",
    "    \n",
    "#     # Calculate the proportion\n",
    "#     court_stats['proportion_on_time'] = court_stats['delivered_on_time'] / court_stats['total_scheduled']\n",
    "    \n",
    "#     return court_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate the proportion\n",
    "# on_time_proportion = get_on_time_delivery_proportions(scheduled_df_v3)\n",
    "# #on_time_proportion0 = get_on_time_delivery_proportions(scheduled_df_v3)\n",
    "# #on_time_proportion = calculate_on_time_delivery_proportion(scheduled_df_v3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Group by judge and case_number to ensure each case is counted once per judge\n",
    "# case_level = scheduled_df.groupby(['court', 'case_number'])['judgment_status'].last().reset_index()\n",
    "\n",
    "# case_level = scheduled_df.groupby(['court', 'case_number']).agg({\n",
    "#     'set_date': lambda x: x.notna().any(),  # Was the case scheduled?\n",
    "#     'delivery_date': lambda x: x.notna().any(),  # Was the judgment delivered?\n",
    "#     'judgment_delayed': 'any'  # Was the judgment delayed for this case?\n",
    "# }).reset_index()\n",
    "\n",
    "# # Now aggregate to the judge level\n",
    "# judge_stats = case_level.groupby('court')['judgment_status'].value_counts().unstack(fill_value=0).reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Rename columns for clarity\n",
    "# judge_stats.columns.name = None\n",
    "# judge_stats = judge_stats.rename(columns={\n",
    "#     'Scheduled': 'scheduled_cases',\n",
    "#     'Delivered': 'delivered_cases',\n",
    "#     'Delayed': 'delayed_cases'\n",
    "# })\n",
    "\n",
    "# # Ensure all columns exist\n",
    "# for col in ['scheduled_cases', 'delivered_cases', 'delayed_cases']:\n",
    "#     if col not in judge_stats.columns:\n",
    "#         judge_stats[col] = 0\n",
    "\n",
    "# # Calculate total scheduled cases\n",
    "# judge_stats['scheduled_cases'] = judge_stats['delivered_cases'] + judge_stats['delayed_cases']\n",
    "\n",
    "# # Calculate proportions\n",
    "# judge_stats['delay_proportion'] = judge_stats['delayed_cases'] / judge_stats['scheduled_cases']\n",
    "# judge_stats['delivered_proportion'] = judge_stats['delivered_cases'] / judge_stats['scheduled_cases']\n",
    "\n",
    "# # Sort by delay proportion in descending order\n",
    "# judge_stats = judge_stats.sort_values('delay_proportion', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Group by judge and case_number to ensure each case is counted once per judge\n",
    "# case_level = scheduled_df.groupby(['court', 'case_number']).agg({\n",
    "#     'set_date': lambda x: x.notna().any(),  # Was the case scheduled?\n",
    "#     'delivery_date': lambda x: x.notna().any(),  # Was the judgment delivered?\n",
    "#     'judgment_delayed': 'any'  # Was the judgment delayed for this case?\n",
    "# }).reset_index()\n",
    "\n",
    "# # Now aggregate to the judge level\n",
    "# judge_stats = case_level.groupby('court').agg({\n",
    "#     'set_date': 'sum',  # Total scheduled cases\n",
    "#     'delivery_date': 'sum',  # Total delivered judgments\n",
    "#     'judgment_delayed': 'sum'  # Total delayed cases\n",
    "# }).reset_index()\n",
    "\n",
    "# # Rename columns for clarity\n",
    "# judge_stats.columns = ['court', 'scheduled_cases', 'delivered_cases', 'delayed_cases']\n",
    "\n",
    "# # Calculate the proportion of delayed cases among scheduled cases\n",
    "# judge_stats['delay_proportion'] = judge_stats['delayed_cases'] / judge_stats['scheduled_cases']\n",
    "\n",
    "# # Calculate the proportion of cases delivered on time\n",
    "# judge_stats['delivered_on_time_proportion'] = (judge_stats['delivered_cases'] - judge_stats['delayed_cases']) / judge_stats['scheduled_cases']\n",
    "\n",
    "# # Sort by delay proportion in descending order\n",
    "# judge_stats = judge_stats.sort_values('delay_proportion', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_199713/3487600709.py:40: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '126' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  result.loc[result['case_number'] == case_number, 'time_taken_days'] = time_taken_days\n"
     ]
    }
   ],
   "source": [
    "# df = df.sort_values('activity_date')\n",
    "# processed_df = calculate_judgment_time(df)\n",
    "# scheduled_df = determine_judgment_scheduling(processed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Group by judge and case_number to ensure each case is counted once per judge\n",
    "# case_level = scheduled_df.groupby(['court', 'case_number']).agg({\n",
    "#     'set_date': lambda x: x.notna().any(),  # Was the case scheduled?\n",
    "#     'delivery_date': lambda x: x.notna().any(),  # Was the judgment delivered?\n",
    "#     'judgment_delayed': 'any'  # Was the judgment delayed for this case?\n",
    "# }).reset_index()\n",
    "\n",
    "# # Now aggregate to the judge level\n",
    "# judge_stats = case_level.groupby('court').agg({\n",
    "#     'set_date': 'sum',  # Total scheduled cases\n",
    "#     'delivery_date': 'sum',  # Total delivered judgments\n",
    "#     'judgment_delayed': 'sum'  # Total delayed cases\n",
    "# }).reset_index()\n",
    "\n",
    "# # Rename columns for clarity\n",
    "# judge_stats.columns = ['court', 'scheduled_cases', 'delivered_cases', 'delayed_cases']\n",
    "\n",
    "# # Calculate the proportion of delayed cases among scheduled cases\n",
    "# judge_stats['delay_proportion'] = judge_stats['delayed_cases'] / judge_stats['scheduled_cases']\n",
    "\n",
    "# # Calculate the proportion of cases delivered as scheduled\n",
    "# judge_stats['delivered_as_scheduled_proportion'] = (judge_stats['delivered_cases'] - judge_stats['delayed_cases']) / judge_stats['scheduled_cases']\n",
    "\n",
    "# # Sort by number of delayed cases in descending order\n",
    "# judge_stats = judge_stats.sort_values('delayed_cases', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.max_columns', 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter where the set_date is not NaN \n",
    "set_df = scheduled_df[scheduled_df['set_date'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47096, 55)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduled_df = determine_judgment_scheduling(processed_df)\n",
    "# Group by judge and case_number to ensure each case is counted once per judge\n",
    "case_level = scheduled_df.groupby(['court', 'case_number']).agg({\n",
    "    'first_scheduled_date': lambda x: x.notna().any(),  # Was the case scheduled?\n",
    "    'judgment_delayed': 'any'  # Was the judgment delayed for this case?\n",
    "}).reset_index()\n",
    "\n",
    "# Now aggregate to the judge level\n",
    "judge_stats = case_level.groupby('court').agg({\n",
    "    'first_scheduled_date': 'sum',  # Total scheduled cases\n",
    "    'judgment_delayed': 'sum'  # Total delayed cases\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "judge_stats.columns = ['court', 'scheduled_cases', 'delayed_cases']\n",
    "\n",
    "# Calculate the proportion of delayed cases among scheduled cases\n",
    "judge_stats['delay_proportion'] = judge_stats['delayed_cases'] / judge_stats['scheduled_cases']\n",
    "\n",
    "# Sort by number of delayed cases in descending order\n",
    "judge_stats = judge_stats.sort_values('delayed_cases', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concluded_cases = df.groupby('court').agg({'concluded':'sum'}).reset_index()\n",
    "annual_df = df[\n",
    "    (df['activity_date'] >= pd.to_datetime('2023-07-01')) &\n",
    "    (df['activity_date'] <= pd.to_datetime('2024-06-30'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save \n",
    "filed_cases.to_csv(f'{file_path}/reports/total_filed_cases.csv', index=False)\n",
    "resolved_cases.to_csv(f'{file_path}/reports/total_resolved_cases.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by court and month of activity_date month \n",
    "monthly_concluded_cases = df.groupby(['court', 'broad_case_type', df['activity_date'].dt.month_name()]).agg({'concluded':'sum'}).reset_index()\n",
    "monthly_filed_cases = df.groupby(['court','broad_case_type',  df['activity_date'].dt.month_name()]).agg({'registered':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_concluded_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly_concluded_cases.to_csv(f'{file_path}/reports/all_concluded_cases.csv', index=False)\n",
    "monthly_filed_cases.to_csv(f'{file_path}/reports/all_filed_cases.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "court_productivity.to_csv(f'{file_path}/reports/court_merit_productivity.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "column_order = ['Murder', 'Criminal Appeal', 'Criminal Application', \n",
    "                'Criminal Revision', 'Civil Suit', 'Civil Appeal', 'Miscellaneous Application', \n",
    "                'Constitution Petition', 'Judicial Review',\n",
    "                  'Bankruptcy and Insolvency', 'Tax Appeal', \n",
    "                  'Adoption', 'Divorce', 'Probate Administration']\n",
    "resolved_cases.to_csv(f'{file_path}/reports/annual_resolved_cases.csv', columns=column_order, index=True)\n",
    "monthly_filed_cases.to_csv(f'{file_path}/reports/monthly_filed.csv', index=False)\n",
    "monthly_concluded_cases.to_csv(f'{file_path}/reports/monthly_concluded.csv', index=False)\n",
    "#court_productivity.to_csv(f'{file_path}/reports/court_productivity.csv', index=True)\n",
    "#average_time_to_conclude.to_csv(f'{file_path}/reports/average_time_to_conclude.csv', index=True)\n",
    "#resolved_within_pmmu_timeline.to_csv(f'{file_path}/reports/resolved_within_pmmu_timeline.csv', columns=column_order, index=True)\n",
    "#proportion_resolved_within_timeline_per_court.to_csv(f'/{file_path}/reports/proportion_resolved_within_timeline.csv')\n",
    "#judge_productivity.to_csv(f'{file_path}/reports/judge_productivity.csv', index=False)\n",
    "#adjourned_per_court.to_csv(f'{file_path}/reports/adjourn_per_court.csv', index=False)\n",
    "#adjourn_proportion.to_csv(f'{file_path}/reports/adjourn_proportion.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data\n",
    "column_order = ['Murder', 'Criminal Appeal', 'Criminal Application', \n",
    "                'Criminal Revision', 'Civil Suit', 'Civil Appeal', 'Miscellaneous Application', \n",
    "                'Constitution Petition', 'Judicial Review',\n",
    "                  'Bankruptcy and Insolvency', 'Tax Appeal', \n",
    "                  'Adoption', 'Probate Administration']\n",
    "filed_cases.to_csv(f'{file_path}/reports/annual_filed_cases.csv', columns=column_order, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determine Productivity per judge (Merit/Non Merit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.groupby('judge_1')['concluded'].sum().sort_values(ascending=False).reset_index(name='count').to_csv(f'{file_path}/reports/judge_productivity.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#judges = df['judge_1'].unique().tolist()\n",
    "#judge_productivity = df.groupby('judge_1')['concluded'].sum().sort_values(ascending=False).reset_index(name='count')\n",
    "#judge_productivity.to_csv(f'{output_path}/judge_productivity.csv', index=False)\n",
    "#judge_df.groupby(['judge_1', 'court'])['court'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # productivity per court\n",
    "# court_productivity = df.pivot_table(index='court', columns='productivity', values='concluded', aggfunc='sum', fill_value=0)\n",
    "# court_pivot = court_productivity.rename_axis(columns=None)\n",
    "# # matters handled by judge per court\n",
    "# matters_handled = judge_df.groupby(['court','judge_1'])['court'].count().reset_index(name='count')\n",
    "# # Resolved cases by judge per court\n",
    "# judge_court_productivity = judge_df.groupby(['judge_1', 'court'])['concluded'].sum().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pending Cases Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df_cases = merged_df[merged_df['resolved'] != 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = unique_df_cases.drop_duplicates(subset='case_number', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df = unique_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to get only the rows that are in pending_baseline but not in df\n",
    "only_in_baseline = unique_df[unique_df['_merge'] == 'left_only']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_in_baseline.groupby('court').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_dataframe(df):\n",
    "#     # Sort DataFrame by 'activity_date' in descending order\n",
    "#     df_sorted = df.sort_values(by=['court', 'year_filed'], ascending=False)\n",
    "    \n",
    "#     # Drop duplicates based on 'number_on_file' while keeping the first occurrence\n",
    "#     df_unique_cases = df_sorted.drop_duplicates(subset='case_number', keep='first')\n",
    "    \n",
    "#     # Filter unresolved cases\n",
    "#     unique_unresolved_cases = df_unique_cases[df_unique_cases['resolved'] == 0]\n",
    "    \n",
    "#     # Reset index\n",
    "#     unique_unresolved_cases = unique_unresolved_cases.reset_index(drop=True)\n",
    "    \n",
    "#     return unique_unresolved_cases\n",
    "# processed_df = preprocess_dataframe(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42628, 53)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_df.groupby('court')['court'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df.groupby('court')['court'].value_counts().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = ['court', 'comingfor', 'outcome', 'activity_date', 'filed_date', 'activity_date_year', 'activity_date_month', 'nature', 'case_category', 'case_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert both dataframes to sets of 'case_number' values\n",
    "pending_baseline_cases = set(pending_baseline['case_number'].unique())\n",
    "\n",
    "df_cases = set(df['case_number'].unique())\n",
    "\n",
    "# Find the cases present in df but not in df_a\n",
    "cases_not_in_pending = df_cases.difference(pending_baseline_cases)\n",
    "\n",
    "# Print the cases\n",
    "print(\"Cases present in df but not in df_a:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "cases_not_in_pending = pd.DataFrame(cases_not_in_pending)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85181, 1)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cases_not_in_pending.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(df, pending_baseline, on='case_number', how='left', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[combined_df['_merge'] == 'left_only'].drop(columns='_merge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df.sort_values(by=['court', 'activity_date', 'case_number'], ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert df_a['case_number'] to a set\n",
    "df_a_cases = set(pending_baseline['case_number'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_closed = df[(df['concluded'] == 1) & (df['case_number'].isin(df_a_cases))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter df based on 'outcome' == 1 and 'case_number' not in df_a_cases\n",
    "filtered_df = df[(df['concluded'] == 1) & ~(df['case_number'].isin(df_a_cases))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.groupby('court')['case_number'].count().sort_values(ascending=False).reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['resolved'] = filtered_df.groupby('case_number')['concluded'].transform('max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Drop duplicates based on 'number_on_file' while keeping the first occurrence\n",
    "filtered_df = filtered_df.drop_duplicates(subset='case_number', keep='first')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "nakuru = filtered_df[filtered_df['court'] == 'Milimani Anti Corruption and Economic Crimes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "nakuru.to_csv(f'{output_path}/nakuru.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_baseline.to_csv(f'{output_path}/pending_baseline_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.groupby('court')['case_number'].count().sort_values(ascending=False).reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>court</th>\n",
       "      <th>case_number</th>\n",
       "      <th>case_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [court, case_number, case_type]\n",
       "Index: []"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pending_baseline[pending_baseline['case_number'] == 'Busia/HCCCMISC/E026/2023']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backlog determination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas as pd\n",
    "# raw data of pending cases(next period baseline)\n",
    "#df = pd.read_csv(f'{output_path}/raw_pending_cases.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The date for computation of backlog ought to be the end of the quarter\n",
    "quarter_end = pd.to_datetime('2024-03-31')\n",
    "df['end_date'] = quarter_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a function to categorize ages\n",
    "def categorize_age(age):\n",
    "    if age <= 365:  # 0-1 years\n",
    "        return '0-1 years'\n",
    "    elif age <= 3 * 365:  # 1-3 years\n",
    "        return '1-3 years'\n",
    "    else:\n",
    "        return 'Over 3 years'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['filed_date'] = pd.to_datetime(df['filed_date'], format='%Y-%m-%d')\n",
    "processed_df['pending_age'] = (processed_df['end_date'] - processed_df['filed_date']).dt.days\n",
    "processed_df = processed_df[processed_df['pending_age'] >= 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df['age_group'] = processed_df['pending_age'].apply(categorize_age)\n",
    "backlog_category = processed_df.pivot_table(index='court', columns='age_group', values='unique_number', aggfunc='count', fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the data to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['Murder', 'Criminal Appeal', 'Criminal Application', \n",
    "                'Criminal Revision', 'Civil Suit', 'Civil Appeal', 'Miscellaneous Application', \n",
    "                'Constitution Petition', 'Judicial Review',\n",
    "                  'Bankruptcy and Insolvency', 'Tax Appeal', \n",
    "                  'Adoption', 'Divorce', 'Probate Administratio']\n",
    "# Total missing per month\n",
    "missing_per_month.to_csv(f'{output_path}/missing_outcomes_per_month.csv', index=False)\n",
    "\n",
    "# Total filed cases\n",
    "filed_cases.to_csv(f'{output_path}/filed_cases.csv', columns=column_order, index=True)\n",
    "\n",
    "# Total concluded cases\n",
    "concluded_cases.to_csv(f'{output_path}/concluded_cases.csv', columns=column_order, index=True)\n",
    "\n",
    "# Total filed, concluded and CCR per month\n",
    "monthly_cases.to_csv(f'{output_path}/monthly_cases.csv', index=False)\n",
    "\n",
    "# Productivity per court\n",
    "df_pivot.to_csv(f'{output_path}/productivity.csv', index=True)\n",
    "\n",
    "# Average time to conclude\n",
    "average_time_to_conclude.to_csv(f'{output_path}/average_time_to_conclude.csv', index=True)\n",
    "\n",
    "# Time lines\n",
    "proportion_resolved_within_timeline_per_court.to_csv(f'{output_path}/proportion_resolved_within_timeline.csv', index=True)\n",
    "\n",
    "judge_pivot.to_csv(f'{output_path}/judge_productivity.csv', index=True)\n",
    "\n",
    "judge_court_productivity.to_csv(f'{output_path}/judge_court_productivity.csv', index=False)\n",
    "\n",
    "court_pivot.to_csv(f'{output_path}/court_productivity.csv', index=True)\n",
    "\n",
    "matters_handled.to_csv(f'{output_path}/judge_matters_handled.csv', index=False)\n",
    "\n",
    "adjourned_per_court.to_csv(f'{output_path}/adjourned_per_court.csv', index=False)\n",
    "\n",
    "adjourn_proportion.to_csv(f'{output_path}/adjourn_proportion.csv', index=False)\n",
    "\n",
    "pending_cases.to_csv(f'{output_path}/hc_pending_cases.csv', index=True)\n",
    "\n",
    "backlog_category.to_csv(f'{output_path}/hc_backlog.csv', index=True)\n",
    "\n",
    "# raw data of pending cases(next period baseline)\n",
    "processed_df.to_csv(f'{output_path}/raw_pending_cases.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_resolved_within_timeline_per_court.to_csv(f'{output_path}/proportion_resolved_within_timeline.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COA Saving\n",
    "output_path = '/home/arch/devel/data/Report'\n",
    "'''\n",
    "column_order = ['murder', 'criminal_appeal', 'criminal_application', \n",
    "                'revision', 'suit', 'civil_appeal', 'misc_application', \n",
    "                'constitutional_petition', 'judicial_review',\n",
    "                  'bankruptcy_and_insolvency', 'tax_appeal', \n",
    "                  'adoption', 'divorce', 'probate_and_admin']\n",
    "\n",
    "'''\n",
    "column_order  = ['COA Criminal Appeal', 'Criminal Applications', 'Civil Appeal', 'Civil Applications']\n",
    "# Total missing per month\n",
    "missing_per_month.to_csv(f'{output_path}/missing_outcomes_per_month.csv', index=False)\n",
    "\n",
    "# Total filed cases\n",
    "filed_cases.to_csv(f'{output_path}/filed_cases.csv', index=True)\n",
    "\n",
    "# Total concluded cases\n",
    "concluded_cases.to_csv(f'{output_path}/concluded_cases.csv', index=True)\n",
    "\n",
    "# Total filed, concluded and CCR per month\n",
    "monthly_cases.to_csv(f'{output_path}/monthly_cases.csv', index=False)\n",
    "\n",
    "# Productivity per court\n",
    "df_pivot.to_csv(f'{output_path}/productivity.csv', index=True)\n",
    "\n",
    "# Average time to conclude\n",
    "average_time_to_conclude.to_csv(f'{output_path}/average_time_to_conclude.csv', index=True)\n",
    "\n",
    "# Time lines\n",
    "proportion_resolved_within_timeline_per_court.to_csv(f'{output_path}/proportion_resolved_within_timeline.csv', index=True)\n",
    "\n",
    "\n",
    "court_pivot.to_csv(f'{output_path}/court_productivity.csv', index=True)\n",
    "\n",
    "\n",
    "adjourned_per_court.to_csv(f'{output_path}/adjourned_per_court.csv', index=False)\n",
    "\n",
    "adjourn_proportion.to_csv(f'{output_path}/adjourn_proportion.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjourned_per_court.to_csv(f'{output_path}/KIBERA_adjourned_per_court.csv', index=False)\n",
    "\n",
    "adjourn_proportion.to_csv(f'{output_path}/KIBERA_adjourn_proportion.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_resolved_within_timeline_per_court.to_csv(f'{output_path}/proportion_resolved_within_timeline.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f'{output_path}/coa_cases.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cases_per_quarter(df, column):\n",
    "    # Group by quarters and count cases\n",
    "    cases_per_quarter = df.groupby(pd.Grouper(key='activity_date', freq='QE'))[column].sum()\n",
    "\n",
    "    # Reset index to make the quarters a column\n",
    "    cases_per_quarter = cases_per_quarter.reset_index()\n",
    "\n",
    "    # Rename the columns\n",
    "    cases_per_quarter.columns = ['quarter', f'cases_{column}']\n",
    "\n",
    "    return cases_per_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_case_nature_per_quarter(df: pd.DataFrame, column: str, nature: str):\n",
    "   \n",
    "    # Set up date range for quarters\n",
    "    quarters = df['activity_date'].dt.to_period('Q')\n",
    "\n",
    "    # Filter cases where concluded == 1 and case nature == 'civil'\n",
    "    filtered_df = df[(df[column] == 1) & (df['nature'] == nature)]\n",
    "\n",
    "    # Group by quarter and count cases\n",
    "    cases_per_quarter = filtered_df.groupby(quarters).size()\n",
    "\n",
    "    return cases_per_quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop if activity_date is null\n",
    "df = df.dropna(subset=['activity_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_adjourned =  get_cases_per_quarter(df, 'adjourned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_adjournable =  get_cases_per_quarter(df, 'adjournable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quarter</th>\n",
       "      <th>cases_adjournable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-30</td>\n",
       "      <td>87671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-12-31</td>\n",
       "      <td>102883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-03-31</td>\n",
       "      <td>86448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     quarter  cases_adjournable\n",
       "0 2023-09-30              87671\n",
       "1 2023-12-31             102883\n",
       "2 2024-03-31              86448"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quarterly_adjournable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_concluded =  get_cases_per_quarter(df, 'concluded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_concluded =  get_cases_per_quarter(df, 'concluded')\n",
    "quarterly_registered =  get_cases_per_quarter(df, 'registered')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge quarterly_concluded and quarterly_registered on quarter column\n",
    "merged_quarterly = pd.merge(quarterly_concluded, quarterly_registered, on='quarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('court', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['court', 'month'])['concluded'].sum().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_concluded_civil = get_case_nature_per_quarter(df, 'concluded', 'Civil')\n",
    "quarterly_registered_civil = get_case_nature_per_quarter(df, 'registered', 'Civil')\n",
    "\n",
    "quarterly_concluded_criminal = get_case_nature_per_quarter(df, 'concluded', 'Criminal')\n",
    "quarterly_registered_criminal = get_case_nature_per_quarter(df, 'registered', 'Criminal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge quarterly_concluded_civil quarterly_registered_civil quarterly_concluded_criminal quarterly_registered_criminal on quarter column \n",
    "merged_civil_criminal = pd.merge(quarterly_concluded_civil, quarterly_registered_civil, on='quarter')\n",
    "merged_civil_criminal = pd.merge(merged_civil_criminal, quarterly_concluded_criminal, on='quarter')\n",
    "merged_civil_criminal = pd.merge(merged_civil_criminal, quarterly_registered_criminal, on='quarter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_civil_criminal.to_csv(f'{output_path}/quarterly_case_nature.csv', index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "### adjourn by event\n",
    "### adjourn by case type\n",
    "\n",
    "### backlog by case type\n",
    "### check if there a courts that resolved more cases than pending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[(df['court'] == 'Milimani Commercial and Tax') & (df['activity_date_year'] == 2024)].groupby('judge_1').size().reset_index(name='count')\n",
    "# group by case_type if outcome == 'Ruling Delivered- Case Closed' \n",
    "#df[df['productivity'] == 'judgment'].groupby('case_category').size().reset_index(name='count')\n",
    "#court_productivity = df[df['productivity'] == 'ruling']\n",
    "#court_productivity_pivot = court_productivity.pivot_table(index='court', columns='case_category', values='concluded', aggfunc='sum', fill_value=0)\n",
    "#productivity_pivot = court_productivity_pivot.rename_axis(columns=None)\n",
    "#df[df['productivity'] == 'ruling'].groupby('case_category').size().reset_index(name='count')\n",
    "#df[df['outcome'] == 'Ruling Delivered- Accused Discharged'].groupby(['court', 'case_category'])['court'].size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_count = pending_df.groupby(['court', 'case_category']).size().reset_index(name='pending_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_pivot = pending_count.pivot_table(index='court', columns='case_category', values='pending_count', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_pivot.to_csv('/home/arch/devel/data/pending_case_types.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_concluded_cases(df):\n",
    "    \"\"\"\n",
    "    Categorize concluded cases into '1-3 year' and 'over 3 year' based on age column.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with an additional column 'age_category'.\n",
    "    \"\"\"\n",
    "    # Filter only concluded cases\n",
    "    df_concluded = df[df['concluded'] == 1]\n",
    "\n",
    "    # Calculate age in years\n",
    "    df_concluded['age_years'] = df_concluded['age'] / 365\n",
    "\n",
    "    # Categorize based on age\n",
    "    df_concluded.loc[:, 'age_category'] = df_concluded['age_years'].apply(lambda x: '1-3 year' if 1 <= x <= 3 else 'over 3 year')\n",
    "\n",
    "    # Merge back to original DataFrame\n",
    "    df = pd.merge(df, df_concluded[['case_number', 'age_category']], on='case_number', how='left')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = categorize_concluded_cases(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby judge_1 if court == 'Milimani Commercial and Tax' \n",
    "#df(df['court'] == 'Milimani Commercial and Tax').groupby([ 'judge_1',])['outcome'].size().reset_index(name='count')\n",
    "df[df['court'] == 'Meru'].groupby(['judge_1'])['outcome'].size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by court if case_type == 'Murder Case' and registered == 1\n",
    "df[(df['case_type'] == 'Criminal Appeal') & (df['outcome'] == 'File Transferred')].groupby('court').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['comingfor', 'outcome',  'male_applicant', 'female_applicant',\n",
    "       'organization_applicant', 'male_defendant', 'female_defendant',\n",
    "       'organization_defendant', 'legalrep', 'court',\n",
    "       'activity_date', 'filed_date', 'activity_date_year',\n",
    "       'activity_date_month', 'nature', 'case_category', 'case_number',\n",
    "       'registered', 'concluded', 'productivity', 'age', 'time_lines',\n",
    "       'adjourned', 'adjournable']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "   # Drop duplicates based on 'number_on_file' while keeping the first occurrence\n",
    "df_unique_cases = df.drop_duplicates(subset='case_number', keep='last')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103156, 53)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_unique_cases.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filed_df = df[df['registered'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_applicants = filed_df[(filed_df['male_applicant'] >= 1) & (filed_df['broad_case_type'] != 'Murder')].groupby('broad_case_type').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_applicants = filed_df[(filed_df['female_applicant'] > 0) & (filed_df['broad_case_type'] != 'Murder')].groupby('broad_case_type').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_accused = filed_df[(filed_df['male_defendant'] == 1) & (filed_df['broad_case_type'] == 'Murder')].groupby('broad_case_type').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_murder_defendants = filed_df[(filed_df['male_defendant'] == 1) & (filed_df['broad_case_type'] == 'Murder')].groupby('broad_case_type').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_murder_defendants = filed_df[(filed_df['female_defendant'] == 1) & (filed_df['broad_case_type'] == 'Murder')].groupby('broad_case_type').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicants = pd.merge(female_applicants, male_applicants, on='broad_case_type', how='outer', suffixes=('_female', '_male'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "respodents = pd.merge(female_murder_defendants, male_murder_defendants, on='broad_case_type', how='outer', suffixes=('_female', '_male'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>broad_case_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Murder</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  broad_case_type  count\n",
       "0          Murder    202"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['broad_case_type'] == 'Murder') & (df['female_defendant'] > 0) & (df['registered'] == 1)].groupby('broad_case_type').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['court', 'date_dd', 'date_mon', 'date_yyyy', 'caseid_type', 'caseid_no',\n",
       "       'filed_dd', 'filed_mon', 'filed_yyyy', 'original_court',\n",
       "       'original_code', 'original_number', 'original_year', 'case_type',\n",
       "       'judge_1', 'judge_2', 'judge_3', 'judge_4', 'judge_5', 'judge_6',\n",
       "       'judge_7', 'comingfor', 'outcome', 'reason_adj', 'next_dd', 'next_mon',\n",
       "       'next_yyyy', 'male_applicant', 'female_applicant',\n",
       "       'organization_applicant', 'male_defendant', 'female_defendant',\n",
       "       'organization_defendant', 'legalrep', 'applicant_witness',\n",
       "       'defendant_witness', 'custody', 'other_details', 'activity_date',\n",
       "       'filed_date', 'next_date', 'nature', 'broad_case_type', 'case_number',\n",
       "       'concluded', 'registered', 'productivity', 'age', 'time_lines',\n",
       "       'adjourned', 'adjournable'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "applicants.to_csv(f'{file_path}/reports/applicants_gender.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "bplot = ax.boxplot(pending_baseline['total_events'],\n",
    "                     vert=False,  # Set vert to False for a vertical box plot\n",
    "                     patch_artist=True) \n",
    "\n",
    "# Add labels for median, mean, etc.\n",
    "# Add labels for median, lower quartile, upper quartile, and outliers\n",
    "for line in bplot.keys():\n",
    "    if line == 'medians':\n",
    "        for median in bplot[line]:\n",
    "            ax.text(median.get_xdata()[0], median.get_ydata()[0],\n",
    "                    f'{median.get_xdata()[0]:.1f}', ha='center', va='bottom', color='red', fontsize=10)\n",
    "    elif line == 'whiskers':\n",
    "        for whisker in bplot[line]:\n",
    "            ax.text(whisker.get_xdata()[0], whisker.get_ydata()[0],\n",
    "                    f'{whisker.get_xdata()[0]:.1f}', ha='center', va='bottom', color='green', fontsize=10)\n",
    "            ax.text(whisker.get_xdata()[1], whisker.get_ydata()[1],\n",
    "                    f'{whisker.get_xdata()[1]:.1f}', ha='center', va='bottom', color='green', fontsize=10)\n",
    "    elif line == 'fliers':\n",
    "        for fliers in bplot[line]:\n",
    "            for f in fliers.get_xdata():\n",
    "                ax.text(f, fliers.get_ydata()[0], f'{f:.1f}', ha='center', va='bottom', color='blue', fontsize=10)\n",
    "\n",
    "\n",
    "ax.set_title('Workload Analysis')\n",
    "ax.set_xlabel('Cases per Judge')\n",
    "\n",
    "# Set face color for the box plot\n",
    "colors = ['lightgreen']\n",
    "for patch, color in zip(bplot['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "data = [pending_baseline['total_events']]\n",
    "\n",
    "# Create a box plot with horizontal orientation\n",
    "fig, ax = plt.subplots()\n",
    "bplot = ax.boxplot(data, vert=True, patch_artist=True)\n",
    "\n",
    "# Add labels for median, mean, etc.\n",
    "for line in bplot.keys():\n",
    "    if line == 'medians':\n",
    "        for median in bplot[line]:\n",
    "            # Add label for median\n",
    "            ax.text(median.get_xdata()[0], median.get_ydata()[0],\n",
    "                    f'{median.get_xdata()[0]:.2f}', ha='center', va='bottom', color='red', fontsize=8)\n",
    "    elif line == 'fliers':\n",
    "        for fliers in bplot[line]:\n",
    "            # Add labels for outliers\n",
    "            for f in fliers.get_xdata():\n",
    "                ax.text(f, fliers.get_ydata()[0], f'{f:.2f}', ha='center', va='bottom', color='blue', fontsize=8)\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Workload')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Workload Analysis')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of circuits\n",
    "circuit_court = [\n",
    "'Kapenguria',\n",
    "'Garsen',\n",
    "'Lodwar',\n",
    "'Nyahururu',\n",
    "'Kwale',\n",
    "'Eldama',\n",
    "'Iten',\n",
    "'Kilgoris',\n",
    "'Mandera',\n",
    "'Maralal']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_mobile = [\n",
    "'Milimani Civil',\n",
    "'Meru',\n",
    "'Kericho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the rows where 'court' is in the list\n",
    "df2 = df1[df1['court'].isin(non_mobile)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the rows where 'court' is in the list\n",
    "df1 = df[df['court'].isin(circuit_court)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "judges = df2['judge_1'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.groupby('court').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hon Justice Jesse Nyaga\n",
    "Hon Justice Lucy Gitari\n",
    "Hon Justice Joseph Karanja\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judge_1</th>\n",
       "      <th>judge</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gitari, Lucy</td>\n",
       "      <td>1146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karanja, Joseph R.</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Njagi, Jesse Nyaga</td>\n",
       "      <td>1042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              judge_1  judge\n",
       "0        Gitari, Lucy   1146\n",
       "1  Karanja, Joseph R.    554\n",
       "2  Njagi, Jesse Nyaga   1042"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby('judge_1').size().reset_index(name='judge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "circut_judge = ['Njagi, Jesse Nyaga', 'Gitari, Lucy', 'Karanja, Joseph R.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2['judge_1'].isin(circut_judge)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judge_1</th>\n",
       "      <th>court</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gitari, Lucy</td>\n",
       "      <td>Meru</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Karanja, Joseph R.</td>\n",
       "      <td>Kericho</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Njagi, Jesse Nyaga</td>\n",
       "      <td>Meru</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Njagi, Jesse Nyaga</td>\n",
       "      <td>Milimani Civil</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              judge_1           court  count\n",
       "0        Gitari, Lucy            Meru    101\n",
       "1  Karanja, Joseph R.         Kericho    105\n",
       "2  Njagi, Jesse Nyaga            Meru      0\n",
       "3  Njagi, Jesse Nyaga  Milimani Civil     98"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.groupby(['judge_1', 'court'])['concluded'].sum().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine df1 and df2\n",
    "combined_df = pd.concat([df1, df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('court_circuits.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judge_1</th>\n",
       "      <th>court</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gikonyo, Francis Muthuku</td>\n",
       "      <td>Kilgoris</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kipkorir, Weldon Kipyegon</td>\n",
       "      <td>Kapenguria</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Anne Ong'injo</td>\n",
       "      <td>Garsen</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anne Ong'injo</td>\n",
       "      <td>Kwale</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Auka, Christine Kemuma</td>\n",
       "      <td>Kwale</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Wambua.josephine Wayua</td>\n",
       "      <td>Kapenguria</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Wananda,robert Anuro</td>\n",
       "      <td>Iten</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Wananda,robert Anuro</td>\n",
       "      <td>Kapenguria</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Wanyanga, James Helekia Sijenyi</td>\n",
       "      <td>Maralal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Waswa, Cyprian  Wafula</td>\n",
       "      <td>Kilgoris</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            judge_1       court  count\n",
       "0          Gikonyo, Francis Muthuku    Kilgoris     70\n",
       "1         Kipkorir, Weldon Kipyegon  Kapenguria      0\n",
       "2                     Anne Ong'injo      Garsen      0\n",
       "3                     Anne Ong'injo       Kwale     33\n",
       "4            Auka, Christine Kemuma       Kwale      0\n",
       "..                              ...         ...    ...\n",
       "62           Wambua.josephine Wayua  Kapenguria      0\n",
       "63             Wananda,robert Anuro        Iten     64\n",
       "64             Wananda,robert Anuro  Kapenguria      0\n",
       "65  Wanyanga, James Helekia Sijenyi     Maralal      0\n",
       "66           Waswa, Cyprian  Wafula    Kilgoris     33\n",
       "\n",
       "[67 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.groupby(['judge_1', 'court'])['concluded'].sum().reset_index(name='count')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
