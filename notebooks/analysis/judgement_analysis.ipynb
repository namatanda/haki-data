{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "from typing import Dict, Any, List, Union, Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_columns', 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4463/2985956275.py:2: DtypeWarning: Columns (15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(f'{file_path}/processed_23-24_df.csv')\n"
     ]
    }
   ],
   "source": [
    "file_path = '/home/stanoo/dcrt/data'\n",
    "df = pd.read_csv(f'{file_path}/processed_23-24_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "problematic_columns = df.columns[df.apply(lambda col: col.astype(str).str.contains(r\"[\\u2019]\").any())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stations\n",
    "stations = df.court.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "hc_stations = ['Marsabit', 'Embu', 'Chuka', 'Muranga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = df[df['court'].isin(hc_stations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>court</th>\n",
       "      <th>date_dd</th>\n",
       "      <th>date_mon</th>\n",
       "      <th>date_yyyy</th>\n",
       "      <th>caseid_type</th>\n",
       "      <th>caseid_no</th>\n",
       "      <th>filed_dd</th>\n",
       "      <th>filed_mon</th>\n",
       "      <th>filed_yyyy</th>\n",
       "      <th>original_court</th>\n",
       "      <th>...</th>\n",
       "      <th>broad_case_type</th>\n",
       "      <th>case_number</th>\n",
       "      <th>concluded</th>\n",
       "      <th>registered</th>\n",
       "      <th>merit_category</th>\n",
       "      <th>age</th>\n",
       "      <th>timely</th>\n",
       "      <th>adjourned</th>\n",
       "      <th>adjournable</th>\n",
       "      <th>transfer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170573</th>\n",
       "      <td>Embu</td>\n",
       "      <td>19</td>\n",
       "      <td>Jul</td>\n",
       "      <td>2023</td>\n",
       "      <td>HCCC</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>Nov</td>\n",
       "      <td>2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Civil Matter</td>\n",
       "      <td>Embu/HCCC/6/2018</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1718</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170574</th>\n",
       "      <td>Embu</td>\n",
       "      <td>25</td>\n",
       "      <td>Sep</td>\n",
       "      <td>2023</td>\n",
       "      <td>HCFP&amp;A</td>\n",
       "      <td>640</td>\n",
       "      <td>11</td>\n",
       "      <td>Dec</td>\n",
       "      <td>2014</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Probate Administration</td>\n",
       "      <td>Embu/HCFP&amp;A/640/2014</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3210</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170575</th>\n",
       "      <td>Embu</td>\n",
       "      <td>6</td>\n",
       "      <td>Jul</td>\n",
       "      <td>2023</td>\n",
       "      <td>HCFP&amp;A</td>\n",
       "      <td>329</td>\n",
       "      <td>8</td>\n",
       "      <td>Aug</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Probate Administration</td>\n",
       "      <td>Embu/HCFP&amp;A/329/2011</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4350</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170576</th>\n",
       "      <td>Embu</td>\n",
       "      <td>5</td>\n",
       "      <td>Jul</td>\n",
       "      <td>2023</td>\n",
       "      <td>HCCRC</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Feb</td>\n",
       "      <td>2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Murder</td>\n",
       "      <td>Embu/HCCRC/3/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>Merit Resolution</td>\n",
       "      <td>1227</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170577</th>\n",
       "      <td>Embu</td>\n",
       "      <td>6</td>\n",
       "      <td>Jul</td>\n",
       "      <td>2023</td>\n",
       "      <td>HCFP&amp;A</td>\n",
       "      <td>E016</td>\n",
       "      <td>12</td>\n",
       "      <td>Jul</td>\n",
       "      <td>2022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Probate Administration</td>\n",
       "      <td>Embu/HCFP&amp;A/E016/2022</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>359</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       court  date_dd date_mon  date_yyyy caseid_type caseid_no  filed_dd  \\\n",
       "170573  Embu       19      Jul       2023        HCCC         6         4   \n",
       "170574  Embu       25      Sep       2023      HCFP&A       640        11   \n",
       "170575  Embu        6      Jul       2023      HCFP&A       329         8   \n",
       "170576  Embu        5      Jul       2023       HCCRC         3        24   \n",
       "170577  Embu        6      Jul       2023      HCFP&A      E016        12   \n",
       "\n",
       "       filed_mon  filed_yyyy original_court  ...         broad_case_type  \\\n",
       "170573       Nov        2018            NaN  ...            Civil Matter   \n",
       "170574       Dec        2014            NaN  ...  Probate Administration   \n",
       "170575       Aug        2011            NaN  ...  Probate Administration   \n",
       "170576       Feb        2020            NaN  ...                  Murder   \n",
       "170577       Jul        2022            NaN  ...  Probate Administration   \n",
       "\n",
       "                  case_number  concluded registered    merit_category   age  \\\n",
       "170573       Embu/HCCC/6/2018          0      False               NaN  1718   \n",
       "170574   Embu/HCFP&A/640/2014          0      False               NaN  3210   \n",
       "170575   Embu/HCFP&A/329/2011          0      False               NaN  4350   \n",
       "170576      Embu/HCCRC/3/2020          1      False  Merit Resolution  1227   \n",
       "170577  Embu/HCFP&A/E016/2022          0      False               NaN   359   \n",
       "\n",
       "       timely  adjourned  adjournable  transfer  \n",
       "170573  False          0            1     False  \n",
       "170574  False          0            1     False  \n",
       "170575  False          0            1     False  \n",
       "170576  False          0            1     False  \n",
       "170577  False          0            1     False  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['judge_1'] = df['judge_1'].astype(str).str.replace(r\"[\\u2019]\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>outcome</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Order Issued - Case Closed</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Consolidated- Case Closed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Judgment Delivered- Case Closed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Terminated</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           outcome  count\n",
       "0       Order Issued - Case Closed      3\n",
       "1        Consolidated- Case Closed      1\n",
       "2  Judgment Delivered- Case Closed      1\n",
       "3                       Terminated      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[(df['court'] == 'Iten') & (df['concluded'] == 1) & (df['broad_case_type']=='Murder')].groupby('outcome')['concluded'].count().sort_values(ascending=False).reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop the columns  'set_date', 'delivery_date', 'time_taken_days', 'judgment_status', 'delivery_category' from milimani_df\n",
    "# df = df.drop(['set_date', 'delivery_date', 'time_taken_days', 'judgment_status', 'delivery_category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_column(df: pd.DataFrame, column_names: List[str], new_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a new date column in the DataFrame by concatenating the values of three specified columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_names (List[str]): A list of three column names to be concatenated [year, month, day].\n",
    "        new_col (str): The name of the new date column to be created.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new date column added.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input list doesn't contain exactly three column names or if columns are missing.\n",
    "    \"\"\"\n",
    "    if len(column_names) != 3:\n",
    "        raise ValueError(\"column_names must contain exactly three elements: [year, month, day]\")\n",
    "\n",
    "    year_col, month_col, day_col = column_names\n",
    "\n",
    "    # Check if all required columns exist in the DataFrame\n",
    "    missing_columns = set(column_names) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Create copies to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "\n",
    "    try:\n",
    "        # Convert year and day columns to integers\n",
    "        df[year_col] = df[year_col].astype(float).astype(int)\n",
    "        df[day_col] = df[day_col].astype(float).astype(int)\n",
    "\n",
    "        # Concatenate the columns to create a date string\n",
    "        df[new_col] = (df[year_col].astype(str) + '-' + \n",
    "                       df[month_col].astype(str) + '-' + \n",
    "                       df[day_col].astype(str))\n",
    "\n",
    "        # Convert to datetime\n",
    "        df[new_col] = pd.to_datetime(df[new_col], errors='coerce')\n",
    "\n",
    "        # Log information about the conversion\n",
    "        valid_dates = df[new_col].notna().sum()\n",
    "        logger.info(f\"Created new date column '{new_col}'. Valid dates: {valid_dates}/{len(df)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating date column: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_121153/4091687294.py:40: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[new_col] = pd.to_datetime(df[new_col], errors='coerce')\n",
      "2024-11-04 09:16:16,989 - INFO - Created new date column 'next_date'. Valid dates: 427065/508802\n"
     ]
    }
   ],
   "source": [
    "df = create_date_column(df.copy(), ['next_dd', 'next_mon', 'next_yyyy'], 'next_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where the sheduled/next date is outside the evaluation period\n",
    "cutoff_date = pd.Timestamp('2024-06-30') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_judgment_scheduling(df, cutoff_date):\n",
    "    judgment_date_set_outcomes = [\"Judgment Date Given\", \"Judgment On Notice\", \"Judgment Date Set\"]\n",
    "    judgment_delivered_outcomes = [\"Grant Revoked\", \"Judgment Delivered\", \n",
    "                                   \"Judgment Delivered- Acquittal\", \"Judgment Delivered- Case Closed\", \n",
    "                                   \"Judgment Delivered- Convicted\"]\n",
    "    \n",
    "    # Preprocessing: Filter and sort the DataFrame upfront\n",
    "    df_filtered = df[df['outcome'].isin(judgment_date_set_outcomes + judgment_delivered_outcomes)]\n",
    "    df_filtered = df_filtered.sort_values(by=['case_number', 'activity_date'])\n",
    "    \n",
    "    # Initialize columns\n",
    "    df['judgment_status'] = 'Not Scheduled'\n",
    "    df['set_date'] = pd.NaT\n",
    "    df['delivery_date'] = pd.NaT\n",
    "    df['delivery_category'] = ''\n",
    "    \n",
    "    # Filter rows with judgment set outcomes and valid schedule dates\n",
    "    judgment_set_rows = df_filtered[df_filtered['outcome'].isin(judgment_date_set_outcomes) & \n",
    "                                    (df_filtered['next_date'] <= cutoff_date)]\n",
    "    \n",
    "    # For each case, find the earliest set date\n",
    "    earliest_schedule = judgment_set_rows.groupby('case_number').first().reset_index()\n",
    "    \n",
    "    # Create dictionaries to map case numbers to their schedule dates and statuses\n",
    "    case_to_set_date = dict(zip(earliest_schedule['case_number'], earliest_schedule['next_date']))\n",
    "    case_to_status = {case: 'Scheduled' for case in earliest_schedule['case_number']}\n",
    "    \n",
    "    # Update the result dataframe with schedule information\n",
    "    df['set_date'] = df['case_number'].map(case_to_set_date)\n",
    "    df['judgment_status'] = df['case_number'].map(case_to_status).fillna('Not Scheduled')\n",
    "    df['delivery_category'] = df['case_number'].map(case_to_status).fillna('')\n",
    "    \n",
    "    # Filter rows with judgment delivered outcomes\n",
    "    judgment_delivered_rows = df_filtered[df_filtered['outcome'].isin(judgment_delivered_outcomes)]\n",
    "    \n",
    "    # Find the first delivery date after set date\n",
    "    for case_number, group in earliest_schedule.groupby('case_number'):\n",
    "        set_date = group['next_date'].values[0]\n",
    "        delivery = judgment_delivered_rows[(judgment_delivered_rows['case_number'] == case_number) & \n",
    "                                           (judgment_delivered_rows['activity_date'] >= set_date)]\n",
    "        \n",
    "        if not delivery.empty:\n",
    "            delivery_date = delivery.iloc[0]['activity_date']\n",
    "            df.loc[df['case_number'] == case_number, 'delivery_date'] = delivery_date\n",
    "            df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "            \n",
    "            if delivery_date <= set_date:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'On Time'\n",
    "            else:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'Delayed'\n",
    "        else:\n",
    "            earlier_delivery = judgment_delivered_rows[(judgment_delivered_rows['case_number'] == case_number) & \n",
    "                                                       (judgment_delivered_rows['activity_date'] < set_date)]\n",
    "            if earlier_delivery.empty:\n",
    "                if cutoff_date >= set_date:\n",
    "                    df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delayed'\n",
    "                    df.loc[df['case_number'] == case_number, 'delivery_category'] = 'Delayed'\n",
    "            else:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_date'] = earlier_delivery.iloc[0]['activity_date']\n",
    "                df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'On Time'\n",
    "    \n",
    "    return df[df['set_date'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'less_equal' did not contain a loop with signature matching types (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.StrDType'>) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[50], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m judgement_df \u001b[38;5;241m=\u001b[39m \u001b[43mdetermine_judgment_scheduling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff_date\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[15], line 40\u001b[0m, in \u001b[0;36mdetermine_judgment_scheduling\u001b[0;34m(df, cutoff_date)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m case_number, group \u001b[38;5;129;01min\u001b[39;00m earliest_schedule\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcase_number\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     38\u001b[0m     set_date \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     39\u001b[0m     delivery \u001b[38;5;241m=\u001b[39m judgment_delivered_rows[(judgment_delivered_rows[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcase_number\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m case_number) \u001b[38;5;241m&\u001b[39m \n\u001b[0;32m---> 40\u001b[0m                                        (\u001b[43mjudgment_delivered_rows\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivity_date\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mset_date\u001b[49m)]\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m delivery\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     43\u001b[0m         delivery_date \u001b[38;5;241m=\u001b[39m delivery\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity_date\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/haki-data-K3z4TeDN-py3.12/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/haki-data-K3z4TeDN-py3.12/lib/python3.12/site-packages/pandas/core/arraylike.py:60\u001b[0m, in \u001b[0;36mOpsMixin.__ge__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__ge__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__ge__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/haki-data-K3z4TeDN-py3.12/lib/python3.12/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/haki-data-K3z4TeDN-py3.12/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/haki-data-K3z4TeDN-py3.12/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32mops.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.ops.scalar_compare\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'less_equal' did not contain a loop with signature matching types (<class 'numpy.dtypes.DateTime64DType'>, <class 'numpy.dtypes.StrDType'>) -> None"
     ]
    }
   ],
   "source": [
    "judgement_df = determine_judgment_scheduling(df, cutoff_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_on_time_delivery_proportions(scheduled_cases):\n",
    "    # Get the final status for each case\n",
    "    final_status = scheduled_cases.groupby(['court', 'case_number']).last().reset_index()\n",
    "    \n",
    "    # Group by court and calculate statistics\n",
    "    court_stats = final_status.groupby('court').agg({\n",
    "        'case_number': 'count',\n",
    "        'delivery_category': lambda x: (x == 'On Time').sum()\n",
    "    }).rename(columns={\n",
    "        'case_number': 'total_scheduled',\n",
    "        'delivery_category': 'delivered_on_time'\n",
    "    })\n",
    "    \n",
    "    # Calculate the proportion\n",
    "    court_stats['proportion_on_time'] = court_stats['delivered_on_time'] / court_stats['total_scheduled']\n",
    "    \n",
    "    return court_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions2 = get_on_time_delivery_proportions(judgement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportions2.to_csv(f'{file_path}/reports/scheduled_judgement.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_judgment_time(df):\n",
    "    # Define the outcomes representing judgment date set and judgment delivered\n",
    "    judgment_date_set_outcomes = [\"Judgment Date Given\", \"Judgment On Notice\", \"Judgment Date Set\"]\n",
    "    judgment_delivered_outcomes = [\"Grant Revoked\", \"Judgment Delivered\", \n",
    "                                   \"Judgment Delivered- Acquittal\", \"Judgment Delivered- Case Closed\", \n",
    "                                   \"Judgment Delivered- Convicted\"]\n",
    "\n",
    "    # Create a copy of the original DataFrame to avoid modifying it\n",
    "    result = df.copy()\n",
    "\n",
    "    result['time_taken_days'] = pd.NaT\n",
    "\n",
    "    # Group by case_number\n",
    "    grouped = df.groupby('case_number')\n",
    "\n",
    "    for case_number, group in grouped:\n",
    "        # Find the minimum judgment set date\n",
    "        set_date = group[group['outcome'].isin(judgment_date_set_outcomes)]['activity_date'].min()\n",
    "        \n",
    "        # Find the maximum judgment delivered date\n",
    "        delivery_date = group[group['outcome'].isin(judgment_delivered_outcomes)]['activity_date'].max()\n",
    "\n",
    "        # If there is no set date but there is a delivery date and an earliest \"Judgement\" entry\n",
    "        earliest_judgement_date = group[group['comingfor'] == \"Judgement\"]['activity_date'].min()\n",
    "        if pd.isna(set_date) and pd.notna(delivery_date) and pd.notna(earliest_judgement_date):\n",
    "            # Get dates for the same case before the earliest \"Judgement\"\n",
    "            previous_dates = group[(group['activity_date'] < earliest_judgement_date) & (group['activity_date'] >= group['activity_date'].min())]['activity_date']\n",
    "\n",
    "            if not previous_dates.empty:\n",
    "                set_date = previous_dates.max()\n",
    "\n",
    "        # If both dates are available, calculate the time taken\n",
    "        if pd.notna(set_date) and pd.notna(delivery_date):\n",
    "            time_taken_days = (delivery_date - set_date).days\n",
    "            result.loc[result['case_number'] == case_number, 'set_date'] = set_date\n",
    "            result.loc[result['case_number'] == case_number, 'delivery_date'] = delivery_date\n",
    "            result.loc[result['case_number'] == case_number, 'time_taken_days'] = time_taken_days\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_taken = calculate_judgment_time(judgement_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivered_df = time_taken[time_taken['judgment_status']=='Delivered']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivered_status = delivered_df.groupby(['court', 'case_number']).last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivered_status['within_60_days'] = delivered_status['time_taken_days'] <= 60\n",
    "# group the data by court and calculate the proportion of cases within 60 days\n",
    "within_60_days = delivered_status.groupby('court').agg({\n",
    "    'case_number': 'count',\n",
    "    'within_60_days': lambda x: (x == True).sum()\n",
    "}).rename(columns={\n",
    "    'case_number': 'total_scheduled',\n",
    "    'within_60_days': 'delivered_within_60_days'\n",
    "})\n",
    "\n",
    "within_60_days['proportion_within_60_days'] = within_60_days['delivered_within_60_days'] / within_60_days['total_scheduled']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "within_60_days.to_csv(f'{file_path}/reports/delivered_within_60_days.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_case_resolution_proportions(df, case_type_timelines):\n",
    "    # Convert date columns to datetime\n",
    "    date_columns = ['filed_date', 'activity_date']\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    # Function to check if a case is resolved within timeline\n",
    "    def is_resolved_within_timeline(row):\n",
    "        timeline = case_type_timelines.get(row['broad_case_type'], float('inf'))\n",
    "        return row['concluded'] == 1 and row['age'] <= timeline\n",
    "\n",
    "    # Group by court and case type, then calculate statistics\n",
    "    stats = df.groupby(['court', 'broad_case_type']).apply(\n",
    "        lambda x: pd.Series({\n",
    "            'total_cases': len(x),\n",
    "            'resolved_within_timeline': sum(x.apply(is_resolved_within_timeline, axis=1)),\n",
    "            'proportion_resolved': sum(x.apply(is_resolved_within_timeline, axis=1)) / len(x) if len(x) > 0 else 0\n",
    "        })\n",
    "    ).reset_index()\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_case_resolution_data(df, case_type_timelines):\n",
    "    # Convert date columns to datetime\n",
    "    date_columns = ['filed_date', 'activity_date']\n",
    "    for col in date_columns:\n",
    "        df[col] = pd.to_datetime(df[col])\n",
    "    \n",
    "    # Function to check if a case is resolved within timeline\n",
    "    def is_resolved_within_timeline(row, case_type, timeline):\n",
    "        return 1 if row['concluded'] == 1 and row['age'] <= timeline and row['broad_case_type'] == case_type else 0\n",
    "\n",
    "    # Add a column for each case type indicating if it's resolved within timeline\n",
    "    for case_type, timeline in case_type_timelines.items():\n",
    "        column_name = f\"{case_type}_{timeline}_days\"\n",
    "        df[column_name] = df.apply(\n",
    "            lambda row: is_resolved_within_timeline(row, case_type, timeline), \n",
    "            axis=1\n",
    "        )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_case_resolution_pivot(df, case_type_timelines):\n",
    "    # Prepare the aggfunc dictionary\n",
    "    aggfunc = {}\n",
    "    for case_type, timeline in case_type_timelines.items():\n",
    "        column = f\"{case_type}_{timeline}_days\"\n",
    "        aggfunc[f\"{column}_total\"] = 'count'\n",
    "        aggfunc[f\"{column}_resolved\"] = 'sum'\n",
    "        aggfunc[f\"{column}_proportion\"] = lambda x: x.sum() / x.count() if x.count() > 0 else 0\n",
    "\n",
    "    # Create pivot table\n",
    "    pivot = pd.pivot_table(\n",
    "        df,\n",
    "        values=[f\"{case_type}_{timeline}_days\" for case_type, timeline in case_type_timelines.items()],\n",
    "        index=['court'],\n",
    "        aggfunc=aggfunc\n",
    "    )\n",
    "\n",
    "    # Rename columns to match the desired format\n",
    "    new_columns = []\n",
    "    for case_type, timeline in case_type_timelines.items():\n",
    "        for stat in ['total', 'resolved', 'proportion']:\n",
    "            new_columns.append(f\"{case_type}_{timeline}_days_{stat}\")\n",
    "    \n",
    "    pivot.columns = new_columns\n",
    "\n",
    "    return pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Assuming df is your original dataframe\n",
    "prepared_df = prepare_case_resolution_data(df, case_type_timelines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "case_type_timelines = {\n",
    "    'Murder': 360,\n",
    "    'Criminal Revision': 90,\n",
    "    'Miscellaneous Application': 90,\n",
    "    'Civil Suit': 360,\n",
    "    'Judicial Review': 180,\n",
    "    'Constitution Petition': 180,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivot_table(df, case_type_timelines):\n",
    "  # Calculate statistics using your existing function\n",
    "  stats = get_case_resolution_proportions(df, case_type_timelines)\n",
    "\n",
    "  # Pivot the data\n",
    "  pivot_table = stats.pivot_table(\n",
    "      index='court',\n",
    "      columns='broad_case_type',\n",
    "      values=['total_cases', 'resolved_within_timeline', 'proportion_resolved']\n",
    "  )\n",
    "\n",
    "  # Flatten the column hierarchy\n",
    "  pivot_table.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_table.columns]\n",
    "\n",
    "  return pivot_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3738/877221319.py:13: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stats = df.groupby(['court', 'broad_case_type']).apply(\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have df and case_type_timelines\n",
    "pivot_table = create_pivot_table(df, case_type_timelines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_case_resolution_proportions(df, case_type_timelines):\n",
    "  # Convert date columns to datetime\n",
    "  date_columns = ['filed_date', 'activity_date']\n",
    "  for col in date_columns:\n",
    "    df[col] = pd.to_datetime(df[col])\n",
    "\n",
    "  # Filter cases based on case_type_timelines\n",
    "  df = df[df['broad_case_type'].isin(case_type_timelines.keys())]\n",
    "\n",
    "  # Function to check if a case is resolved within timeline\n",
    "  def is_resolved_within_timeline(row):\n",
    "    timeline = case_type_timelines.get(row['broad_case_type'], float('inf'))\n",
    "    return row['concluded'] == 1 and row['age'] <= timeline\n",
    "\n",
    "  # Group by court and case type, then calculate statistics\n",
    "  stats = df.groupby(['court', 'broad_case_type']).apply(\n",
    "    lambda x: pd.Series({\n",
    "      'total_cases': len(x),\n",
    "      'resolved_within_timeline': sum(x.apply(is_resolved_within_timeline, axis=1)),\n",
    "      'proportion_resolved': sum(x.apply(is_resolved_within_timeline, axis=1)) / len(x) if len(x) > 0 else 0\n",
    "    })\n",
    "  ).reset_index()\n",
    "\n",
    "  return stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pivot_table(df, case_type_timelines):\n",
    "  # Calculate statistics using the modified function\n",
    "  stats = get_case_resolution_proportions(df, case_type_timelines)\n",
    "\n",
    "  # Pivot the data\n",
    "  pivot_table = stats.pivot_table(\n",
    "      index='court',\n",
    "      columns='broad_case_type',\n",
    "      values=['total_cases', 'resolved_within_timeline', 'proportion_resolved']\n",
    "  )\n",
    "\n",
    "  # Flatten the column hierarchy\n",
    "  pivot_table.columns = [f\"{col[1]}_{col[0]}\" for col in pivot_table.columns]\n",
    "\n",
    "  return pivot_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3738/1850208883.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  stats = df.groupby(['court', 'broad_case_type']).apply(\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have df and case_type_timelines\n",
    "pivot_table = create_pivot_table(df, case_type_timelines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_table.to_csv(f'{file_path}/reports/pmmu_resolution.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time_limit(age, case_category, concluded, time_lines):\n",
    "    \"\"\"\n",
    "    Check if a case falls within the specified time limit for its category and is concluded.\n",
    "    \n",
    "    Parameters:\n",
    "        age (int): The age of the case in days.\n",
    "        case_category (str): The category of the case.\n",
    "        concluded (int): The status of the case conclusion (1 for concluded, 0 otherwise).\n",
    "        time_lines (dict): A dictionary with case categories as keys and time limits as values.\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if the case is within the time limit and concluded, otherwise 0.\n",
    "    \"\"\"\n",
    "    time_limit = time_lines.get(case_category, 0)\n",
    "    return 1 if age <= time_limit and concluded == 1 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time lines\n",
    "df['time_lines'] = df.apply(lambda row: check_time_limit(row['age'], row['broad_case_type'], row['concluded'], case_type_timelines), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmmu_timelines = df[df['time_lines'] == 1].pivot_table(index='court', columns='broad_case_type', values='time_lines', aggfunc='count', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_concluded_per_court = df[df['concluded'] == 1].pivot_table(index='court', columns='broad_case_type', values='time_lines', aggfunc='count', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_within_pmmu_timeline = pmmu_timelines / total_concluded_per_court"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_within_pmmu_timeline.to_csv(f'{file_path}/reports/pmmu_timeline.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_within_pmmu_timeline"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haki-data-K3z4TeDN-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
