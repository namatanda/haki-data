{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "file_path = '/mnt/c/Users/Administrator/OneDrive/Documents/DCRT/RAW DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read stata \n",
    "df  = pd.read_csv(f'{file_path}/SC/sc-2023-24.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'bench_1':'judge_1','bench_2':'judge_2', 'bench_3':'judge_3', 'bench_4':'judge_4', 'bench_5':'judge_5', 'bench_6':'judge_6', 'bench_7':'judge_7'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join 'caseid_type','caseid_no', 'filed_yyyy' to create case number\n",
    "df['case_number'] = df['caseid_type'].astype(str) + '-' + df['caseid_no'].astype(str) + '-' + df['filed_yyyy'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drs = ['KARIUKI, NELLY WANGECHI', 'KASAVULI, BERNARD', 'WACHIRA, LETIZIA M.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip leading and trailing spaces from the 'judge_1', 'judge_2' and 'judge_3' columns \n",
    "for column in ['judge_1', 'judge_2', 'judge_3', 'judge_4', 'judge_5', 'judge_6', 'judge_7']:\n",
    "    df[column] = df[column].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe of drs only based on 'judge_1 - judge_7' columns if they are in the list of drs \n",
    "df_drs = df[df['judge_1'].isin(drs) | df['judge_2'].isin(drs) | df['judge_3'].isin(drs) | df['judge_4'].isin(drs) | df['judge_5'].isin(drs) | df['judge_6'].isin(drs) | df['judge_7'].isin(drs)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure columns \"judge_1\", \"judge_2\" and \"judge_3\" do not contain names in the drs list\n",
    "for column in ['judge_1', 'judge_2', 'judge_3', 'judge_4', 'judge_5', 'judge_6', 'judge_7']:\n",
    "    df = df[~df[column].isin(drs)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a new column 'matters handled' to the df_drs dataframe\n",
    "df['matters_handled'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a group of of pannel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_lists(column):\n",
    "    result = []\n",
    "    for item in column:\n",
    "        if isinstance(item, list):\n",
    "            if not any(pd.isna(x) for x in item):\n",
    "                result.append(item)\n",
    "        elif not pd.isna(item):\n",
    "            result.append(item)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Function to check similarity between lists\n",
    "def are_lists_similar(list1, list2):\n",
    "    return sorted(list1) == sorted(list2)\n",
    "\n",
    "# Function to create groupings of similar lists\n",
    "def create_groups(df, col_name):\n",
    "    group_number = 1\n",
    "    groups = {}\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        found_group = False\n",
    "        for group_id, group in groups.items():\n",
    "            if any(are_lists_similar(row[col_name], x) for x in group):\n",
    "                groups[group_id].append(row[col_name])\n",
    "                found_group = True\n",
    "                break\n",
    "        \n",
    "        if not found_group:\n",
    "            group_name = f\"Group_{group_number}\"\n",
    "            groups[group_name] = [row[col_name]]\n",
    "            group_number += 1\n",
    "    \n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bench_name'] = df.apply(lambda row: [row['judge_1'], row['judge_2'], row['judge_3'], row['judge_4'], row['judge_5'], row['judge_6'], row['judge_7']], axis=1)\n",
    "## Drop where the combined bench column contains null values\n",
    "df.loc[:, 'bench_name'] = df['bench_name'].apply(lambda x: drop_nan_lists(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to create groupings\n",
    "groupings = create_groups(df, 'bench_name')\n",
    "# Create a mapping of list to group number\n",
    "group_map = {}\n",
    "for group_id, group in groupings.items():\n",
    "    for item in group:\n",
    "        group_map[str(item)] = group_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the mapping to create a 'group' column in the DataFrame\n",
    "df['bench_panel'] = df['bench_name'].apply(lambda x: group_map[str(x)])\n",
    "# sort the elements of the 'bench_panel' column\n",
    "df['bench_name'] = df['bench_name'].apply(lambda x: sorted(x))\n",
    "df['bench_tuple'] = df['bench_name'].apply(tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop if length of df['bench_panel'] is < 2 \n",
    "df_bench = df[df['bench_name'].apply(lambda x: len(x) >= 2)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MERIT_CATEGORY ={\n",
    "    'Merit Resolution' : [     \n",
    "    'Judgment Delivered- Case Closed',\n",
    "    'Judgment Delivered', \n",
    "    'Judgment Delivered- Acquittal',\n",
    "    'Judgment Delivered- Convicted',\n",
    "    'Retrial',\n",
    "    'Appeal Dismissed',\n",
    "    'Grant Revoked',\n",
    "],\n",
    "'Non Merit Resolution': [\n",
    "    'Grant Confirmed', \n",
    "    'Matter Withdrawn',\n",
    "    'Dismissed For Want Of Prosecution - Case Closed',\n",
    "    'Dismissed',\n",
    "    'Terminated/ Struck Out/ Dismissed/case Closed', \n",
    "    'Application Allowed - Case Closed',\n",
    "    'Matter Settled- Case Closed', \n",
    "    'Consent Recorded - Case Closed',\n",
    "    'Application Withdrawn - Case Closed',\n",
    "    'Struck Out', \n",
    "    'Application Dismissed - Case Closed',\n",
    "    'Out Of Court Settlement Reached', \n",
    "    'Terminated',\n",
    "    'Consolidated- Case Closed',\n",
    "    'Interlocutory Judgement Entered', \n",
    "    'Abated', \n",
    "    'Limited Grant Issued',\n",
    "    'Placed In Probation', \n",
    "    'Revision Declined',  \n",
    "    'Probation Orders Issued',\n",
    "    'Matter Settled Through Mediation', \n",
    "    'Appeal Rejected', \n",
    "    'Order Issued - Case Closed',\n",
    "    'Terminated'  \n",
    "    ],\n",
    "    'Rulings': [\n",
    "    'Ruling delivered- Accused put on defense',\n",
    "    'Ruling Delivered- Case Closed', \n",
    "    'Ruling Delivered- Accused Discharged',\n",
    "    'Ruling Delivered- Application Closed',\n",
    "    'Ruling Delivered- Case Closed',\n",
    "    'Ruling-Case Closed',\n",
    "    ],\n",
    "    'Ruling Delivered': ['Ruling Delivered']\n",
    "} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_title_case(text):\n",
    "    \"\"\"\n",
    "    Apply title case to a given string.\n",
    "    \n",
    "    Args:\n",
    "        text: The input string to process.\n",
    "    \n",
    "    Returns:\n",
    "        str: The processed string in title case.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    if not isinstance(text, str):\n",
    "        return str(text)\n",
    "    return text.title()\n",
    "df_bench['outcome'] = df_bench['outcome'].apply(apply_title_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all coumns to uppercase\n",
    "df_bench['outcome'] = df_bench['outcome'].str.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench['merit_classification'] = df_bench['outcome'].map({v: k for k, values in MERIT_CATEGORY.items() for v in values}).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_performance = df_bench.pivot_table(index='bench_tuple', columns='merit_classification', values='case_number', aggfunc='count', fill_value=0).assign(total=lambda x: x.sum(axis=1)).sort_values('total', ascending=False).drop(columns='total')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "matters_handled = df_bench.groupby('bench_tuple')['matters_handled'].sum().reset_index()\n",
    "bench_performance = bench_performance.merge(matters_handled, on='bench_tuple', how='left')\n",
    "bench_performance.rename(columns={'matters_handled': 'total_matters_handled'}, inplace=True)\n",
    "bench_performance.reset_index(inplace=True)\n",
    "bench_performance.rename(columns={'index': 'bench_panel'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_performance.to_csv(f'{file_path}/SC/bench_performance.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "merit_classification",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "case_number",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7548d8aa-9779-4087-bb46-d3c056d7e81b",
       "rows": [
        [
         "3",
         "Rulings",
         "36"
        ],
        [
         "0",
         "Merit Resolution",
         "21"
        ],
        [
         "2",
         "Ruling Delivered",
         "19"
        ],
        [
         "1",
         "Non Merit Resolution",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>merit_classification</th>\n",
       "      <th>case_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rulings</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Merit Resolution</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ruling Delivered</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non Merit Resolution</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   merit_classification  case_number\n",
       "3               Rulings           36\n",
       "0      Merit Resolution           21\n",
       "2      Ruling Delivered           19\n",
       "1  Non Merit Resolution            1"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bench.groupby('merit_classification').agg({'case_number': 'count'}).reset_index().sort_values('case_number', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bench_tuple\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM, WANJALA, SMOKIN C.)    20\n",
       "(IBRAHIM, MOHAMMED K., LENAOLA, ISAAC, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                              15\n",
       "(IBRAHIM, MOHAMMED K., MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                       9\n",
       "(IBRAHIM, MOHAMMED K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                              8\n",
       "(IBRAHIM, MOHAMMED K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, WANJALA, SMOKIN C.)                                      7\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, WANJALA, SMOKIN C.)                                           6\n",
       "(LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                             6\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., MWILU, PHILOMENA MBETE, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                            5\n",
       "(IBRAHIM, MOHAMMED K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM)                                           5\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., LENAOLA, ISAAC, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM, WANJALA, SMOKIN C.)                             4\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, WANJALA, SMOKIN C.)                                    3\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM)                                         3\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., LENAOLA, ISAAC, NDUNGU, SUSANNA NJOKI, WANJALA, SMOKIN C.)                                            3\n",
       "(KOOME, MARTHA K., MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                           2\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, OUKO, WILLIAM)                                                2\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, WANJALA, SMOKIN C.)                    2\n",
       "(KOOME, MARTHA K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                                  2\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI)                                        1\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., LENAOLA, ISAAC, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                                    1\n",
       "(IBRAHIM, MOHAMMED K., KOOME, MARTHA K., NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                             1\n",
       "(KOOME, MARTHA K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM, WANJALA, SMOKIN C.)                           1\n",
       "(KOOME, MARTHA K., LENAOLA, ISAAC, MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM)                                               1\n",
       "(KOOME, MARTHA K., LENAOLA, ISAAC, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                                   1\n",
       "(MWILU, PHILOMENA MBETE, NDUNGU, SUSANNA NJOKI, OUKO, WILLIAM, WANJALA, SMOKIN C.)                                                             1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bench_sittings = df_bench.groupby('bench_tuple').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a name to the bench_sittings Series\n",
    "bench_sittings.name = 'sittings'\n",
    "\n",
    "# bench overall performance is merged bench_performance and bench_sittings\n",
    "bench_overall_performance = pd.merge(bench_performance, bench_sittings, on='bench_tuple', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_overall_performance.groupby('bench_tuple').sum().sort_values('sittings', ascending=False).to_csv(f'{file_path}/ANALYSIS/COA/coa-23-24-bench-overall-performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matters handled by each bench\n",
    "df_bench['bench_name'] = df_bench['bench_name'].apply(lambda x: sorted(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bench_performance.to_csv('/home/fiend/Documents/coa/CoA/bench_performance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench.groupby('merit_classification').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench.groupby('outcome').size().reset_index(name='count').sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench = df_bench.dropna(subset=['productivity_outcome'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top bench sittings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench.groupby('bench_tuple')['productivity_outcome'].sum().reset_index(name='total').sort_values('total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench.groupby('bench_panel')['productivity_outcome'].sum().reset_index(name='total').sort_values('total', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Create a bench combination column by collecting non-null judge names, sorting them, and converting to a tuple\n",
    "def get_bench_combination(row):\n",
    "    judges = [row['judge_1'], row['judge_2'], row['judge_3']]\n",
    "    judges = [j for j in judges if pd.notnull(j)]\n",
    "    return tuple(sorted(judges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['bench_combination'] = df.apply(get_bench_combination, axis=1)\n",
    "\n",
    "# 3. Sort the DataFrame so that if a case has any concluded row, it appears first\n",
    "df_sorted = df.sort_values(by='concluded', ascending=False)\n",
    "\n",
    "# 4. Drop duplicate case_number entries, keeping the first occurrence (which will be a concluded row if it exists)\n",
    "df_unique = df_sorted.drop_duplicates(subset='case_number', keep='first')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Filter to only include cases that have concluded (concluded == 1)\n",
    "df_concluded = df_unique[df_unique['concluded'] == 1]\n",
    "\n",
    "# 6. Group by bench combination and count the number of concluded cases per bench\n",
    "bench_concluded_counts = df_concluded.groupby('bench_combination').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concluded.groupby('bench_tuple').size().reset_index(name='count').sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concluded per judge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Melt the judge columns into a single column; keep case_number and case_type for reference.\n",
    "df_melt = df_concluded.melt(id_vars=['case_number', 'productivity'],\n",
    "                            value_vars=['judge_1', 'judge_2', 'judge_3'],\n",
    "                            value_name='judge')\n",
    "\n",
    "# Remove any rows with missing judge names\n",
    "df_melt = df_melt.dropna(subset=['judge'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.pivot_table(df_melt,\n",
    "                             index='judge',\n",
    "                             columns='productivity',\n",
    "                             aggfunc='size',\n",
    "                             fill_value=0).to_csv(f'{file_path}/judge_productivity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Count the occurrences of each judge\n",
    "#    Each occurrence represents a concluded case where that judge sat.\n",
    "judge_concluded_counts = df_melt['judge'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_concluded_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/fiend/Documents/coa/CoA/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index='bench_tuple', columns='productivity', values='concluded', aggfunc='sum', fill_value=0).rename_axis(columns=None)\n",
    "#.to_csv(f'{file_path}/bench_productivity.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('bench_tuple').size().reset_index(name='count').sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bench with the highest sittings \n",
    "top_20_bench_sittings = df.groupby('bench_tuple').size().reset_index(name='count').sort_values('count', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_20_bench_sittings.to_csv('top_20_bench_sittings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Judge who sat in the most benches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the bench_tuple column and count occurrences of each name\n",
    "most_bench_sittings = df['bench_tuple'].explode().value_counts()\n",
    "# Get the names that appear most frequently\n",
    "top_10_judges = most_bench_sittings.nlargest(10)  \n",
    "top_10_judges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_bench_sittings.to_csv('top_judges_most_bench_sittings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Judge who sat in the most benches that concluded cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for rows where 'concluded' is 1\n",
    "df_concluded = df[df['concluded'] == 1]\n",
    "\n",
    "# Flatten the bench_tuple column and count occurrences of each name\n",
    "most_bench_conclusions = df_concluded['bench_tuple'].explode().value_counts()\n",
    "# Get the names that appear most frequently\n",
    "#top_ten_resolutions = most_bench_conclusions.nlargest(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_bench_conclusions.to_csv('top_ten_resolutions.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bench adjournments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace df['reason_adj'] with NaN if  == Other (specify in details of case)\n",
    "df.loc[df['reason_adj'] == 'Other (specify in details of case)', 'reason_adj'] = np.nan\n",
    "# create a column of 1 if reason_adj is present otherwise 0\n",
    "df['adjourned'] = df['reason_adj'].notna().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows where reason_adj_indicator is 1\n",
    "adjourned_df = df[df['adjourned'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'bench_panel' and 'judge_list'\n",
    "grouped_df = adjourned_df.groupby(['court','bench_panel', 'bench_tuple']).size().reset_index(name='count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjourments per panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_adjournments = grouped_df.groupby(['court','bench_tuple', 'bench_panel'])['count'].sum().sort_values(ascending=False).reset_index().head(20)\n",
    "top_adjournments.to_csv('top_adjournments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_adjournments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort grouped_df by 'count' in descending order\n",
    "benched_df = grouped_df.sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['bench_panel']=='Group_16')].groupby('reason_adj').size().reset_index(name='count').sort_values('count', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haki-data-fitKH9hs-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
