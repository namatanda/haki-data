{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List, Union, Optional\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "file_path = '/mnt/c/Users/Alexra/OneDrive/Documents/CASELOAD DATA/HC/RAW DATA'\n",
    "output_path = '/mnt/c/Users/Alexra/OneDrive/Documents/CASELOAD DATA/ANALYSIS/HC'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_columns(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows containing NaN values from the specified columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to process.\n",
    "        columns (List[str]): A list of column names to check for NaN values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with NaN-containing rows dropped.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any of the specified columns are not present in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Validate that all specified columns exist in the DataFrame\n",
    "    missing_columns = set(columns) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Columns not found in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Identify columns with NaN values\n",
    "    nan_columns = df[columns].columns[df[columns].isna().any()].tolist()\n",
    "\n",
    "    # Log dropped rows if any\n",
    "    if nan_columns:\n",
    "        nan_count = df[columns].isna().sum()\n",
    "        logger.info(\"Dropping rows with NaN values:\")\n",
    "        for col in nan_columns:\n",
    "            logger.info(f\"  {col}: {nan_count[col]} rows\")\n",
    "\n",
    "    # Drop rows with NaN values in specified columns\n",
    "    original_row_count = len(df)\n",
    "    df_cleaned = df.dropna(subset=columns)\n",
    "    dropped_row_count = original_row_count - len(df_cleaned)\n",
    "\n",
    "    if dropped_row_count > 0:\n",
    "        logger.info(f\"Total rows dropped: {dropped_row_count}\")\n",
    "    else:\n",
    "        logger.info(\"No rows were dropped.\")\n",
    "\n",
    "    return df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicates(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove duplicates from a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    num_duplicates = data.duplicated().sum()\n",
    "    \n",
    "    if num_duplicates > 0:\n",
    "        logging.info(f\"{num_duplicates} duplicates found.\")\n",
    "        data = data.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "        logging.info(f\"{num_duplicates} duplicates removed.\")\n",
    "    else:\n",
    "        logging.info(\"No duplicates found.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_column(df: pd.DataFrame, column_names: List[str], new_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a new date column in the DataFrame by concatenating the values of three specified columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_names (List[str]): A list of three column names to be concatenated [year, month, day].\n",
    "        new_col (str): The name of the new date column to be created.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new date column added.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input list doesn't contain exactly three column names or if columns are missing.\n",
    "    \"\"\"\n",
    "    if len(column_names) != 3:\n",
    "        raise ValueError(\"column_names must contain exactly three elements: [year, month, day]\")\n",
    "\n",
    "    year_col, month_col, day_col = column_names\n",
    "\n",
    "    # Check if all required columns exist in the DataFrame\n",
    "    missing_columns = set(column_names) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Create copies to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "\n",
    "    try:\n",
    "        # Convert year and day columns to integers\n",
    "        df[year_col] = df[year_col].astype(float).astype(int)\n",
    "        df[day_col] = df[day_col].astype(float).astype(int)\n",
    "\n",
    "        # Concatenate the columns to create a date string\n",
    "        df[new_col] = (df[year_col].astype(str) + '-' + \n",
    "                       df[month_col].astype(str) + '-' + \n",
    "                       df[day_col].astype(str))\n",
    "\n",
    "        # Convert to datetime\n",
    "        df[new_col] = pd.to_datetime(df[new_col], errors='coerce')\n",
    "\n",
    "        # Log information about the conversion\n",
    "        valid_dates = df[new_col].notna().sum()\n",
    "        logger.info(f\"Created new date column '{new_col}'. Valid dates: {valid_dates}/{len(df)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating date column: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_title_case(text):\n",
    "    \"\"\"\n",
    "    Apply title case to a given string.\n",
    "    \n",
    "    Args:\n",
    "        text: The input string to process.\n",
    "    \n",
    "    Returns:\n",
    "        str: The processed string in title case.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return np.nan\n",
    "    if not isinstance(text, str):\n",
    "        logger.warning(f\"Non-string value encountered: {text}\")\n",
    "        return str(text)\n",
    "    return text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outcome_column(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the 'outcome' column of the DataFrame by applying title case.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing the 'outcome' column.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the processed 'outcome' column.\n",
    "    \"\"\"\n",
    "    if 'outcome' not in df.columns:\n",
    "        logger.error(\"'outcome' column not found in the DataFrame\")\n",
    "        return df\n",
    "\n",
    "    original_null_count = df['outcome'].isnull().sum()\n",
    "    \n",
    "    df['outcome'] = df['outcome'].apply(apply_title_case)\n",
    "    \n",
    "    new_null_count = df['outcome'].isnull().sum()\n",
    "    if new_null_count > original_null_count:\n",
    "        logger.warning(f\"Number of null values in 'outcome' increased from {original_null_count} to {new_null_count}\")\n",
    "    \n",
    "    non_string_count = df['outcome'].apply(lambda x: not isinstance(x, str) if pd.notna(x) else False).sum()\n",
    "    if non_string_count > 0:\n",
    "        logger.warning(f\"Found {non_string_count} non-string values in 'outcome' after processing\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_null_values(df: pd.DataFrame, column_name: str = 'outcome') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows from the DataFrame where the specified column contains null values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame from which to drop rows.\n",
    "        column_name (str): The name of the column to check for null values. Default is 'outcome'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with rows containing null values in the specified column dropped.\n",
    "    \"\"\"\n",
    "    initial_row_count: int = df.shape[0]\n",
    "    cleaned_df: pd.DataFrame = df.dropna(subset=[column_name])\n",
    "    final_row_count: int = cleaned_df.shape[0]\n",
    "    dropped_row_count: int = initial_row_count - final_row_count\n",
    "    \n",
    "    logging.info(f\"Total dropped rows with null values in '{column_name}': {dropped_row_count}\")\n",
    "    \n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_case(case_type: str, criminal_cases: Optional[List[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Categorize a case as 'Criminal' or 'Civil' based on its type.\n",
    "    \n",
    "    Args:\n",
    "        case_type (str): The type of the case.\n",
    "        criminal_cases (Optional[List[str]]): List of case types considered as criminal.\n",
    "        \n",
    "    Returns:\n",
    "        str: 'Criminal' if the case type is in the criminal cases list or if criminal_cases is None, 'Civil' otherwise.\n",
    "    \"\"\"\n",
    "    if criminal_cases is None:\n",
    "        return 'Criminal'\n",
    "    else:\n",
    "        return 'Criminal' if case_type in criminal_cases else 'Civil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def categorize_cases(df: pd.DataFrame, criminal_cases: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Categorize all cases in the DataFrame as 'Criminal' or 'Civil'.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case data.\n",
    "        criminal_cases (Optional[List[str]]): List of case types considered as criminal.\n",
    "            If None, all cases are categorized as 'Criminal'.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an added 'nature' column indicating case nature.\n",
    "    \"\"\"\n",
    "    df['nature'] = df['case_type'].apply(lambda x: categorize_case(x, criminal_cases))\n",
    "\n",
    "    # Check for presence of both case types\n",
    "    if 'Criminal' not in df['nature'].values:\n",
    "        logging.warning(\"No criminal cases found in the DataFrame.\")\n",
    "    if 'Civil' not in df['nature'].values:\n",
    "        logging.warning(\"No civil cases found in the DataFrame.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_dict(value: Any, dictionary: Dict[str, Union[str, List[Any]]]) -> Union[str, None]:\n",
    "    \"\"\"\n",
    "    Find all keys in a dictionary where the given value matches.\n",
    "\n",
    "    Args:\n",
    "        value: The value to search for.\n",
    "        dictionary: The dictionary to search in.\n",
    "\n",
    "    Returns:\n",
    "        A list of keys where the value matches, or None if no matches are found.\n",
    "    \"\"\"\n",
    "    matching_keys = []\n",
    "    for key, dict_value in dictionary.items():\n",
    "        if isinstance(dict_value, str) and dict_value == value:\n",
    "            matching_keys.append(key)\n",
    "        elif isinstance(dict_value, list) and value in dict_value:\n",
    "            matching_keys.append(key)\n",
    "    \n",
    "    if not matching_keys:\n",
    "        return None\n",
    "    elif len(matching_keys) == 1:\n",
    "        return matching_keys[0]\n",
    "    else:\n",
    "        return matching_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_case_num(df: pd.DataFrame, court_col: str, caseid_type_col: str, caseid_no_col: str, filed_yyyy_col: str, new_col='case_number') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a case number by concatenating court, caseid_type, caseid_no, and filed_yyyy columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the necessary columns.\n",
    "        court_col (str): The name of the column containing court information.\n",
    "        caseid_type_col (str): The name of the column containing case ID type.\n",
    "        caseid_no_col (str): The name of the column containing case ID number.\n",
    "        filed_yyyy_col (str): The name of the column containing the year the case was filed.\n",
    "        new_col (str): The name of the new column to be created for the case number. Default is 'case_num'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the new case number column.\n",
    "    \"\"\"\n",
    "    df[new_col] = df[court_col] + '/' + df[caseid_type_col] + '/' + df[caseid_no_col] + '/' + df[filed_yyyy_col].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def is_concluded(outcome: str, resolved_outcomes: List[str]) -> int:\n",
    "    \"\"\"\n",
    "    Determine if the case is concluded based on the outcome.\n",
    "    \n",
    "    Args:\n",
    "        outcome (str): The outcome of the case.\n",
    "        resolved_outcomes (List[str]): List of outcomes considered as resolved.\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if the case outcome is resolved, 0 otherwise.\n",
    "    \"\"\"\n",
    "    return 1 if outcome in resolved_outcomes else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_case_registered(outcome: str, activity_date: Union[pd.Timestamp, str], filed_date: Union[pd.Timestamp, str]) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if a case is registered based on its outcome and dates.\n",
    "\n",
    "    Args:\n",
    "        outcome (str): The outcome of the case.\n",
    "        activity_date (Union[pd.Timestamp, str]): The date of the activity.\n",
    "        filed_date (Union[pd.Timestamp, str]): The date the case was filed.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the case is registered, False otherwise.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Normalize the outcome string\n",
    "        normalized_outcome = outcome.strip().lower()\n",
    "\n",
    "        # Check if the outcome indicates registration\n",
    "        is_registered_outcome = 'case registered/filed' in normalized_outcome \n",
    "\n",
    "        # Convert dates to pd.Timestamp if they're strings\n",
    "        if isinstance(activity_date, str):\n",
    "            activity_date = pd.to_datetime(activity_date, errors='coerce')\n",
    "        if isinstance(filed_date, str):\n",
    "            filed_date = pd.to_datetime(filed_date, errors='coerce')\n",
    "\n",
    "        # Check if dates are equal\n",
    "        dates_match = pd.notna(activity_date) and pd.notna(filed_date) and activity_date == filed_date\n",
    "\n",
    "        is_registered = is_registered_outcome and dates_match\n",
    "\n",
    "        if is_registered:\n",
    "            logger.debug(f\"Case registered: outcome='{outcome}', activity_date={activity_date}, filed_date={filed_date}\")\n",
    "        \n",
    "        return is_registered\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in is_case_registered: {e}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_case_status(df: pd.DataFrame, resolved_outcome: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the DataFrame to add 'concluded' and 'registered' columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case information.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with added 'concluded' and 'registered' columns.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If required columns are missing from the DataFrame.\n",
    "    \"\"\"\n",
    "    required_columns = ['outcome', 'activity_date', 'filed_date']\n",
    "    missing_columns = set(required_columns) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
    "\n",
    "    #df['concluded'] = df['outcome'].apply(is_case_concluded)\n",
    "    df['concluded'] = df['outcome'].apply(lambda x: is_concluded(x, resolved_outcome))\n",
    "    df['registered'] = df.apply(lambda row: is_case_registered(row['outcome'], row['activity_date'], row['filed_date']), axis=1)\n",
    "\n",
    "    logger.info(f\"Processed {len(df)} cases\")\n",
    "    logger.info(f\"Concluded cases: {df['concluded'].sum()}\")\n",
    "    logger.info(f\"Registered cases: {df['registered'].sum()}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_court_outcomes(df: pd.DataFrame, start_date: str, end_date: str, outcome: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the number of case outcomes per court within a specified period.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): A pandas DataFrame containing the data.\n",
    "        start_date (str): The starting date of the period (YYYY-MM-DD format).\n",
    "        end_date (str): The ending date of the period (YYYY-MM-DD format).\n",
    "        outcome (str): A column representing the outcome of interest.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame showing the number of resolved cases per court and case category.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        period_start = pd.to_datetime(start_date)\n",
    "        period_end = pd.to_datetime(end_date)\n",
    "        \n",
    "        if period_start > period_end:\n",
    "            raise ValueError(\"start_date must be earlier than end_date\")\n",
    "        \n",
    "        required_columns = {'court', 'broad_case_type', 'activity_date', outcome}\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            missing_columns = required_columns - set(df.columns)\n",
    "            raise KeyError(f\"Missing required columns: {missing_columns}\")\n",
    "        \n",
    "        filtered_cases = df[\n",
    "            (df['activity_date'] >= period_start) &\n",
    "            (df['activity_date'] <= period_end) &\n",
    "            (df[outcome] == 1)\n",
    "        ]\n",
    "        \n",
    "        if filtered_cases.empty:\n",
    "            logging.warning(\"No cases found for the given date range and outcome.\")\n",
    "   \n",
    "        outcome_by_type = (\n",
    "            filtered_cases\n",
    "            .groupby(['court', 'broad_case_type'])\n",
    "            .size()\n",
    "            .reset_index(name='num_cases')\n",
    "        )\n",
    "\n",
    "        result = outcome_by_type.pivot_table(\n",
    "            index='court', \n",
    "            columns='broad_case_type', \n",
    "            values='num_cases', \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        logging.info(\"Successfully calculated case outcomes per court.\")\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_time_limit(age, case_category, concluded, time_lines):\n",
    "    \"\"\"\n",
    "    Check if a case falls within the specified time limit for its category and is concluded.\n",
    "    \n",
    "    Parameters:\n",
    "        age (int): The age of the case in days.\n",
    "        case_category (str): The category of the case.\n",
    "        concluded (int): The status of the case conclusion (1 for concluded, 0 otherwise).\n",
    "        time_lines (dict): A dictionary with case categories as keys and time limits as values.\n",
    "        \n",
    "    Returns:\n",
    "        int: 1 if the case is within the time limit and concluded, otherwise 0.\n",
    "    \"\"\"\n",
    "    time_limit = time_lines.get(case_category, 0)\n",
    "    return 1 if age <= time_limit and concluded == 1 else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_case_stats(df, registered_col, concluded_col):\n",
    "    \"\"\"Calculates monthly statistics for registered and concluded cases.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing case data.\n",
    "        registered_col (str): The name of the column containing registered cases.\n",
    "        concluded_col (str): The name of the column containing concluded cases.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with monthly statistics for registered and concluded cases.\n",
    "    \"\"\"\n",
    "\n",
    "    monthly_cases = df.groupby(['court', 'date_mon', 'case_type']).agg(\n",
    "        registered=(registered_col, 'sum'),\n",
    "        concluded=(concluded_col, 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    return monthly_cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_timely_pmmu_column(data_f, time_lines):\n",
    "    data_f['timely'] = data_f.apply(lambda row: True if row['broad_case_type'] in time_lines and row['concluded'] == 1 and row['age'] <= time_lines[row['broad_case_type']] else False, axis=1)\n",
    "    return data_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_adjournment_columns(df, non_adjourned):\n",
    "    \"\"\"Adds 'adjourned' and 'adjournable' columns to the DataFrame.\"\"\"\n",
    "    df['adjourned'] = (df['reason_adj'].notnull() & df['comingfor'].apply(lambda x: x not in non_adjourned)).astype(int)\n",
    "    df['adjournable'] = df['comingfor'].apply(lambda x: x not in non_adjourned).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adjourned_per_court(df):\n",
    "    \"\"\"Calculates adjourned cases per court and reason.\"\"\"\n",
    "    return df.groupby(['court', 'reason_adj'])['adjourned'].sum().reset_index(name='count')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adjournment_proportion(df):\n",
    "    \"\"\"Calculates total adjourned, adjournable cases, and adjournment proportion per court.\"\"\"\n",
    "    court_summary = df.groupby('court').agg(\n",
    "        total_adjourned=('adjourned', 'sum'),\n",
    "        total_adjournable=('adjournable', 'sum')\n",
    "    ).reset_index()\n",
    "    court_summary['adjourn_proportion'] = court_summary['total_adjourned'] / court_summary['total_adjournable']\n",
    "    return court_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NON_ADJOUNABLE = [\n",
    "    'Taxation and Issuance of Certificates',\n",
    "    'Orders',\n",
    "    'Appointments of  Mediator',\n",
    "    'Screening of files for Mediation',\n",
    "    'Post-judgment',\n",
    "    'Re-activation',\n",
    "    'Reactivation',\n",
    "    'Notice of Taxation',\n",
    "    'Entering Interlocutory Judgments',\n",
    "    'Approval by DR', \n",
    "    'Registration/Filing-Application', \n",
    "    'Registration/Filing', \n",
    "    'Registration/Filing-Application',\n",
    " ]\n",
    "RESOLVED_OUTCOMES = [\n",
    "    'Ruling Delivered- Case Closed', 'Grant Confirmed', 'Matter Withdrawn',\n",
    "    'Dismissed For Want Of Prosecution - Case Closed', 'Dismissed',\n",
    "    'Terminated/ Struck Out/ Dismissed/case Closed', 'Judgment Delivered- Case Closed',\n",
    "    'Application Allowed - Case Closed',\n",
    "    'Matter Settled- Case Closed', 'Consent Recorded - Case Closed',\n",
    "    'Judgment Delivered', 'Judgment Delivered- Acquittal',\n",
    "    'Judgment Delivered- Convicted', 'Application Withdrawn - Case Closed',\n",
    "    'Struck Out', 'Application Dismissed - Case Closed',\n",
    "    'Out Of Court Settlement Reached', 'Terminated',\n",
    "    'Ruling Delivered- Application Closed', 'Consolidated- Case Closed',\n",
    "    'Interlocutory Judgement Entered', 'Abated', 'Limited Grant Issued',\n",
    "    'Grant Revoked', 'Placed In Probation', 'Ruling Delivered- Accused Discharged',\n",
    "    'Revision Declined', 'Retrial', 'Probation Orders Issued',\n",
    "    'Matter Settled Through Mediation', 'Appeal Dismissed', 'Appeal Rejected', \n",
    "    'Order Issued - Case Closed',\n",
    "    'Terminated',\n",
    "    'File Transferred',\n",
    "    'Terminated/ Struck Out/ Dismissed/Case Closed', \n",
    "    'Application Dismissed',\n",
    "    'Application Allowed',\n",
    "    'Terminated/ Struck Out/ Dismissed/Case Closed '\n",
    "]\n",
    "CRIMINAL_CASES = [\n",
    "    'Murder Case',\n",
    "    'Criminal Revision',\n",
    "    'Criminal Appeal',\n",
    "    'Murder - Gender Justice Criminal Case',\n",
    "    'Criminal Court Martial Appeal',\n",
    "    'Anti-Corruption and Economic Crimes Revision',\n",
    "    'Criminal Miscellaneous Application',\n",
    "    'Criminal Applications', \n",
    "    'COA Criminal Appeal'\n",
    "]\n",
    "BROAD_CASE_TYPES = {\n",
    "    'Civil Matter': [\n",
    "        'Civil Suit',\n",
    "        'Anti-Corruption and Economic Crimes Suit',\n",
    "        'Family Originating Summons',\n",
    "        'Family Civil Case',\n",
    "        'HCC(OS) Family',\n",
    "        'Commercial Admiralty',\n",
    "        'Commercial Matters',\n",
    "    ],\n",
    "    \n",
    "    'Adoption': 'Family Adoption',\n",
    "    'Divorce': 'Family Divorce Cause',\n",
    "\n",
    "    'Criminal Application': 'Criminal Miscellaneous Application',\n",
    "\n",
    "    'Civil Application': [\n",
    "        'Civil Case Miscellaneous',\n",
    "        'Judicial Review Miscellaneous',\n",
    "        'JR  Petition Miscellaneous',\n",
    "        'Anti-Corruption and Economic Crimes Miscellaneous',\n",
    "        'Commercial Miscellaneous',\n",
    "        'Constitution and Human Rights Petitions Miscellaneous',\n",
    "        'Family Miscellaneous',\n",
    "        'Commercial Arbitration',\n",
    "    ],\n",
    "    'Judicial Review': [\n",
    "        'Anti-Corruption and Economic Crime Judicial review',\n",
    "        'Judicial Review ELC',\n",
    "        'Judicial Review',\n",
    "    ],\n",
    "    'Criminal Revision': [\n",
    "        'Criminal Revision',\n",
    "        'Anti-Corruption and Economic Crimes Revision',\n",
    "    ],\n",
    "    'Criminal Appeal': [\n",
    "        'Criminal Appeal',\n",
    "        'Criminal Court Martial Appeal',\n",
    "        'Anti-Corruption and Economic Crimes Appeal',\n",
    "    ],\n",
    "    'Civil Appeal': [\n",
    "        'Family Appeal',\n",
    "        'Civil Appeal',\n",
    "        'Commercial Appeal',\n",
    "        'Constitution and Human Rights Election Petition Appeal',\n",
    "        'Constitution and Human Rights Petition Appeal',\n",
    "        'Constitution and Human Rights Election Petition Appeal',\n",
    "        'Gender Justice Civil Appeal',\n",
    "        'Constitution and Human Rights Miscellaneous Election Petition Appeal (MEPA)',\n",
    "    ],\n",
    "    'Constitution Petition': [\n",
    "        'Anti Corruption and Economic Crimes Petition',\n",
    "        'High Court Criminal Petition',\n",
    "        'Constitution and Human Rights Petition (Civil)',\n",
    "        'Constitution and Human Rights Election Petition',\n",
    "        'High Court Constitution and Human Rights Petitions (Criminal)',\n",
    "        'Commercial Petition',\n",
    "    ],\n",
    "    'Probate Administration': [\n",
    "        'Family P&A Intestate',\n",
    "        'Family P&A Ad Litem',\n",
    "        'Family P&A Ad Colligenda',\n",
    "        'Family P&A Citation',\n",
    "        'Family P&A Testate',\n",
    "        'Family P&A Resealing of Grant',\n",
    "        'Family P&A De Bonis Non',\n",
    "        'Resealing of Grant',\n",
    "        'Citation-Family',\n",
    "    ],\n",
    "    'Murder': [\n",
    "        'Murder Case',\n",
    "        'Murder - Gender Justice Criminal Case',\n",
    "    ],\n",
    "    'Tax Appeal': [\n",
    "        'Commercial Income Tax Appeal',\n",
    "        'Commercial Custom Tax Appeal',\n",
    "    ],\n",
    "    'Bankruptcy and Insolvency' : [\n",
    "        'Commercial Insolvency Notice Petition',\n",
    "        'Commercial Insolvency Petition',\n",
    "        'Commercial Bankruptcy Notice',\n",
    "        'Commercial Insolvency Cause',\n",
    "        'Commercial Insolvency Notice',\n",
    "        'Commercial Bankruptcy Cause',\n",
    "        'Commercial Winding Up Cause',\n",
    "    ]\n",
    "}\n",
    "\n",
    "MERIT_CATEGORY ={\n",
    "    'Merit Resolution' : [     \n",
    "    'Judgment Delivered- Case Closed',\n",
    "    'Judgment Delivered', \n",
    "    'Judgment Delivered- Acquittal',\n",
    "    'Judgment Delivered- Convicted',\n",
    "    'Retrial',\n",
    "    'Appeal Dismissed',\n",
    "    'Grant Revoked',\n",
    "],\n",
    "'Non Merit Resolution': [\n",
    "    'Grant Confirmed', \n",
    "    'Matter Withdrawn',\n",
    "    'Dismissed For Want Of Prosecution - Case Closed',\n",
    "    'Dismissed',\n",
    "    'Terminated/ Struck Out/ Dismissed/case Closed', \n",
    "    'Application Allowed - Case Closed',\n",
    "    'Matter Settled- Case Closed', \n",
    "    'Consent Recorded - Case Closed',\n",
    "    'Application Withdrawn - Case Closed',\n",
    "    'Struck Out', \n",
    "    'Application Dismissed - Case Closed',\n",
    "    'Out Of Court Settlement Reached', \n",
    "    'Terminated',\n",
    "    'Consolidated- Case Closed',\n",
    "    'Interlocutory Judgement Entered', \n",
    "    'Abated', \n",
    "    'Limited Grant Issued',\n",
    "    'Placed In Probation', \n",
    "    'Revision Declined',  \n",
    "    'Probation Orders Issued',\n",
    "    'Matter Settled Through Mediation', \n",
    "    'Appeal Rejected', \n",
    "    'Order Issued - Case Closed',\n",
    "    'Terminated'  \n",
    "    ],\n",
    "    'Rulings': [\n",
    "    'Ruling delivered- Accused put on defense',\n",
    "    'Ruling delivered',\n",
    "    'Ruling Delivered- Case Closed', \n",
    "    'Ruling Delivered- Accused Discharged',\n",
    "    'Ruling Delivered- Application Closed',\n",
    "    'Ruling Delivered- Case Closed',\n",
    "    ]\n",
    "} \n",
    "\n",
    "\n",
    "productivity = {\n",
    "    'Judgment Delivered': [\n",
    "        'Judgment Delivered- Case Closed',\n",
    "        'Judgment Delivered',\n",
    "        'Judgment Delivered- Acquittal',\n",
    "        'Judgment Delivered- Convicted',\n",
    "        'Grant Revoked',\n",
    "        'Retrial',\n",
    "        'Ruling Delivered- Accused Discharged',\n",
    "        ],\n",
    "\n",
    "    'Ruling Delivered': [\n",
    "        'Ruling delivered- Accused put on defense',\n",
    "        'Ruling delivered'\n",
    "        ],\n",
    "\n",
    "    'Ruling Case Closed': [\n",
    "        'Ruling Delivered- Case Closed', \n",
    "        ],\n",
    "    'Final Grant': [\n",
    "        'Grant Confirmed',\n",
    "        'Limited Grant Issued',\n",
    "        ],\n",
    "    'Case Withdrawn': [\n",
    "        'Matter Withdrawn',\n",
    "        'Application Withdrawn - Case Closed',\n",
    "        ],\n",
    "   'Out Of Court Settlement': [\n",
    "        'Consent Recorded - Case Closed',\n",
    "        'Matter Settled Through Mediation',\n",
    "        'Out Of Court Settlement Reached',\n",
    "    ],\n",
    "    'Dismissed':[\n",
    "        'Dismissed For Want Of Prosecution - Case Closed',\n",
    "        'Dismissed',\n",
    "        'Appeal Dismissed',\n",
    "        'Terminated',\n",
    "        'Terminated/ Struck Out/ Dismissed/case Closed',\n",
    "    ],\n",
    "    'Case Transfered': [\n",
    "        'File Transfered -case Closed',\n",
    "        'File Transferred',\n",
    "    ],\n",
    "    'Case Closed': [\n",
    "        'Struck Out',\n",
    "        'Application Dismissed - Case Closed',\n",
    "        'Application Allowed - Case Closed',\n",
    "        'Matter Settled- Case Closed',\n",
    "        'Ruling Delivered- Application Closed',\n",
    "        'Consolidated- Case Closed',\n",
    "        'Abated',\n",
    "        'Placed In Probation',\n",
    "        'Revision Declined',\n",
    "        'Probation Orders Issued',\n",
    "        'Appeal Rejected',\n",
    "        'Interlocutory Judgement Entered',\n",
    "    ],\n",
    "}\n",
    "HC_PMMU_TIME_LINES = {\n",
    "    'Murder': 365, \n",
    "    'Constitution Petition': 180, \n",
    "    'Criminal Revision': 90, \n",
    "    'Judicial Review': 180, \n",
    "    'Civil Matter': 365,\n",
    "    'Civil Appeal': 180,\n",
    "    'Criminal Appeal': 180\n",
    "}\n",
    "# transferred\n",
    "TRANSFERED_CASES = ['File Transfered -case Closed', \n",
    "        'File Transferred',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "merit_classification = {\n",
    "    'judgement': [\n",
    "        'Judgment Delivered- Case Closed',\n",
    "        'Judgment Delivered',\n",
    "        'Judgment Delivered- Acquittal',\n",
    "        'Judgment Delivered- Convicted',\n",
    "        'Grant Revoked',\n",
    "        'Retrial'\n",
    "        ],\n",
    "\n",
    "    'ruling_closed': [\n",
    "        'Ruling Delivered- Case Closed', \n",
    "        'Ruling Delivered- Case Closed',\n",
    "        'Ruling Delivered- Accused Discharged'\n",
    "        ],\n",
    "\n",
    "    'ruling_delivered': [\n",
    "        'Ruling Delivered- Accused Put On Defense',\n",
    "        'Ruling Delivered'\n",
    "        ],\n",
    "\n",
    "    'other_resolution': [\n",
    "        'Grant Confirmed',\n",
    "        'Limited Grant Issued',\n",
    "        'Matter Withdrawn',\n",
    "        'Application Withdrawn - Case Closed',\n",
    "        'Consent Recorded - Case Closed',\n",
    "        'Matter Settled Through Mediation',\n",
    "        'Out Of Court Settlement Reached',\n",
    "        'Dismissed For Want Of Prosecution - Case Closed',\n",
    "        'Dismissed',\n",
    "        'Appeal Dismissed',\n",
    "        'Terminated',\n",
    "        'Terminated/ Struck Out/ Dismissed/case Closed',\n",
    "        'Struck Out',\n",
    "        'Application Dismissed - Case Closed',\n",
    "        'Application Allowed - Case Closed',\n",
    "        'Matter Settled- Case Closed',\n",
    "        'Ruling Delivered- Application Closed',\n",
    "        'Consolidated- Case Closed',\n",
    "        'Abated',\n",
    "        'Placed In Probation',\n",
    "        'Revision Declined',\n",
    "        'Probation Orders Issued',\n",
    "        'Appeal Rejected',\n",
    "        'Interlocutory Judgement Entered',\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{file_path}/hc-q3-24-25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['outcome'] = df['outcome'].replace('Terminated/ Struck Out/ Dismissed/Case Closed ', 'Terminated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "judges_df = pd.read_csv(f'{file_path}/final_judges.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep if the df['judge_1'] is in the judges_df \n",
    "df = df[df['judge_1'].isin(judges_df['name'])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_date_column(df.copy(), ['date_dd', 'date_mon', 'date_yyyy'], 'activity_date')\n",
    "df = create_date_column(df.copy(), ['filed_dd', 'filed_mon', 'filed_yyyy'], 'filed_date')\n",
    "df = drop_nan_columns(df, ['date_dd', 'date_mon', 'date_yyyy', 'caseid_type', 'caseid_no',\n",
    "       'filed_dd', 'filed_mon', 'filed_yyyy', 'case_type', 'comingfor'])\n",
    "df = remove_duplicates(df)\n",
    "df = df.apply(lambda x: x.strip().title() if isinstance(x, str) else x)\n",
    "df = process_outcome_column(df)\n",
    "df = drop_null_values(df)\n",
    "df = categorize_cases(df, CRIMINAL_CASES)\n",
    "df['broad_case_type'] = df['case_type'].apply(lambda x: apply_dict(x, BROAD_CASE_TYPES))\n",
    "df = generate_case_num(df, 'court', 'caseid_type', 'caseid_no', 'filed_yyyy')\n",
    "df['age'] = (df['activity_date'] - df['filed_date']).dt.days\n",
    "df = process_case_status(df, RESOLVED_OUTCOMES)\n",
    "df['merit_category'] = df['outcome'].apply(lambda x: apply_dict(x, MERIT_CATEGORY))\n",
    "df = add_timely_pmmu_column(df, HC_PMMU_TIME_LINES)\n",
    "df['comingfor'] = df['comingfor'].str.strip()\n",
    "df = add_adjournment_columns(df, NON_ADJOUNABLE)\n",
    "df['transfer'] = df['outcome'].apply(lambda x: x in TRANSFERED_CASES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = pd.to_datetime('2024-07-01')\n",
    "end_date = pd.to_datetime('2024-12-31')  \n",
    "\n",
    "# Ensure the activity_date column is in datetime format\n",
    "df['activity_date'] = pd.to_datetime(df['activity_date'], errors='coerce')\n",
    "\n",
    "# Filter the DataFrame based on the date range\n",
    "df = df[(df['activity_date'] >= start_date) & (df['activity_date'] <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concluded = df[df['concluded'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = df.drop_duplicates(subset=['case_number'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['classification'] = df['outcome'].apply(lambda x: apply_dict(x, merit_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pivot_table(index='judge_1', columns='classification', values='concluded', aggfunc='sum', fill_value=0).rename_axis(columns=None).to_csv(f'{output_path}/classification.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'classification' in df.columns:\n",
    "\tdf['ruling_delivered'] = (df['classification'] == 'ruling_delivered').astype(int)\n",
    "else:\n",
    "\traise KeyError(\"'classification' column is not defined in the DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('judge_1')['ruling_delivered'].sum().reset_index(name='total').to_csv(f'{output_path}/ruling_delivered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract the quarter from the activity_date column\n",
    "df['quarter'] = df['activity_date'].dt.to_period('Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resolution_mode'] = df['outcome'].apply(lambda x: apply_dict(x, merit_classification))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filed_cases = analyze_court_outcomes(df, start_date, end_date, 'registered')\n",
    "resolved_cases = analyze_court_outcomes(df, start_date, end_date, 'concluded')\n",
    "monthly_filed_cases = df.groupby(['court','date_mon']).agg({'registered':'sum'}).reset_index()\n",
    "monthly_concluded_cases = df.groupby(['court','date_mon']).agg({'concluded':'sum'}).reset_index()\n",
    "average_time_to_conclude = df.loc[df['concluded'] == 1].pivot_table(index='court', columns='nature', values='age', aggfunc='mean', fill_value=0).round(2)\n",
    "monthly_stats = monthly_case_stats(df, 'registered', 'concluded')\n",
    "court_productivity = df.pivot_table(index='court', columns='merit_category', values='concluded', aggfunc='sum', fill_value=0).rename_axis(columns=None)\n",
    "total_resolved_cases = df.pivot_table( index='court', columns='broad_case_type', values='timely', aggfunc=lambda x: np.sum(df.loc[x.index, 'concluded'] == 1), fill_value=0)\n",
    "timely_resolved_cases = df[df['timely']].pivot_table(index='court', columns='broad_case_type', values='timely', aggfunc='sum', fill_value=0)\n",
    "percentage_timely = (timely_resolved_cases / resolved_cases ).fillna(0)\n",
    "adjourned_per_court = calculate_adjourned_per_court(df)\n",
    "adjourned_proportion = calculate_adjournment_proportion(df)\n",
    "transfered_cases = df[df['transfer']].pivot_table(index='court', columns='broad_case_type', values='transfer', aggfunc='sum', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['Murder', 'Criminal Appeal', 'Criminal Application', \n",
    "                'Criminal Revision', 'Civil Matter', 'Civil Appeal', 'Civil Application', \n",
    "                'Constitution Petition', 'Judicial Review',\n",
    "                  'Bankruptcy and Insolvency', 'Tax Appeal', \n",
    "                  'Adoption', 'Divorce', 'Probate Administration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "resolved_cases.to_csv(f'{output_path}/{end_date}_resolved_cases.csv', columns=column_order, index=True)\n",
    "monthly_filed_cases.to_csv(f'{output_path}/{end_date}_filed_per_month.csv', index=False)\n",
    "monthly_concluded_cases.to_csv(f'{output_path}/{end_date}_monthly_concluded.csv', index=False)\n",
    "court_productivity.to_csv(f'{output_path}/{end_date}_court_productivity.csv')\n",
    "average_time_to_conclude.to_csv(f'{output_path}/{end_date}_average_time_to_conclude.csv')\n",
    "percentage_timely.to_csv(f'{output_path}/{end_date}_resolved_within_timeline.csv')\n",
    "adjourned_per_court.to_csv(f'{output_path}/{end_date}_adjournement.csv', index=False)\n",
    "adjourned_proportion.to_csv(f'{output_path}/{end_date}_adjourned_proportion.csv', index=False)\n",
    "transfered_cases.to_csv(f'{output_path}/{end_date}_transfered_cases.csv',columns=column_order, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['Murder', 'Criminal Appeal', 'Criminal Application', \n",
    "                'Criminal Revision', 'Civil Matter', 'Civil Appeal', 'Civil Application', \n",
    "                'Constitution Petition', 'Judicial Review',\n",
    "                  'Bankruptcy and Insolvency', 'Tax Appeal',\n",
    "                  'Adoption', 'Probate Administration']\n",
    "filed_cases.to_csv(f'{output_path}/{end_date}_filed_cases.csv', columns=column_order, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_concluded_cases(df):\n",
    "    \"\"\"\n",
    "    Categorize concluded cases into '1-3 year' and 'over 3 year' based on age column.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame containing the data.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: DataFrame with an additional column 'age_category'.\n",
    "    \"\"\"\n",
    "    # Filter only concluded cases\n",
    "    df_concluded = df[df['concluded'] == 1]\n",
    "\n",
    "    # Calculate age in years\n",
    "    df_concluded['age_years'] = df_concluded['age'] / 365\n",
    "\n",
    "    # Categorize based on age\n",
    "    df_concluded.loc[:, 'age_category'] = df_concluded['age_years'].apply(lambda x: '1-3 year' if 1 <= x <= 3 else 'over 3 year')\n",
    "\n",
    "    # Merge back to original DataFrame\n",
    "    df = pd.merge(df, df_concluded[['case_number', 'age_category']], on='case_number', how='left')\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def track_case_transitions(df, start_period, end_period):\n",
    "    \"\"\"\n",
    "    Track case transitions to over 1 year and over 3 years based on age.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing case data with an 'age' column.\n",
    "        start_period (pd.Timestamp): The start period as a timestamp.\n",
    "        end_period (pd.Timestamp): The end period as a timestamp.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with additional columns indicating transitions.\n",
    "    \"\"\"\n",
    "    # Calculate the age difference between the periods\n",
    "    age_difference = (end_period - start_period).days\n",
    "\n",
    "    # Define thresholds in days\n",
    "    one_year_days = 365\n",
    "    three_year_days = 3 * one_year_days\n",
    "\n",
    "    # Transition to 1 year category\n",
    "    df['transition_to_1_year'] = (\n",
    "        (df['age'] < one_year_days) &\n",
    "        (df['age'] + age_difference >= one_year_days) &\n",
    "        (df['age'] + age_difference < 2 * one_year_days)\n",
    "    ).astype(int)\n",
    "\n",
    "    # Transition to 3 year category\n",
    "    df['transition_to_3_year'] = (\n",
    "        (df['age'] < three_year_days) &\n",
    "        (df['age'] + age_difference >= three_year_days) &\n",
    "        (df['age'] + age_difference < 4 * one_year_days)\n",
    "    ).astype(int)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = track_case_transitions(df, start_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max transition_to_1_year if df['concluded']== 1 to avoid double counting\n",
    "df['transition_1_year'] = df.apply(lambda x: max(x['transition_to_1_year'], x['concluded']), axis=1)\n",
    "df['transition_3_year'] = df.apply(lambda x: max(x['transition_to_3_year'], x['concluded']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "df_2 = df_2.drop_duplicates(subset=['court', 'case_number'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2['age_2'] = (df_2['activity_date'] - end_date).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transited_backlog = df_2.groupby('court').agg(\n",
    "    transition_to_1_year=('transition_to_1_year', 'sum'),\n",
    "    transition_to_3_year=('transition_to_3_year', 'sum')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transited_backlog.to_csv(f'{output_path}/{end_date}_transited_backlog.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concluded_backlog = df_2[df_2['concluded']==1].groupby('court').agg(\n",
    "    transition_to_1_year=('transition_to_1_year', 'sum'),\n",
    "    transition_to_3_year=('transition_to_3_year', 'sum')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resolved_backlog_over 3 \n",
    "resolved_backlog_over_3 = df_2[(df_2['concluded']==1) & (df['age_1'] > 1080)].groupby('court').agg(\n",
    "    transition_to_3_year=('transition_to_3_year', 'sum')\n",
    ").reset_index()\n",
    "resolved_backlog_over_3.to_csv(f'{output_path}/{end_date}_resolved_backlog_over_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concluded_backlog.to_csv(f'{output_path}/{end_date}_concluded_backlog.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('transition_to_1_year')['case_number'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.query('court == \"Voi\" & concluded == 1 & transition_to_1_year == 1')\n",
    "#.groupby('case_number')['transition_to_1_year'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.query('court == \"Garsen\" & case_number == \"Garsen/HCCA/E002/2024\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table where df['concluded] == 1 and transited to df['transition_to_1_year'] and df['transition_to_3_year'] per court\n",
    "df[df['concluded']== 1].groupby('court')['transition_to_1_year'].sum().reset_index().sort_values(by='transition_to_1_year', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = categorize_concluded_cases(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['resolved'] = df.groupby('case_number')['concluded'].transform('max')\n",
    "pending_df = df[df['resolved'] != 1]\n",
    "# custody_df.groupby(['court', 'case_type'])['reg'].count().reset_index(name='count')\n",
    "# custody_df.groupby(['court','case_number'])['reg'].count().sort_values(ascending=False).reset_index(name='count').to_csv(f'{file_path}/hc_custody_cases.csv', index=False)\n",
    "# custody_df.to_csv(f'{file_path}/hc_custody_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pending_df.to_csv(f'{file_path}/kibera_pending.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filed_df = df[df['registered'] == 1]\n",
    "male_applicants = filed_df[(filed_df['male_applicant'] == 1) & (filed_df['case_category'] != 'murder')].groupby('case_category').size().reset_index(name='count')\n",
    "female_applicants = filed_df[(filed_df['female_applicant'] == 1) & (filed_df['case_category'] != 'murder')].groupby('case_category').size().reset_index(name='count')\n",
    "male_accused = filed_df[(filed_df['male_defendant'] == 1) & (filed_df['case_category'] == 'murder')].groupby('case_category').size().reset_index(name='count')\n",
    "male_murder_defendants = filed_df[(filed_df['male_defendant'] == 1) & (filed_df['case_category'] == 'murder')].groupby('case_category').size().reset_index(name='count')\n",
    "female_murder_defendants = filed_df[(filed_df['female_defendant'] == 1) & (filed_df['case_category'] == 'murder')].groupby('case_category').size().reset_index(name='count')\n",
    "applicants = pd.merge(female_applicants, male_applicants, on='case_category', how='outer', suffixes=('_female', '_male'))\n",
    "applicants.to_csv(f'{output_path}/applicants_gender.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kisumu analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kisumu_df['filed_date'] = pd.to_datetime(kisumu_df['filed_dd'].astype(str) + '-' + kisumu_df['filed_mon'].astype(str) + '-' + kisumu_df['filed_yyyy'].astype(str), format='%d-%b-%Y')\n",
    "# kisumu_df = drop_nan_columns(kisumu_df, ['date_dd', 'date_mon', 'date_yyyy', 'caseid_type', 'caseid_no',\n",
    "#        'filed_dd', 'filed_mon', 'filed_yyyy', 'case_type', 'comingfor'])\n",
    "# kisumu_df = kisumu_df.apply(lambda x: x.strip().title() if isinstance(x, str) else x)\n",
    "# kisumu_df = process_outcome_column(kisumu_df)\n",
    "# kisumu_df = drop_null_values(kisumu_df)\n",
    "# kisumu_df['broad_case_type'] = kisumu_df['case_type'].apply(lambda x: apply_dict(x, BROAD_CASE_TYPES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milimani divs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{file_path}/processed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milimani_df = df[df['court'].str.contains('Milimani')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milimani_df_2 = df[df['court'].str.contains('Milimani')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "milimani_df_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['court', 'date_dd', 'date_mon', 'date_yyyy', 'caseid_type', 'caseid_no',\n",
    "       'filed_dd', 'filed_mon', 'filed_yyyy', 'original_court',\n",
    "       'original_code', 'original_number', 'original_year', 'case_type',\n",
    "       'judge_1', 'judge_2', 'judge_3', 'judge_4', 'judge_5', 'judge_6',\n",
    "       'judge_7', 'comingfor', 'outcome', 'reason_adj', 'next_dd', 'next_mon',\n",
    "       'next_yyyy', 'male_applicant', 'female_applicant',\n",
    "       'organization_applicant', 'male_defendant', 'female_defendant',\n",
    "       'organization_defendant', 'legalrep', 'applicant_witness',\n",
    "       'defendant_witness', 'custody', 'other_details', 'activity_date',\n",
    "       'filed_date', 'nature', 'broad_case_type', 'case_number',\n",
    "       'concluded', 'registered', 'productivity', 'age', 'time_lines',\n",
    "       'adjourned', 'adjournable', 'set_date', 'delivery_date',\n",
    "       'time_taken_days', 'judgment_status', 'delivery_category'],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([milimani_df, milimani_df_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = combined_df[['court', 'date_dd', 'date_mon', 'date_yyyy', 'caseid_type', 'caseid_no',\n",
    "       'filed_dd', 'filed_mon', 'filed_yyyy', 'original_court',\n",
    "       'original_code', 'original_number', 'original_year', 'case_type',\n",
    "       'judge_1', 'judge_2', 'judge_3', 'judge_4', 'judge_5', 'judge_6',\n",
    "       'judge_7', 'comingfor', 'outcome', 'reason_adj', 'next_dd', 'next_mon',\n",
    "       'next_yyyy', 'male_applicant', 'female_applicant',\n",
    "       'organization_applicant', 'male_defendant', 'female_defendant',\n",
    "       'organization_defendant', 'legalrep', 'applicant_witness',\n",
    "       'defendant_witness', 'custody', 'other_details', 'activity_date',\n",
    "       'filed_date', 'nature', 'broad_case_type', 'case_number', 'concluded',\n",
    "       'registered', 'age', 'adjourned',\n",
    "       'adjournable',]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f'{file_path}/milimani_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the activity_date column to datetime format\n",
    "df['activity_date'] = pd.to_datetime(df['activity_date'], format='mixed')\n",
    "\n",
    "# Filter only concluded cases\n",
    "concluded_cases = df[df['concluded'] == 1]\n",
    "\n",
    "# Extract the quarter from the activity_date column\n",
    "concluded_cases['quarter'] = concluded_cases['activity_date'].dt.to_period('Q')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter only concluded cases\n",
    "registered_cases = df[df['registered'] == 1]\n",
    "\n",
    "# Extract the quarter from the activity_date column\n",
    "registered_cases['quarter'] = registered_cases['activity_date'].dt.to_period('Q')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_registered_cases = registered_cases.groupby('quarter').size().reset_index(name='filed_cases_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the quarter and count the number of concluded cases\n",
    "quarterly_concluded_cases = concluded_cases.groupby('quarter').size().reset_index(name='concluded_cases_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine the two DataFrames\n",
    "quarterly_cases = pd.merge(quarterly_registered_cases, quarterly_concluded_cases, on='quarter', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quarterly_cases.to_csv(f'{file_path}/quarterly_cases.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haki-data-HVHT8HQl-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
