{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List, Union, Optional\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any, List, Union, Optional\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRIMINAL_CASES: List[str] = [\n",
    "    'Murder Case',\n",
    "    'Criminal Revision',\n",
    "    'Criminal Appeal',\n",
    "    'Murder - Gender Justice Criminal Case',\n",
    "    'Criminal Court Martial Appeal',\n",
    "    'Anti-Corruption and Economic Crimes Revision',\n",
    "    'Criminal Miscellaneous Application',\n",
    "    'Criminal Applications',\n",
    "    'COA Criminal Appeal'\n",
    "]\n",
    "\n",
    "BROAD_CASE_TYPES: Dict[str, List[str]] = {\n",
    "    'Civil Suit': [\n",
    "        'Civil Suit',\n",
    "        'Anti-Corruption and Economic Crimes Suit',\n",
    "        'Family Originating Summons',\n",
    "        'Family Civil Case',\n",
    "        'HCC(OS) Family',\n",
    "        'Commercial Admiralty',\n",
    "        'Commercial Matters',\n",
    "    ],\n",
    "\n",
    "    'Adoption': ['Family Adoption'],\n",
    "    \n",
    "    'Divorce': ['Family Divorce Cause'],\n",
    "    \n",
    "    'Criminal Application': ['Criminal Miscellaneous Application'],\n",
    "    \n",
    "    'Miscellaneous Application': [\n",
    "        'Civil Case Miscellaneous',\n",
    "        'Judicial Review Miscellaneous',\n",
    "        'JR  Petition Miscellaneous',\n",
    "        'Anti-Corruption and Economic Crimes Miscellaneous',\n",
    "        'Commercial Miscellaneous',\n",
    "        'Constitution and Human Rights Petitions Miscellaneous',\n",
    "        'Family Miscellaneous',\n",
    "        'Commercial Arbitration',\n",
    "    ],\n",
    "    \n",
    "    'Judicial Review': [\n",
    "        'Anti-Corruption and Economic Crime Judicial review',\n",
    "        'Judicial Review ELC',\n",
    "        'Judicial Review',\n",
    "    ],\n",
    "    \n",
    "    'Criminal Revision': [\n",
    "        'Criminal Revision',\n",
    "        'Anti-Corruption and Economic Crimes Revision',\n",
    "    ],\n",
    "    \n",
    "    'Criminal Appeal': [\n",
    "        'Criminal Appeal',\n",
    "        'Criminal Court Martial Appeal',\n",
    "        'Anti-Corruption and Economic Crimes Appeal',\n",
    "    ],\n",
    "    \n",
    "    'Civil Appeal': [\n",
    "        'Family Appeal',\n",
    "        'Civil Appeal',\n",
    "        'Commercial Appeal',\n",
    "        'Constitution and Human Rights Election Petition Appeal',\n",
    "        'Constitution and Human Rights Petition Appeal',\n",
    "        'Constitution and Human Rights Election Petition Appeal',\n",
    "        'Gender Justice Civil Appeal',\n",
    "        'Constitution and Human Rights Miscellaneous Election Petition Appeal (MEPA)',\n",
    "    ],\n",
    "    \n",
    "    'Constitution Petition': [\n",
    "        'Anti Corruption and Economic Crimes Petition',\n",
    "        'High Court Criminal Petition',\n",
    "        'Constitution and Human Rights Petition (Civil)',\n",
    "        'Constitution and Human Rights Election Petition',\n",
    "        'High Court Constitution and Human Rights Petitions (Criminal)',\n",
    "        'Commercial Petition',\n",
    "    ],\n",
    "    \n",
    "    'Probate Administration': [\n",
    "        'Family P&A Intestate',\n",
    "        'Family P&A Ad Litem',\n",
    "        'Family P&A Ad Colligenda',\n",
    "        'Family P&A Citation',\n",
    "        'Family P&A Testate',\n",
    "        'Family P&A Resealing of Grant',\n",
    "        'Family P&A De Bonis Non',\n",
    "        'Resealing of Grant',\n",
    "        'Citation-Family',\n",
    "    ],\n",
    "    \n",
    "    'Murder': [\n",
    "        'Murder Case',\n",
    "        'Murder - Gender Justice Criminal Case',\n",
    "    ],\n",
    "    \n",
    "    'Tax Appeal': [\n",
    "        'Commercial Income Tax Apperiod_startpeal',\n",
    "        'Commercial Custom Tax Appeal',\n",
    "    ],\n",
    "    \n",
    "    'Bankruptcy and Insolvency': [\n",
    "        'Commercial Insolvency Notice Petition',\n",
    "        'Commercial Insolvency Petition',\n",
    "        'Commercial Bankruptcy Notice',\n",
    "        'Commercial Insolvency Cause',\n",
    "        'Commercial Insolvency Notice',\n",
    "        'Commercial Bankruptcy Cause',\n",
    "        'Commercial Winding Up Cause',\n",
    "    ]\n",
    "}\n",
    "\n",
    "\n",
    "RESOLVED_OUTCOMES: List[str] = [\n",
    "    'Ruling Delivered- Case Closed',\n",
    "    'Terminated',\n",
    "    'Matter Settled- Case Closed',\n",
    "    'Application Dismissed - Case Closed',\n",
    "    'Judgment Delivered- Case Closed',\n",
    "    'Matter Withdrawn',\n",
    "    'Application Allowed - Case Closed',\n",
    "    'Application Withdrawn - Case Closed',\n",
    "    'Judgment Delivered- Convicted',\n",
    "    'Placed In Probation',\n",
    "    'Dismissed',\n",
    "    'Judgment Delivered',\n",
    "    'Judgment Delivered- Acquittal',\n",
    "    'Ruling Delivered- Accused Discharged',\n",
    "    'Abated',\n",
    "    'Consolidated- Case Closed',\n",
    "    'Grant Confirmed',\n",
    "    'Limited Grant Issued',\n",
    "    'Struck Out',\n",
    "    'Grant Revoked',\n",
    "    'Consent Recorded - Case Closed',\n",
    "    'Dismissed For Want Of Prosecution - Case Closed',\n",
    "    'Out Of Court Settlement Reached',\n",
    "    'Appeal Dismissed',\n",
    "    'Retrial',\n",
    "    'Appeal Rejected',\n",
    "    'Sentence Commuted',\n",
    "    'Ruling Delivered- Application Closed',\n",
    "    'Probation Orders Issued',\n",
    "    'Order Issued - Case Closed',\n",
    "    'Revision Declined'\n",
    "]\n",
    "\n",
    "\n",
    "TRANSFERED_CASES: List[str] = [\n",
    "    'File Transfered -case Closed',\n",
    "    'File Transferred',\n",
    "]\n",
    "\n",
    "\n",
    "MERIT_CATEGORY: Dict[str, List[str]] = {\n",
    "    'Judgment Delivered': [\n",
    "        'Judgment Delivered- Case Closed',\n",
    "        'Judgment Delivered',\n",
    "        'Judgment Delivered- Acquittal',\n",
    "        'Judgment Delivered- Convicted',\n",
    "        'Grant Revoked',\n",
    "        'Retrial'\n",
    "    ],\n",
    "    'Ruling Case Closed': [\n",
    "        'Ruling Delivered- Case Closed',\n",
    "        'Ruling Delivered- Accused Discharged',\n",
    "    ],\n",
    "    'Final Grant': [\n",
    "        'Grant Confirmed',\n",
    "        'Limited Grant Issued',\n",
    "    ],\n",
    "    'Case Withdrawn': [\n",
    "        'Matter Withdrawn',\n",
    "        'Application Withdrawn - Case Closed',\n",
    "    ],\n",
    "    'Out Of Court Settlement': [\n",
    "        'Consent Recorded - Case Closed',\n",
    "        'Matter Settled Through Mediation',\n",
    "        'Out Of Court Settlement Reached',\n",
    "    ],\n",
    "    'Dismissed': [\n",
    "        'Dismissed For Want Of Prosecution - Case Closed',\n",
    "        'Dismissed',\n",
    "        'Appeal Dismissed',\n",
    "        'Terminated'\n",
    "    ],\n",
    "\n",
    "    'Case Closed': [\n",
    "        'Struck Out',\n",
    "        'Application Dismissed - Case Closed',\n",
    "        'Application Allowed - Case Closed',\n",
    "        'Matter Settled- Case Closed',\n",
    "        'Ruling Delivered- Application Closed',\n",
    "        'Consolidated- Case Closed',\n",
    "        'Abated',\n",
    "        'Placed In Probation',\n",
    "        'Revision Declined',\n",
    "        'Probation Orders Issued',\n",
    "        'Appeal Rejected',\n",
    "        'Interlocutory Judgement Entered',\n",
    "        'Order issued - Case closed'\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "TIME_LIMITS: Dict[str, int] = {\n",
    "    'Murder': 360, \n",
    "    'Constitution Petition': 360, \n",
    "    'Criminal Revision': 90, \n",
    "    'Judicial Review': 360, \n",
    "    'Civil Matter': 360,\n",
    "    'Anti Corruption': 360,\n",
    "    'Income Tax Appeal': 180,\n",
    "    'Matrimonial Property': 360,\n",
    "    'Succession': 180,\n",
    "}\n",
    "\n",
    "\n",
    "NON_ADJOURNABLE: List[str] = [\n",
    "    'Taxation and Issuance of Certificates',\n",
    "    'Orders',\n",
    "    'Appointments of  Mediator',\n",
    "    'Screening of files for Mediation',\n",
    "    'Post-judgment',\n",
    "    'Re-activation',\n",
    "    'Reactivation',\n",
    "    'Notice of Taxation',\n",
    "    'Entering Interlocutory Judgments',\n",
    "    'Approval by DR',\n",
    "    'Registration/Filing-Application',\n",
    "    'Registration/Filing',\n",
    "    'Registration/Filing-Application',\n",
    "]\n",
    "\n",
    "\n",
    "MERIT_OUTCOMES: List[str] = [\n",
    "    'Ruling Delivered- Case Closed',\n",
    "    'Judgment Delivered- Case Closed',\n",
    "    'Judgment Delivered',\n",
    "    'Judgment Delivered- Acquittal',\n",
    "    'Judgment Delivered- Convicted',\n",
    "    'Grant Revoked',\n",
    "    'Ruling Delivered- Accused Discharged',\n",
    "    'Retrial'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_nan_columns(df: pd.DataFrame, columns: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows containing NaN values from the specified columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to process.\n",
    "        columns (List[str]): A list of column names to check for NaN values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated DataFrame with NaN-containing rows dropped.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any of the specified columns are not present in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Validate that all specified columns exist in the DataFrame\n",
    "    missing_columns = set(columns) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Columns not found in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Identify columns with NaN values\n",
    "    nan_columns = df[columns].columns[df[columns].isna().any()].tolist()\n",
    "\n",
    "    # Log dropped rows if any\n",
    "    if nan_columns:\n",
    "        nan_count = df[columns].isna().sum()\n",
    "        logger.info(\"Dropping rows with NaN values:\")\n",
    "        for col in nan_columns:\n",
    "            logger.info(f\"  {col}: {nan_count[col]} rows\")\n",
    "\n",
    "    # Drop rows with NaN values in specified columns\n",
    "    original_row_count = len(df)\n",
    "    df_cleaned = df.dropna(subset=columns)\n",
    "    dropped_row_count = original_row_count - len(df_cleaned)\n",
    "\n",
    "    if dropped_row_count > 0:\n",
    "        logger.info(f\"Total rows dropped: {dropped_row_count}\")\n",
    "    else:\n",
    "        logger.info(\"No rows were dropped.\")\n",
    "\n",
    "    return df_cleaned\n",
    "\n",
    "def remove_duplicates(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Remove duplicates from a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): Input DataFrame.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    num_duplicates = data.duplicated().sum()\n",
    "    \n",
    "    if num_duplicates > 0:\n",
    "        logging.info(f\"{num_duplicates} duplicates found.\")\n",
    "        data = data.drop_duplicates(keep=\"first\").reset_index(drop=True)\n",
    "        logging.info(f\"{num_duplicates} duplicates removed.\")\n",
    "    else:\n",
    "        logging.info(\"No duplicates found.\")\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def drop_null_values(df: pd.DataFrame, column_name: str = 'outcome') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drop rows from the DataFrame where the specified column contains null values.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame from which to drop rows.\n",
    "        column_name (str): The name of the column to check for null values. Default is 'outcome'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with rows containing null values in the specified column dropped.\n",
    "    \"\"\"\n",
    "    df['outcome'] = df['outcome'].str.strip()\n",
    "    initial_row_count: int = df.shape[0]\n",
    "    cleaned_df: pd.DataFrame = df.dropna(subset=[column_name])\n",
    "    final_row_count: int = cleaned_df.shape[0]\n",
    "    dropped_row_count: int = initial_row_count - final_row_count\n",
    "    \n",
    "    if dropped_row_count > 0:\n",
    "        logger.info(f\"Total dropped rows with null values in '{column_name}': {dropped_row_count}\")\n",
    "    else:\n",
    "        logger.info(f\"No rows dropped with null values in '{column_name}'\")\n",
    "    return cleaned_df\n",
    "\n",
    "\n",
    "def strip_dataframe_columns(df):\n",
    "    \"\"\"Strips leading and trailing whitespace from all columns in a Pandas DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to modify.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: The modified DataFrame with stripped columns.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        df = df.astype(str).apply(lambda x: x.str.strip())\n",
    "        logger.info(\"str.strip() applied successfully to all columns.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error applying str.strip(): {e}\")\n",
    "        return None\n",
    "\n",
    "def convert_to_title_case(df: pd.DataFrame, column: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the specified column of the DataFrame by applying title case.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        column (str): The name of the column to process.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the processed column.\n",
    "    \"\"\"\n",
    "\n",
    "    if column not in df.columns:\n",
    "        logger.error(f\"'{column}' column not found in the DataFrame\")\n",
    "        return df\n",
    "\n",
    "    df[column] = df[column].str.title()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_columns(df: pd.DataFrame, required_columns: Union[str, List[str]]) -> None:\n",
    "    \"\"\"\n",
    "    Validate that the DataFrame contains the required columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        required_columns (Union[str, List[str]]): A single column name (str) or a list of column names (List[str]) that must be present.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If any required columns are missing.\n",
    "    \"\"\"\n",
    "    # Convert required_columns to a list if it's a string\n",
    "    if isinstance(required_columns, str):\n",
    "        required_columns = [required_columns]\n",
    "\n",
    "    # Check which required columns are missing\n",
    "    missing_columns = set(required_columns) - set(df.columns)\n",
    "    \n",
    "    # If there are missing columns, raise a ValueError with an informative message\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
    "\n",
    "\n",
    "\n",
    "def add_date(df: pd.DataFrame, column_names: List[str], new_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Creates a new date column in the DataFrame by concatenating the values of three specified columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        column_names (List[str]): A list of three column names to be concatenated [year, month, day].\n",
    "        new_col (str): The import commandsname of the new date column to be created.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new date column added.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the input list doesn't contain exactly three column names or if columns are missing.\n",
    "    \"\"\"\n",
    "    if len(column_names) != 3:\n",
    "        raise ValueError(\"column_names must contain exactly three elements: [year, month, day]\")\n",
    "\n",
    "    year_col, month_col, day_col = column_names\n",
    "\n",
    "    # Check if all required columns exist in the DataFrame\n",
    "    missing_columns = set(column_names) - set(df.columns)\n",
    "    if missing_columns:\n",
    "        raise ValueError(f\"Missing columns in DataFrame: {', '.join(missing_columns)}\")\n",
    "\n",
    "    # Create copies to avoid SettingWithCopyWarning\n",
    "    df = df.copy()\n",
    "\n",
    "    try:\n",
    "        # Convert year and day columns to integers\n",
    "        df[year_col] = df[year_col].astype(float).astype(int)\n",
    "        df[day_col] = df[day_col].astype(float).astype(int)\n",
    "\n",
    "        # Concatenate the columns to create a date string\n",
    "        df[new_col] = (df[year_col].astype(str) + '-' + \n",
    "                       df[month_col].astype(str) + '-' + \n",
    "                       df[day_col].astype(str))\n",
    "\n",
    "        # Convert to datetime\n",
    "        df[new_col] = pd.to_datetime(df[new_col], errors='coerce')\n",
    "\n",
    "        # Log information about the conversion\n",
    "        valid_dates = df[new_col].notna().sum()\n",
    "        logger.info(f\"Created new date column '{new_col}'. Valid dates: {valid_dates}/{len(df)}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error creating date column: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "    return df\n",
    "\n",
    "def add_case_number(df: pd.DataFrame, court_col: str, caseid_type_col: str, caseid_no_col: str, filed_yyyy_col: str, new_col='case_number') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Generates a case number by concatenating court, caseid_type, caseid_no, and filed_yyyy columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The dataframe containing the necessary columns.\n",
    "        court_col (str): The name of the column containing court information.\n",
    "        caseid_type_col (str): The name of the column containing case ID type.\n",
    "        caseid_no_col (str): The name of the column containing case ID number.\n",
    "        filed_yyyy_col (str): The name of the column containing the year the case was filed.\n",
    "        new_col (str): The name of the new column to be created for the case number. Default is 'case_num'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with the new case number column.\n",
    "    \"\"\"\n",
    "    df[new_col] = df[court_col] + '/' + df[caseid_type_col] + '/' + df[caseid_no_col] + '/' + df[filed_yyyy_col].astype(str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_case_age(df: pd.DataFrame, filed_date_column: str = 'filed_date', activity_date_column: str = 'activity_date', age_column: str = 'case_age') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add a column representing the age of cases in days to the DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case data.\n",
    "        filed_date_column (str): The column name containing the filed dates.\n",
    "        activity_date_column (str): The column name containing the activity dates.\n",
    "        age_column (str): The name of the new column to store the case age in days.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new 'case_age' column added.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the required columns are missing in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Check if required columns exist\n",
    "    required_columns = [filed_date_column, activity_date_column]\n",
    "    missing_columns = [col for col in required_columns if col not in df.columns]\n",
    "    \n",
    "    if missing_columns:\n",
    "        logger.error(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
    "        raise ValueError(f\"Missing required columns: {', '.join(missing_columns)}\")\n",
    "    \n",
    "    # Calculate the case age in days\n",
    "    try:\n",
    "        df[age_column] = (df[activity_date_column] - df[filed_date_column]).dt.days\n",
    "        \n",
    "        logger.info(f\"Successfully added '{age_column}' column to the DataFrame.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating case age: {e}\")\n",
    "        raise\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def categorize_case(case_type: str, criminal_cases: Optional[List[str]]) -> str:\n",
    "    \"\"\"\n",
    "    Categorize a case as 'Criminal' or 'Civil' based on its type.\n",
    "    \n",
    "    Args:\n",
    "        case_type (str): The type of the case.\n",
    "        criminal_cases (Optional[List[str]]): List of case types considered as criminal.\n",
    "        \n",
    "    Returns:\n",
    "        str: 'Criminal' if the case type is in the criminal cases list or if criminal_cases is None, 'Civil' otherwise.\n",
    "    \"\"\"\n",
    "    if criminal_cases is None:\n",
    "        return 'Criminal'\n",
    "    else:\n",
    "        return 'Criminal' if case_type in criminal_cases else 'Civil'\n",
    "\n",
    "def add_case_nature(df: pd.DataFrame, criminal_cases: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Categorize all cases in the DataFrame as 'Criminal' or 'Civil'.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case data.\n",
    "        criminal_cases (Optional[List[str]]): List of case types considered as criminal.\n",
    "            If None, all cases are categorized as 'Criminal'.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with an added 'nature' column indicating case nature.\n",
    "    \"\"\"\n",
    "    df['nature'] = df['case_type'].apply(lambda x: categorize_case(x, criminal_cases))\n",
    "\n",
    "    # Check for presence of both case types\n",
    "    if 'Criminal' not in df['nature'].values:\n",
    "        logging.warning(\"No criminal cases found in the DataFrame.\")\n",
    "    if 'Civil' not in df['nature'].values:\n",
    "        logging.warning(\"No civil cases found in the DataFrame.\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def find_matching_keys(value: Any, mapping: Dict[str, Union[str, List[Any]]]) -> Optional[Union[str, List[str]]]:\n",
    "    \"\"\"\n",
    "    Find all keys in a dictionary where the given value is present.\n",
    "\n",
    "    Args:\n",
    "        value (Any): The value to search for.\n",
    "        mapping (Dict[str, Union[str, List[Any]]]): A dictionary where keys map to either a string or a list of values.\n",
    "\n",
    "    Returns:\n",
    "        Optional[Union[str, List[str]]]: A single key if exactly one match is found, \n",
    "                                         a list of keys if multiple matches are found,\n",
    "                                         or None if no matches are found.\n",
    "    \"\"\"\n",
    "    matching_keys = [\n",
    "        key for key, dict_value in mapping.items()\n",
    "        if (isinstance(dict_value, str) and dict_value == value) or\n",
    "           (isinstance(dict_value, list) and value in dict_value)\n",
    "    ]\n",
    "\n",
    "    if not matching_keys:\n",
    "        return None\n",
    "    return matching_keys[0] if len(matching_keys) == 1 else matching_keys\n",
    "\n",
    "\n",
    "\n",
    "def add_broad_category(\n",
    "    df: pd.DataFrame, \n",
    "    case_type_column: str, \n",
    "    broad_case_type_column: str, \n",
    "    mapping: Dict[str, Union[str, List[Any]]]\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Map case types to broad case categories based on a given mapping dictionary.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        case_type_column (str): The column name containing case types to be mapped.\n",
    "        broad_case_type_column (str): The name of the new column where the broad case categories will be stored.\n",
    "        mapping (Dict[str, Union[str, List[Any]]]): The mapping dictionary where keys are broad categories and values are specific case types.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with the new column containing broad case categories.\n",
    "    \n",
    "    Raises:\n",
    "        ValueError: If the case_type_column is not found in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Check if the required column exists\n",
    "    if case_type_column not in df.columns:\n",
    "        logger.error(f\"Column '{case_type_column}' not found in DataFrame\")\n",
    "        raise ValueError(f\"Column '{case_type_column}' not found in the DataFrame\")\n",
    "    \n",
    "    # Apply the dictionary mapping using find_matching_keys function\n",
    "    df[broad_case_type_column] = df[case_type_column].apply(lambda x: find_matching_keys(x, mapping))\n",
    "    \n",
    "    logger.info(f\"Successfully mapped case types to broad categories in '{broad_case_type_column}' column.\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def analyze_court_outcomes(df: pd.DataFrame, start_date: str, end_date: str, outcome: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the number of case outcomes per court within a specified period.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): A pandas DataFrame containing the data.\n",
    "        start_date (str): The starting date of the period (YYYY-MM-DD format).\n",
    "        end_date (str): The ending date of the period (YYYY-MM-DD format).\n",
    "        outcome (str): A column representing the outcome of interest.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame showing the number of resolved cases per court and case category.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        period_start = pd.to_datetime(start_date)\n",
    "        period_end = pd.to_datetime(end_date)\n",
    "        \n",
    "        if period_start > period_end:\n",
    "            raise ValueError(\"start_date must be earlier than end_date\")\n",
    "        \n",
    "        required_columns = {'court', 'broad_case_type', 'activity_date', outcome}\n",
    "        if not required_columns.issubset(df.columns):\n",
    "            missing_columns = required_columns - set(df.columns)\n",
    "            raise KeyError(f\"Missing required columns: {missing_columns}\")\n",
    "        \n",
    "        filtered_cases = df[\n",
    "            (df['activity_date'] >= period_start) &\n",
    "            (df['activity_date'] <= period_end) &\n",
    "            (df[outcome] == 1)\n",
    "        ]\n",
    "        \n",
    "        if filtered_cases.empty:\n",
    "            logging.warning(\"No cases found for the given date range and outcome.\")\n",
    "   \n",
    "        outcome_by_type = (\n",
    "            filtered_cases\n",
    "            .groupby(['court', 'broad_case_type'])\n",
    "            .size()\n",
    "            .reset_index(name='num_cases')\n",
    "        )\n",
    "\n",
    "        result = outcome_by_type.pivot_table(\n",
    "            index='court', \n",
    "            columns='broad_case_type', \n",
    "            values='num_cases', \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        logging.info(\"Successfully calculated case outcomes per court.\")\n",
    "        return result\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def process_case_time_limits(df: pd.DataFrame, time_limits: Dict[str, int]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the case data by adding age and time limit compliance columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case data.\n",
    "                           Required columns: 'filed_date', 'activity_date', 'broad_case_type', 'concluded'\n",
    "        time_limits (Dict[str, int]): A dictionary with case categories as keys and time limits as values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The processed DataFrame with 'age' and 'within_time_limit' columns added.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if each case is within the time limit and concluded\n",
    "    df['within_time_limit'] = (\n",
    "        (df['case_age'] <= df['broad_case_type'].map(time_limits).fillna(0)) & \n",
    "        df['concluded']\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def is_concluded(outcome: str, resolved_outcomes: List[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if a case outcome is resolved.\n",
    "\n",
    "    Args:\n",
    "        outcome (str): The outcome of the case.\n",
    "        resolved_outcomes (List[str]): List of outcomes that indicate resolution.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the outcome is considered resolved, otherwise False.\n",
    "    \"\"\"\n",
    "    return outcome.lower() in (resolved.lower() for resolved in resolved_outcomes)\n",
    "\n",
    "\n",
    "def is_case_registered(outcome: str, activity_date: Union[str, pd.Timestamp], filed_date: Union[str, pd.Timestamp]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if a case is registered based on outcome and whether activity and filed dates match.\n",
    "\n",
    "    Args:\n",
    "        outcome (str): The outcome of the case.\n",
    "        activity_date (Union[str, pd.Timestamp]): The date of the activity.\n",
    "        filed_date (Union[str, pd.Timestamp]): The date the case was filed.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the outcome implies registration and activity_date matches filed_date, otherwise False.\n",
    "    \"\"\"\n",
    "    outcome = outcome.strip().lower()\n",
    "    \n",
    "    if 'registered' not in outcome and 'filed' not in outcome:\n",
    "        return False\n",
    "\n",
    "    return pd.notna(activity_date) and pd.notna(filed_date) and activity_date == filed_date\n",
    "\n",
    "\n",
    "\n",
    "def add_conclusion(df: pd.DataFrame, resolved_outcomes: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add the 'concluded' column to the DataFrame based on resolved outcomes.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame with case data.\n",
    "        resolved_outcomes (List[str]): List of outcomes considered resolved.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'concluded' column added.\n",
    "    \"\"\"\n",
    "    df['concluded'] = df['outcome'].apply(lambda outcome: is_concluded(outcome, resolved_outcomes))\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_registration(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Add the 'registered' column to the DataFrame based on case registration criteria.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame with case data.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with 'registered' column added.\n",
    "    \"\"\"\n",
    "    df['registered'] = df.apply(\n",
    "        lambda row: is_case_registered(row['outcome'], row['activity_date'], row['filed_date']),\n",
    "        axis=1\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def add_productivity(df: pd.DataFrame, merit_outcomes: list) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Categorize each row in the DataFrame based on merit and conclusion status.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing 'outcome' and 'concluded' columns.\n",
    "        merit_outcomes (list): A list of outcomes considered merit outcomes.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with an additional 'productivity_category' column.\n",
    "    \"\"\"\n",
    "    def categorize_row(row):\n",
    "        if row['outcome'] in merit_outcomes and row['concluded'] == 1:\n",
    "            return 'Merit'\n",
    "        elif row['outcome'] not in merit_outcomes and row['concluded'] == 1:\n",
    "            return 'Non-Merit'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    # Apply the row categorization\n",
    "    df['productivity_category'] = df.apply(categorize_row, axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def get_productivity(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Create a pivot table summarizing the productivity category counts by court.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame with a 'productivity_category' column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The pivot table with merit and non-merit case counts for each court.\n",
    "    \"\"\"\n",
    "    # Create the pivot table\n",
    "    productivity_pivot_table = pd.pivot_table(\n",
    "        df,\n",
    "        values='concluded',  \n",
    "        index='court',     \n",
    "        columns='productivity_category', \n",
    "        aggfunc='count',   \n",
    "        fill_value=0        \n",
    "    ).rename(columns={'merit': 'Merit', 'non-merit': 'Non_Merit'})\n",
    "\n",
    "    return productivity_pivot_table\n",
    "\n",
    "def get_adjournment(df: pd.DataFrame, non_adjournable: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Perform adjournment analysis on the DataFrame by creating columns for adjourned and adjournable events,\n",
    "    calculating adjourned events per court and reason, and determining adjournment rates.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing 'reason_adj', 'comingfor', and 'court' columns.\n",
    "        non_adjournable (list): A list of 'comingfor' values that are considered non-adjournable.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing adjournment proportions per court.\n",
    "    \"\"\"\n",
    "    if not all(col in df.columns for col in ['reason_adj', 'comingfor', 'court']):\n",
    "        raise ValueError(\"Input DataFrame must contain 'reason_adj', 'comingfor', and 'court' columns.\")\n",
    "\n",
    "    df['comingfor'] = df['comingfor'].str.strip()\n",
    "\n",
    "    # 1. Create 'adjourned' column (1 if 'reason_adj' is not null and 'comingfor' is not in non_adjournable, else 0)\n",
    "    df['adjourned'] = (df['reason_adj'].notnull() & df['comingfor'].apply(lambda x: x not in non_adjournable)).astype(int)\n",
    "\n",
    "    # 2. Create 'adjournable' column (1 if 'comingfor' is not in non_adjournable, else 0)\n",
    "    df['adjournable'] = df['comingfor'].apply(lambda x: x not in non_adjournable).astype(int)\n",
    "\n",
    "    # 3. Calculate adjourned events per court and reason_adj\n",
    "    adjourned_per_court_reason = df.groupby(['court', 'reason_adj'])['adjourned'].sum().reset_index(name='count')\n",
    "\n",
    "    # 4. Sum adjourned and adjournable events per court\n",
    "    adjourned = df.groupby('court')['adjourned'].sum().reset_index(name='total_adjourned')\n",
    "    adjournable = df.groupby('court')['adjournable'].sum().reset_index(name='total_adjournable')\n",
    "\n",
    "    # 5. Calculate the adjournment proportion per court\n",
    "    adjourn_proportion = pd.merge(adjourned, adjournable, on='court')\n",
    "    adjourn_proportion['adjourn_proportion'] = (adjourn_proportion['total_adjourned'] / adjourn_proportion['total_adjournable']) * 100\n",
    "\n",
    "    return adjourn_proportion\n",
    "\n",
    "\n",
    "def get_monthly_case_stats(df, registered_col, concluded_col):\n",
    "    \"\"\"Calculates monthly statistics for registered and concluded cases.\n",
    "\n",
    "    Args:\n",
    "        df (pandas.DataFrame): The input DataFrame containing case data.\n",
    "        registered_col (str): The name of the column containing registered cases.\n",
    "        concluded_col (str): The name of the column containing concluded cases.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame with monthly statistics for registered and concluded cases.\n",
    "    \"\"\"\n",
    "\n",
    "    monthly_cases = df.groupby(['court', 'date_mon', 'case_type']).agg(\n",
    "        registered=(registered_col, 'sum'),\n",
    "        concluded=(concluded_col, 'sum')\n",
    "    ).reset_index()\n",
    "\n",
    "    return monthly_cases\n",
    "\n",
    "def get_cases_per_quarter(df, column):\n",
    "    # Group by quarters and count cases\n",
    "    cases_per_quarter = df.groupby(pd.Grouper(key='activity_date', freq='QE'))[column].sum()\n",
    "\n",
    "    # Reset index to make the quarters a column\n",
    "    cases_per_quarter = cases_per_quarter.reset_index()\n",
    "\n",
    "    # Rename the columns\n",
    "    cases_per_quarter.columns = ['quarter', f'cases_{column}']\n",
    "\n",
    "    return cases_per_quarter\n",
    "\n",
    "\n",
    "def get_quarterly_stats(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate quarterly statistics for adjourned, adjournable, concluded, and registered cases.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame containing case data.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame with quarterly statistics.\n",
    "    \"\"\"\n",
    "    quarterly_adjourned = get_cases_per_quarter(df, 'adjourned')\n",
    "    quarterly_adjournable = get_cases_per_quarter(df, 'adjournable')\n",
    "    quarterly_concluded = get_cases_per_quarter(df, 'concluded')\n",
    "    quarterly_registered = get_cases_per_quarter(df, 'registered')\n",
    "    \n",
    "    # Merge quarterly data on quarter column\n",
    "    quarterly_stats = quarterly_adjourned.merge(\n",
    "        quarterly_adjournable, on='quarter'\n",
    "    ).merge(\n",
    "        quarterly_concluded, on='quarter'\n",
    "    ).merge(\n",
    "        quarterly_registered, on='quarter'\n",
    "    )\n",
    "    \n",
    "    return quarterly_stats\n",
    "\n",
    "\n",
    "def calculate_timeline_proportion_per_court(\n",
    "    df: pd.DataFrame, \n",
    "    time_limit_column: str = 'within_time_limit', \n",
    "    concluded_column: str = 'concluded', \n",
    "    court_column: str = 'court', \n",
    "    case_type_column: str = 'broad_case_type'\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Calculate the proportion of cases resolved within the time limit per court and case type.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the case data.\n",
    "        time_limit_column (str): The column name indicating if the case was resolved within the time limit (binary).\n",
    "        concluded_column (str): The column name indicating if the case was concluded (binary).\n",
    "        court_column (str): The column name representing courts.\n",
    "        case_type_column (str): The column representing broad case types.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the proportion of cases resolved within the time limit per court.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Filter DataFrame for cases resolved within the time limit\n",
    "        df_resolved_within_limit = df[df[time_limit_column] == 1]\n",
    "        \n",
    "        # Filter DataFrame for concluded cases\n",
    "        df_concluded = df[df[concluded_column] == 1]\n",
    "        \n",
    "        # Create pivot tables\n",
    "        resolved_within_timelimit_pivot = df_resolved_within_limit.pivot_table(\n",
    "            index=court_column, \n",
    "            columns=case_type_column, \n",
    "            values=time_limit_column, \n",
    "            aggfunc='count', \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        total_concluded_per_court_pivot = df_concluded.pivot_table(\n",
    "            index=court_column, \n",
    "            columns=case_type_column, \n",
    "            values=time_limit_column,  # Using `time_limit_column` for count\n",
    "            aggfunc='count', \n",
    "            fill_value=0\n",
    "        )\n",
    "        \n",
    "        # Calculate the proportion of cases resolved within the time limit\n",
    "        timeline_proportion_per_court = resolved_within_timelimit_pivot / total_concluded_per_court_pivot\n",
    "        \n",
    "        # Log the success message\n",
    "        logger.info(\"Successfully calculated timeline proportion per court.\")\n",
    "        \n",
    "        return timeline_proportion_per_court\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error calculating timeline proportions: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reclassify rulings\n",
    "\n",
    "if a outcome has ruling delivered cases closed, check that the comingfor is ruling, meaning it was already scheduled for delivery. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reclassify_ruling(df):\n",
    "    ruling_date_set_outcomes = ['Ruling date given']\n",
    "    ruling_delivered_outcomes = ['Ruling delivered- case closed']\n",
    "    \n",
    "    # Preprocessing: Filter and sort the DataFrame upfront\n",
    "    df_filtered = df[df['outcome'].isin(judgment_date_set_outcomes + judgment_delivered_outcomes)]\n",
    "    df_filtered = df_filtered.sort_values(by=['case_number', 'activity_date'])\n",
    "    \n",
    "    # Initialize columns\n",
    "    df['judgment_status'] = 'Not Scheduled'\n",
    "    df['set_date'] = pd.NaT\n",
    "    df['delivery_date'] = pd.NaT\n",
    "    df['delivery_category'] = ''\n",
    "    \n",
    "    # Filter rows with judgment set outcomes and valid schedule dates\n",
    "    judgment_set_rows = df_filtered[df_filtered['outcome'].isin(judgment_date_set_outcomes) & \n",
    "                                    (df_filtered['next_date'] <= cutoff_date)]\n",
    "    \n",
    "    # For each case, find the earliest set date\n",
    "    earliest_schedule = judgment_set_rows.groupby('case_number').first().reset_index()\n",
    "    \n",
    "    # Create dictionaries to map case numbers to their schedule dates and statuses\n",
    "    case_to_set_date = dict(zip(earliest_schedule['case_number'], earliest_schedule['next_date']))\n",
    "    case_to_status = {case: 'Scheduled' for case in earliest_schedule['case_number']}\n",
    "    \n",
    "    # Update the result dataframe with schedule information\n",
    "    df['set_date'] = df['case_number'].map(case_to_set_date)\n",
    "    df['judgment_status'] = df['case_number'].map(case_to_status).fillna('Not Scheduled')\n",
    "    df['delivery_category'] = df['case_number'].map(case_to_status).fillna('')\n",
    "    \n",
    "    # Filter rows with judgment delivered outcomes\n",
    "    judgment_delivered_rows = df_filtered[df_filtered['outcome'].isin(judgment_delivered_outcomes)]\n",
    "    \n",
    "    # Find the first delivery date after set date\n",
    "    for case_number, group in earliest_schedule.groupby('case_number'):\n",
    "        set_date = group['next_date'].values[0]\n",
    "        delivery = judgment_delivered_rows[(judgment_delivered_rows['case_number'] == case_number) & \n",
    "                                           (judgment_delivered_rows['activity_date'] >= set_date)]\n",
    "        \n",
    "        if not delivery.empty:\n",
    "            delivery_date = delivery.iloc[0]['activity_date']\n",
    "            df.loc[df['case_number'] == case_number, 'delivery_date'] = delivery_date\n",
    "            df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "            \n",
    "            if delivery_date <= set_date:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'On Time'\n",
    "            else:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'Delayed'\n",
    "        else:\n",
    "            earlier_delivery = judgment_delivered_rows[(judgment_delivered_rows['case_number'] == case_number) & \n",
    "                                                       (judgment_delivered_rows['activity_date'] < set_date)]\n",
    "            if earlier_delivery.empty:\n",
    "                if cutoff_date >= set_date:\n",
    "                    df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delayed'\n",
    "                    df.loc[df['case_number'] == case_number, 'delivery_category'] = 'Delayed'\n",
    "            else:\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_date'] = earlier_delivery.iloc[0]['activity_date']\n",
    "                df.loc[df['case_number'] == case_number, 'judgment_status'] = 'Delivered'\n",
    "                df.loc[df['case_number'] == case_number, 'delivery_category'] = 'On Time'\n",
    "    \n",
    "    return df[df['set_date'].notna()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/home/stanoo/Projects/data/tribunal' \n",
    "#file_path = \"/home/stanoo/dcrt/data/API/Hc/hc_23-24_data.csv\"\n",
    "raw_df = pd.read_csv(f'{file_path}/tribunal.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = raw_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outcomes=raw_df.groupby('outcome')['outcome'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# revision_outcomes = raw_df[raw_df['case_type'] == 'Criminal Revision'].groupby('outcome')['outcome'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    validate_columns(df, ['outcome', 'activity_date', 'filed_date'])\n",
    "    logger.info(\"Validation passed.\")\n",
    "except ValueError as e:\n",
    "    logger.error(e)\n",
    "df = add_date(df.copy(), ['date_dd', 'date_mon', 'date_yyyy'], 'activity_date')\n",
    "df = add_date(df.copy(), ['filed_dd', 'filed_mon', 'filed_yyyy'], 'filed_date')\n",
    "df = add_date(df.copy(), ['next_dd', 'next_mon','next_yyyy'], 'next_date')\n",
    "df = add_case_number(df, 'court', 'caseid_type', 'caseid_no', 'filed_yyyy')\n",
    "df = add_case_age(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = add_case_nature(df, CRIMINAL_CASES)\n",
    "df = add_conclusion(df, RESOLVED_OUTCOMES)\n",
    "df = add_registration(df)\n",
    "df = add_productivity(df, MERIT_OUTCOMES)\n",
    "#df = add_broad_category(df, 'case_type', 'broad_case_type', BROAD_CASE_TYPES)\n",
    "#df = process_case_time_limits(df, TIME_LIMITS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['case_number']=='Eldoret High Court_High Court Criminal/HCCRREV/E223/2022']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['court', 'broad_case_type'])['concluded'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['broad_case_type']=='Criminal Revision'].groupby('court')['concluded'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get criminal revisions within time limit per court and broad case type\n",
    "df[df['broad_case_type']=='Criminal Revision'].groupby('court')['within_time_limit'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_timeline = calculate_timeline_proportion_per_court(df)\n",
    "court_productivity = get_productivity(df)\n",
    "adjourned_stats = get_adjournment(df, NON_ADJOURNABLE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# monthly_filed_cases = analysis.get_monthly_cases(df, 'registered')\n",
    "# monthly_concluded_cases = analysis.get_monthly_cases(df, 'concluded')\n",
    "# average_time_to_conclude = analysis.get_average_time_to_conclude(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filed_cases = analyze_court_outcomes(df, '2023-07-01', '2024-06-30', 'registered')\n",
    "resolved_cases = analyze_court_outcomes(df, '2023-07-01', '2024-06-30', 'concluded')\n",
    "monthly_stats = get_monthly_case_stats(df, 'registered', 'concluded')\n",
    "merged_quarterly = get_quarterly_stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filed_cases.to_csv(f'{file_path}/reports/filed_cases.csv')\n",
    "resolved_cases.to_csv(f'{file_path}/reports/resolved_cases.csv')\n",
    "monthly_stats.to_csv(f'{file_path}/reports/monthly_stats.csv', index=False)\n",
    "court_productivity.to_csv(f'{file_path}/reports/court_productivity.csv')\n",
    "average_time_to_conclude.to_csv(f'{file_path}/reports/average_time_to_conclude.csv')\n",
    "performance_timeline.to_csv(f'{file_path}/reports/performance_timeline.csv')\n",
    "adjourned_stats.to_csv(f'{file_path}/reports/adjourned_stats.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_quarterly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolved_within_timelimit = df[df['time_lines'] == 1].pivot_table(index='court', columns='broad_case_type', values='time_lines', aggfunc='count', fill_value=0)\n",
    "total_concluded_per_court = df[df['concluded'] == 1].pivot_table(index='court', columns='broad_case_type', values='time_lines', aggfunc='count', fill_value=0)\n",
    "timeline_per_court = resolved_within_timeline_per_court_pivot / total_concluded_per_court_pivot\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haki-data-HVHT8HQl-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
