{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import logging\n",
    "from typing import List, Optional, Dict\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/mnt/c/Users/Alexra/OneDrive/Documents/DCRT/API/HC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_excel_file(file_path: str, column_names: List[str]) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Read an Excel file and return a DataFrame with specified column names and an added court name column.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file.\n",
    "        column_names (List[str]): List of column names to use for the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: DataFrame with the specified columns and court name, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        court_name = file_name.split(\"-\")[0]\n",
    "        df = pd.read_excel(file_path, header=4, names=column_names)\n",
    "        df = df.assign(court_name=court_name).drop(df.columns[0], axis=1)\n",
    "        df = df[['court_name'] + list(df.columns[:-1])]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_excel_files(folder_path: str, column_names: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read all Excel files in a folder and combine them into a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing Excel files.\n",
    "        column_names (List[str]): List of column names to use for the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame from all Excel files.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no Excel files are found or if unable to read any Excel files.\n",
    "    \"\"\"\n",
    "    file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)\n",
    "                  if filename.endswith((\".xls\", \".xlsx\"))]\n",
    "\n",
    "    if not file_paths:\n",
    "        raise ValueError(\"No Excel files found in the specified folder.\")\n",
    "\n",
    "    with Pool() as pool:\n",
    "        read_func = partial(read_excel_file, column_names=column_names)\n",
    "        data_frames = pool.map(read_func, file_paths)\n",
    "\n",
    "    data_frames = [df for df in data_frames if df is not None and not df.empty]\n",
    "\n",
    "    if not data_frames:\n",
    "        raise ValueError(\"Unable to read any Excel files.\")\n",
    "\n",
    "    return pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df: pd.DataFrame, name_map: Optional[Dict[str, str]] = None, court_prefix_to_remove: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the combined DataFrame by filling NaN values, optionally mapping court names, and reordering columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame to process.\n",
    "        name_map (Optional[Dict[str, str]]): Optional dictionary for mapping court names.\n",
    "        court_prefix_to_remove (Optional[str]): Optional string prefix to remove from court names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Fill NaN values in float columns with 0 and convert them to int\n",
    "    float_columns = df.select_dtypes(include=['float64']).columns\n",
    "    df[float_columns] = df[float_columns].fillna(0).astype(int)\n",
    "\n",
    "    if name_map:\n",
    "        # Create a new column with mapped names\n",
    "        def map_names(name: str) -> str:\n",
    "            for key, value in name_map.items():\n",
    "                name = name.replace(key, value)\n",
    "            return name.split()[0]\n",
    "\n",
    "        df['court'] = df['court_name'].apply(map_names)\n",
    "        df.loc[df['court'] == 'Milimani', 'court'] = df['court_name']\n",
    "        if court_prefix_to_remove:\n",
    "            df['court'] = df['court'].str.replace(court_prefix_to_remove, \"\", case=False, regex=False)\n",
    "        \n",
    "        df['court'] = df['court'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "        # Move court name to the first column and drop the original court_name column\n",
    "        df = df[['court'] + [col for col in df.columns if col != 'court' and col != 'court_name']]\n",
    "\n",
    "    else:\n",
    "        # If no name_map is provided, just rename 'court_name' to 'court'\n",
    "        df = df.rename(columns={'court_name': 'court'})\n",
    "        \n",
    "        if court_prefix_to_remove:\n",
    "            df['court'] = df['court'].str.replace(court_prefix_to_remove, \"\", case=False, regex=False)\n",
    "        \n",
    "        # Ensure 'court' is the first column\n",
    "        df = df[['court'] + [col for col in df.columns if col != 'court']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "        \"line\", \"date_dd\", \"date_mon\", \"date_yyyy\", \"caseid_type\", \"caseid_no\", \"filed_dd\",\n",
    "        \"filed_mon\", \"filed_yyyy\", \"original_court\", \"original_code\", \"original_number\",\n",
    "        \"original_year\", \"case_type\", \"judge_1\", \"judge_2\", \"judge_3\", \"judge_4\", \"judge_5\",\n",
    "        \"judge_6\", \"judge_7\", \"comingfor\", \"outcome\", \"reason_adj\", \"next_dd\", \"next_mon\",\n",
    "        \"next_yyyy\", \"male_applicant\", \"female_applicant\", \"organization_applicant\",\n",
    "        \"male_defendant\", \"female_defendant\", \"organization_defendant\", \"legalrep\",\n",
    "        \"applicant_witness\", \"defendant_witness\", \"custody\", \"other_details\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    combined_df = read_excel_files(file_path, column_names)\n",
    "        \n",
    "    # This is applicable in  High Court otherwise leave out the @name_map, @court_prefix_to_remove arguments while calling process_dataframe\n",
    "    name_map = {'_High Court Div': '', '_High Court Civil': '', '_High Court Criminal': ''}\n",
    "    court_prefix_to_remove = \"High Court_High Court\"\n",
    "        \n",
    "    processed_df = process_dataframe(combined_df, name_map, court_prefix_to_remove)\n",
    "    logger.info(\"Data processing completed successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during data processing: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop court == 'Milimani High Court_Court Annexed Mediation'column_names\n",
    "processed_df = processed_df[processed_df['court'] != 'Milimani High Court_Court Annexed Mediation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '/mnt/c/Users/Alexra/OneDrive/Documents/DCRT/RAW DATA'\n",
    "processed_df.to_csv(f'{raw_data_path}/hc_july_2024-feb_2025.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load use \"\\\\wsl.localhost\\Arch\\home\\fiend\\Documents\\elc\\elrc.dta\" in pandas \n",
    "data_elrc = pd.read_stata('/home/fiend/Documents/elc/elrc.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_elrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "        \"station\", \"date_dd\", \"date_mon\", \"date_yyyy\", \"caseid_type\", \"caseid_no\", \"filed_dd\",\n",
    "        \"filed_mon\", \"filed_yyyy\", \"original_court\", \"original_code\", \"original_number\",\n",
    "        \"original_year\", \"case_type\", \"judge_1\", \"judge_2\", \"judge_3\", \"judge_4\", \"judge_5\",\n",
    "        \"judge_6\", \"judge_7\", \"comingfor\", \"outcome\", \"reason_adj\", \"next_dd\", \"next_mon\",\n",
    "        \"next_yyyy\", \"male_applicant\", \"female_applicant\", \"organization_applicant\",\n",
    "        \"male_defendant\", \"female_defendant\", \"organization_defendant\", \"legalrep\",\n",
    "        \"applicant_witness\", \"defendant_witness\", \"custody\", \"other_details\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename data columns to match column_names\n",
    "data_elrc = data_elrc.rename(columns={\n",
    "    'A': 'line', 'B': 'date_dd', 'C': 'date_mon', 'D': 'date_yyyy', 'E': 'caseid_type',\n",
    "    'F': 'caseid_no', 'G': 'filed_dd', 'H': 'filed_mon', 'I': 'filed_yyyy', 'J': 'original_court',\n",
    "    'K': 'original_code', 'L': 'original_number', 'M': 'original_year', 'N': 'case_type',\n",
    "    'O': 'judge_1', 'P': 'judge_2', 'Q': 'judge_3', 'R': 'judge_4', 'S': 'judge_5',\n",
    "    'T': 'judge_6', 'U': 'judge_7', 'V': 'comingfor', 'W': 'outcome', 'X': 'reason_adj',\n",
    "    'Y': 'next_dd', 'Z': 'next_mon', 'AA': 'next_yyyy', 'AB': 'male_applicant',\n",
    "    'AC': 'female_applicant', 'AD': 'organization_applicant', 'AE': 'male_defendant',\n",
    "    'AF': 'female_defendant', 'AG': 'organization_defendant', 'AH': 'legalrep',\n",
    "    'AI': 'applicant_witness', 'AJ': 'defendant_witness', 'AK': 'custody', 'AL': 'other_details'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_elrc['station'] = data_elrc['station'].str.split('-').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_elrc.to_csv('/home/fiend/Documents/elc/elrc.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haki-data-HVHT8HQl-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
