{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "import logging\n",
    "from typing import List, Optional, Dict\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_excel_file(file_path: str, column_names: List[str]) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Read an Excel file and return a DataFrame with specified column names and an added court name column.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the Excel file.\n",
    "        column_names (List[str]): List of column names to use for the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        Optional[pd.DataFrame]: DataFrame with the specified columns and court name, or None if an error occurs.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        file_name = os.path.basename(file_path)\n",
    "        court_name = file_name.split(\"-\")[0]\n",
    "        df = pd.read_excel(file_path, header=4, names=column_names)\n",
    "        df = df.assign(court_name=court_name).drop(df.columns[0], axis=1)\n",
    "        df = df[['court_name'] + list(df.columns[:-1])]\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error reading file {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_excel_files(folder_path: str, column_names: List[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Read all Excel files in a folder and combine them into a single DataFrame.\n",
    "\n",
    "    Args:\n",
    "        folder_path (str): Path to the folder containing Excel files.\n",
    "        column_names (List[str]): List of column names to use for the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Combined DataFrame from all Excel files.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If no Excel files are found or if unable to read any Excel files.\n",
    "    \"\"\"\n",
    "    file_paths = [os.path.join(folder_path, filename) for filename in os.listdir(folder_path)\n",
    "                  if filename.endswith((\".xls\", \".xlsx\"))]\n",
    "\n",
    "    if not file_paths:\n",
    "        raise ValueError(\"No Excel files found in the specified folder.\")\n",
    "\n",
    "    with Pool() as pool:\n",
    "        read_func = partial(read_excel_file, column_names=column_names)\n",
    "        data_frames = pool.map(read_func, file_paths)\n",
    "\n",
    "    data_frames = [df for df in data_frames if df is not None and not df.empty]\n",
    "\n",
    "    if not data_frames:\n",
    "        raise ValueError(\"Unable to read any Excel files.\")\n",
    "\n",
    "    return pd.concat(data_frames, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dataframe(df: pd.DataFrame, name_map: Optional[Dict[str, str]] = None, court_prefix_to_remove: Optional[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Process the combined DataFrame by filling NaN values, optionally mapping court names, and reordering columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame to process.\n",
    "        name_map (Optional[Dict[str, str]]): Optional dictionary for mapping court names.\n",
    "        court_prefix_to_remove (Optional[str]): Optional string prefix to remove from court names.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Processed DataFrame.\n",
    "    \"\"\"\n",
    "    # Fill NaN values in float columns with 0 and convert them to int\n",
    "    float_columns = df.select_dtypes(include=['float64']).columns\n",
    "    df[float_columns] = df[float_columns].fillna(0).astype(int)\n",
    "\n",
    "    if name_map:\n",
    "        # Create a new column with mapped names\n",
    "        def map_names(name: str) -> str:\n",
    "            for key, value in name_map.items():\n",
    "                name = name.replace(key, value)\n",
    "            return name.split()[0]\n",
    "\n",
    "        df['court'] = df['court_name'].apply(map_names)\n",
    "        \n",
    "        if court_prefix_to_remove:\n",
    "            df['court'] = df['court'].str.replace(court_prefix_to_remove, \"\", case=False, regex=False)\n",
    "        \n",
    "        df['court'] = df['court'].str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "        # Move court name to the first column and drop the original court_name column\n",
    "        df = df[['court'] + [col for col in df.columns if col != 'court' and col != 'court_name']]\n",
    "    else:\n",
    "        # If no name_map is provided, just rename 'court_name' to 'court'\n",
    "        df = df.rename(columns={'court_name': 'court'})\n",
    "        \n",
    "        if court_prefix_to_remove:\n",
    "            df['court'] = df['court'].str.replace(court_prefix_to_remove, \"\", case=False, regex=False)\n",
    "        \n",
    "        # Ensure 'court' is the first column\n",
    "        df = df[['court'] + [col for col in df.columns if col != 'court']]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "        \"line\", \"date_dd\", \"date_mon\", \"date_yyyy\", \"caseid_type\", \"caseid_no\", \"filed_dd\",\n",
    "        \"filed_mon\", \"filed_yyyy\", \"original_court\", \"original_code\", \"original_number\",\n",
    "        \"original_year\", \"case_type\", \"judge_1\", \"judge_2\", \"judge_3\", \"judge_4\", \"judge_5\",\n",
    "        \"judge_6\", \"judge_7\", \"comingfor\", \"outcome\", \"reason_adj\", \"next_dd\", \"next_mon\",\n",
    "        \"next_yyyy\", \"male_applicant\", \"female_applicant\", \"organization_applicant\",\n",
    "        \"male_defendant\", \"female_defendant\", \"organization_defendant\", \"legalrep\",\n",
    "        \"applicant_witness\", \"defendant_witness\", \"custody\", \"other_details\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the directory where the Excel files are located\n",
    "folder_path = '/home/stanoo/dcrt/data/HC/HcNew'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    combined_df = read_excel_files(folder_path, column_names)\n",
    "        \n",
    "    # This is applicable in  High Court otherwise leave out the @name_map, @court_prefix_to_remove arguments while calling process_dataframe\n",
    "    name_map = {'_High Court Div': '', '_High Court Civil': '', '_High Court Criminal': ''}\n",
    "    court_prefix_to_remove = \"High Court_High Court\"\n",
    "        \n",
    "    processed_df = process_dataframe(combined_df, name_map, court_prefix_to_remove)\n",
    "    logger.info(\"Data processing completed successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"An error occurred during data processing: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indicate the directory where you want to save the processed data\n",
    "output_dir = '/home/stanoo/dcrt/data/HC/HcNew'\n",
    "processed_df.to_csv('processed_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
